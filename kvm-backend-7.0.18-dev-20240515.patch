diff --git a/Config.kmk b/Config.kmk
index abcef4a..9808e0a 100644
--- a/Config.kmk
+++ b/Config.kmk
@@ -1587,6 +1587,19 @@ ifdef VBOX_HEADLESS
  VBOX_WITH_VRDP_RDESKTOP =
 endif
 
+#
+# Configure VirtualBox to use the KVM NEM backend.
+#
+ifdef VBOX_WITH_KVM
+ VBOX_WITH_DRIVERLESS_FORCED = 1
+ VBOX_WITH_NATIVE_NEM=1
+ # KVM doesn't need the VirtualBox Ring 0 drivers
+ VBOX_WITH_VBOXDRV=
+ VBOX_WITH_NETFLT=
+ VBOX_WITH_NETFLT_CROSSBOW=
+ VBOX_WITH_NETADP=
+endif
+
 #
 # Undefined VBOX_WITH_MAIN implies exclusion of a few more items.
 #
@@ -1996,6 +2009,14 @@ endif
 ifdef VBOX_WITH_DRIVERLESS_FORCED
  DEFS += VBOX_WITH_DRIVERLESS_FORCED
 endif
+CYBERUS_CXX_FLAGS = -Werror -Wall
+ifdef VBOX_WITH_KVM
+ DEFS += VBOX_WITH_KVM
+ DEFS += VBOX_WITH_KVM_NESTING
+endif
+ifndef VBOX_HEADLESS
+ DEFS += VBOX_WITH_GVT_RENDERING
+endif
 
 # Don't flood CDEFS, old MASMs doesn't like too many defines.
 ifdef VBOX_WITH_DEBUGGER
@@ -3522,6 +3543,8 @@ ifndef VBOX_GCC_std
   VBOX_GCC_std := -std=c++17
   # else if "$(VBOX_CLANG_VERSION_CXX)" vge 60000 # Most language features complete by v6. Lib stuff was less complete in v6, but hopefully acceptable for out purposes.
   #VBOX_GCC_std := -std=c++17
+ else if VBOX_WITH_KVM
+  VBOX_GCC_std := -std=c++17
  else if "$(VBOX_CLANG_VERSION_CXX)" vge 50000 # darwin Xcode 5 allegedly knows what C++11 is
   VBOX_GCC_std := -std=c++11
   # else if "$(VBOX_GCC_VERSION_CXX)" vge 70000 # Language feature P0512R0 was v8, rest v7 or earlier. Most lib stuff present in 7, complete in v12.
diff --git a/configure b/configure
index 4b69712..22709bf 100755
--- a/configure
+++ b/configure
@@ -86,6 +86,7 @@ SETUP_WINE=
 ONLY_ADDITIONS=0
 TARGET_MACHINE=""
 TARGET_CPU=""
+WITH_KVM=0
 WITH_XPCOM=1
 WITH_PYTHON=1
 WITH_JAVA=1
@@ -2529,6 +2530,7 @@ cat << EOF
   --build-libssl           build openssl from sources
   --build-libtpms          build libtpms from sources
   --build-liblzma          build liblzma from sources
+  --with-kvm               build with kvm backend
 EOF
 [ $OSE -eq 0 ] && cat << EOF
   --build-libcurl          build libcurl from sources
@@ -2688,6 +2690,9 @@ for option in "$@"; do
     --with-linux=*)
       LINUX=`echo $option | cut -d'=' -f2`
       ;;
+    --with-kvm)
+      WITH_KVM=1
+      ;;
     --with-makeself=*)
       MAKESELF=`echo $option | cut -d'=' -f2`
       ;;
@@ -2969,6 +2974,7 @@ fi
 [ $WITH_JAVA      -eq 0 ] && cnf_append "VBOX_WITH_JWS" ""
 [ $WITH_HARDENING -eq 0 ] && cnf_append "VBOX_WITHOUT_HARDENING" "1"
 [ $WITH_HARDENING -eq 2 ] && cnf_append "VBOX_WITH_HARDENING" "2"
+[ $WITH_KVM       -eq 1 ] && cnf_append "VBOX_WITH_KVM" "1"
 [ $WITH_VMMRAW    -eq 0 ] && cnf_append "VBOX_WITH_RAW_MODE" ""
 [ $WITH_LIBTPMS   -eq 0 ] && cnf_append "VBOX_WITH_LIBTPMS" ""
 [ $WITH_LIBLZMA   -eq 0 ] && cnf_append "VBOX_WITH_LIBLZMA" ""
diff --git a/include/VBox/log.h b/include/VBox/log.h
index a643902..d59b330 100644
--- a/include/VBox/log.h
+++ b/include/VBox/log.h
@@ -178,10 +178,14 @@ typedef enum VBOXLOGGROUP
     LOG_GROUP_DEV_SMC,
     /** Trusted Platform Module Device group. */
     LOG_GROUP_DEV_TPM,
+    /** Vfio Device group. */
+    LOG_GROUP_DEV_VFIO,
     /** VGA Device group. */
     LOG_GROUP_DEV_VGA,
     /** Virtio PCI Device group. */
     LOG_GROUP_DEV_VIRTIO,
+    /** Virtio GPU Device group. */
+    LOG_GROUP_DEV_VIRTIO_GPU,
     /** Virtio Network Device group. */
     LOG_GROUP_DEV_VIRTIO_NET,
     /** VMM Device group. */
@@ -908,8 +912,10 @@ typedef enum VBOXLOGGROUP
     "DEV_SERIAL", \
     "DEV_SMC", \
     "DEV_TPM", \
+    "DEV_VFIO", \
     "DEV_VGA", \
     "DEV_VIRTIO", \
+    "DEV_VIRTIO_GPU", \
     "DEV_VIRTIO_NET", \
     "DEV_VMM", \
     "DEV_VMM_BACKDOOR", \
diff --git a/include/VBox/pci.h b/include/VBox/pci.h
index cd28b08..4112440 100644
--- a/include/VBox/pci.h
+++ b/include/VBox/pci.h
@@ -631,6 +631,8 @@ typedef enum PCIADDRTYPE
 #define VBOX_PCI_ROM_SLOT    6
 /** Max number of I/O regions. */
 #define VBOX_PCI_NUM_REGIONS 7
+/** Max Number of PCI BARs */
+#define VBOX_PCI_MAX_BARS 6
 
 #define PCI_ROM_SLOT         VBOX_PCI_ROM_SLOT    /**< deprecated */
 #define PCI_NUM_REGIONS      VBOX_PCI_NUM_REGIONS /**< deprecated */
diff --git a/include/VBox/settings.h b/include/VBox/settings.h
index 674e169..78bcbf6 100644
--- a/include/VBox/settings.h
+++ b/include/VBox/settings.h
@@ -1116,6 +1116,22 @@ struct HostPCIDeviceAttachment
 
 typedef std::list<HostPCIDeviceAttachment> HostPCIDeviceAttachmentList;
 
+/**
+ * NOTE: If you add any fields in here, you must update a) the constructor and b)
+ * the operator== which is used by MachineConfigFile::operator==(), or otherwise
+ * your settings might never get saved.
+ */
+struct VFIODeviceAttachment
+{
+    VFIODeviceAttachment();
+
+    bool operator==(const VFIODeviceAttachment &a) const;
+
+    com::Utf8Str strDevicePath;
+};
+
+typedef std::vector<VFIODeviceAttachment> VFIODeviceAttachmentList;
+
 /**
  * A device attached to a storage controller. This can either be a
  * hard disk or a DVD drive or a floppy drive and also specifies
@@ -1313,6 +1329,8 @@ struct Hardware
 
     IOSettings          ioSettings;             // requires settings version 1.10 (VirtualBox 3.2)
     HostPCIDeviceAttachmentList pciAttachments; // requires settings version 1.12 (VirtualBox 4.1)
+    VFIODeviceAttachmentList vfioAttachments;  // requires settings version 1.17 (VirtualBox 6.0)
+
 
     com::Utf8Str        strDefaultFrontend;     // requires settings version 1.14 (VirtualBox 4.3)
 };
diff --git a/include/VBox/vmm/nem.h b/include/VBox/vmm/nem.h
index 0d960a7..8603297 100644
--- a/include/VBox/vmm/nem.h
+++ b/include/VBox/vmm/nem.h
@@ -43,6 +43,14 @@
 #include <VBox/vmm/vmapi.h>
 #include <VBox/vmm/pgm.h>
 
+#ifdef VBOX_WITH_KVM_IRQCHIP_FULL
+// For KVMPICSTATE and KVMIRQCHIP
+#include <VBox/vmm/pdmdev.h>
+#endif
+
+#if defined(VBOX_WITH_KVM) && defined(IN_RING3)
+#include <VBox/vmm/cpum.h>      /* for PCPUMCPUIDLEAF */
+#endif
 
 RT_C_DECLS_BEGIN
 
@@ -160,6 +168,150 @@ VMMR3_INT_DECL(int)  NEMR3NotifyPhysRomRegisterEarly(PVM pVM, RTGCPHYS GCPhys, R
 VMMR3_INT_DECL(int)  NEMR3NotifyPhysRomRegisterLate(PVM pVM, RTGCPHYS GCPhys, RTGCPHYS cb, void *pvPages,
                                                     uint32_t fFlags, uint8_t *pu2State, uint32_t *puNemRange);
 
+#if defined(VBOX_WITH_KVM) && defined(IN_RING3)
+
+/**
+ * Retrieves the value of a single model specific register (MSR).
+ * @param pVCpu The vCPU in which context the MSR should be read (can be any vCPU for global MSRs).
+ * @param msr The index of the MSR that should be read.
+ * @param val A buffer that will contain the value of the specified MSR, if reading was successful.
+ * @return VBox status code, VINF_SUCCESS, if the read access was successful.
+ */
+VMMR3_INT_DECL(int) NEMR3KvmGetMsr(PVMCPU pVCpu, uint64_t msr, uint64_t* val);
+
+/**
+ * Writes a value to single model specific register (MSR).
+ * @param pVCpu The vCPU in which context the MSR should be written (can be any vCPU for global MSRs).
+ * @param msr The index of the MSR that should be written.
+ * @param val The value that should be written to the MSR.
+ * @return VBox status code, VINF_SUCCESS, if the write access was successful.
+ */
+VMMR3_INT_DECL(int) NEMR3KvmSetMsr(PVMCPU pVCpu, uint64_t msr, uint64_t val);
+
+/**
+ * Asserts a specific interrupt line on both PIC and I/O APIC.
+ * @param  pVM The cross context VM structure.
+ * @param  u16Gsi the GSI of the interrupt lines that should be asserted.
+ * @param  iLevel Line level, either PDM_IRQ_LEVEL_HIGH, PDM_IRQ_LEVEL_LOW or PDM_IRQ_LEVEL_FLIP_FLOP.
+ * @return Vbox status code.
+ */
+VMMR3_INT_DECL(int) NEMR3KvmSetIrqLine(PVM pVM, uint16_t u16Gsi, int iLevel);
+
+/**
+ * Execute state load operation. This sets the correct KVM MP state depending on
+ * the VBox vCPUs state.
+ * @param pVM The cross context VM structure
+ */
+VMMR3_INT_DECL(int) NEMR3LoadExec(PVM pVM);
+
+/**
+ * Retrieves the local APIC state from the in-kernel irqchip.
+ * @param pVCpu The vCpu to retrieve the APIC state from
+ * @param pXApicPage Pointer to the memory the APIC state is saved to. Must be
+ *                   at least of size KVM_APIC_REG_SIZE.
+ * @returns VBox status code
+ */
+VMMR3_INT_DECL(int) NEMR3KvmGetLapicState(PVMCPU pVCpu, void* pXApicPage);
+
+/**
+ * Configures the local APIC state of the in-kernel irqchip.
+ * @param pVCpu The vCpu for which to set the APIC state
+ * @param pXApicPage Pointer to the memory containing APIC state. Must be at
+ *                   least of size KVM_APIC_REG_SIZE.
+ * @returns VBox status code
+ */
+VMMR3_INT_DECL(int) NEMR3KvmSetLapicState(PVMCPU pVCpu, void* pXApicPage);
+
+#ifdef VBOX_WITH_KVM_IRQCHIP_FULL
+
+/**
+ * Retrieves the PIC state from the in-kernel irqchip.
+ * @param pVM The VM to retrieve the PIC state from
+ * @param irqchip Whether to retrieve the state from the master or slave pic
+ * @param state Buffer to store the PIC state in.
+ * @returns VBox status code
+ */
+VMMR3_INT_DECL(int) NEMR3KvmGetPicState(PVM pVM, KVMIRQCHIP irqchip, KVMPICSTATE* state);
+
+/**
+ * Configures the PIC state of the in-kernel irqchip.
+ * @param pVM The VM to for which to set the PIC state
+ * @param irqchip Whether to set the state of the master or slave pic
+ * @param state Pointer to the memory containing PIC state.
+ * @returns VBox status code
+ */
+VMMR3_INT_DECL(int) NEMR3KvmSetPicState(PVM pVM, KVMIRQCHIP irqchip, KVMPICSTATE* state);
+
+/**
+ * Retrieves the I/O APIC state from the in-kernel irqchip.
+ * @param pVM The VM to retrieve the I/O APIC state from
+ * @param state Buffer where to store I/O APIC state.
+ * @returns VBox status code
+ */
+VMMR3_INT_DECL(int) NEMR3KvmGetIoApicState(PVM pVM, KVMIOAPICSTATE* state);
+
+/**
+ * Configures the I/O APIC state of the in-kernel irqchip.
+ * @param pVM The VM to for which to set the I/O APIC state
+ * @param state Pointer to the memory containing I/O APIC state.
+ * @returns VBox status code
+ */
+VMMR3_INT_DECL(int) NEMR3KvmSetIoApicState(PVM pVM, KVMIOAPICSTATE* state);
+#endif
+/**
+ * Deliver a MSI via the in-kernel irqchip.
+ *
+ * @returns VBox status code
+ * @param pVM The cross context VM structure
+ * @param pMsi The MSI to inject into the guest
+ */
+VMMR3_INT_DECL(int) NEMR3KvmSplitIrqchipDeliverMsi(PVM pVM, PCMSIMSG pMsi);
+
+/**
+ * Add or update the Entry in the Redirection Table indexed by the GSI number.
+ *
+ * Interrupts configured via this interface will cause an EOI exit when the
+ * guest acknowledges them. Typically, this is only necessary for level
+ * triggered interrupts.
+ *
+ * @returns VBox status code
+ * @param pVM The cross context VM structure
+ * @param gsi The GSI number
+ * @param pMSI The MSI that should be delivered when the interrupt fires
+ */
+VMMR3_INT_DECL(int) NEMR3KvmSplitIrqchipAddUpdateRTE(PVM pVM, uint16_t u16Gsi, PCMSIMSG pMsi);
+
+/**
+ *  Remove an Redirection Table entry indexed by the GSI number
+ *
+ *  @returns VBox status code
+ *  @param pVM The cross context VM structure
+ *  @param gsi The GSI number for what the Redirection Table Entry should be
+ *  removed
+ */
+VMMR3_INT_DECL(int) NEMR3KvmSplitIrqchipRemoveRTE(PVM pVM, uint16_t u16Gsi);
+
+/**
+ * Returns an array of Hyper-V CPUID leaves supported by KVM.
+ *
+ * @returns VBox status code
+ * @param pVM The cross context VM structure
+ * @param outpCpuId The pointer where the CPUID leaves will be returned. Must be freed by the caller!
+ * @param outcLeaves The pointer where the number of CPUID leaves will be returned.
+ */
+VMMR3_INT_DECL(int) NEMR3KvmGetHvCpuIdLeaves(PVM pVM, PCPUMCPUIDLEAF *outpCpuId, size_t *outcLeaves);
+
+/**
+ * Returns an array of CPUID leaves supported by KVM.
+ *
+ * @returns VBox status code
+ * @param pVM The cross context VM structure
+ * @param outpCpuId The pointer where the CPUID leaves will be returned. Must be freed by the caller!
+ * @param outcLeaves The pointer where the number of CPUID leaves will be returned.
+ */
+VMMR3_INT_DECL(int) NEMR3KvmGetCpuIdLeaves(PVM pVM, PCPUMCPUIDLEAF *outpCpuId, size_t *outcLeaves);
+#endif
+
 /** @name Flags for NEMR3NotifyPhysRomRegisterEarly and NEMR3NotifyPhysRomRegisterLate.
  * @{ */
 /** Set if the range is replacing RAM rather that unused space. */
diff --git a/include/VBox/vmm/pdmcommon.h b/include/VBox/vmm/pdmcommon.h
index cbad799..8746e53 100644
--- a/include/VBox/vmm/pdmcommon.h
+++ b/include/VBox/vmm/pdmcommon.h
@@ -111,6 +111,11 @@
 #define PDM_TACH_FLAGS_NO_CALLBACKS     RT_BIT_32(1)
 /** @} */
 
+/** This flag is used in the pfnAttach call for the vga device and indicates
+ * that only a dummy driver should be attached. This is used to "disable" the
+ * vga device.
+ */
+#define PDM_ATTACH_DUMMY_DRIVER RT_BIT_32(31)
 
 /**
  * Is asynchronous handling of suspend or power off notification completed?
diff --git a/include/VBox/vmm/pdmdev.h b/include/VBox/vmm/pdmdev.h
index f895eb8..525d82e 100644
--- a/include/VBox/vmm/pdmdev.h
+++ b/include/VBox/vmm/pdmdev.h
@@ -64,6 +64,49 @@
 #include <iprt/stdarg.h>
 #include <iprt/list.h>
 
+#ifdef VBOX_WITH_KVM
+#define KVM_IRQCHIP_NUM_IOAPIC_INTR_PINS 24
+#define KVM_IRQCHIP_NUM_PIC_INTR_PINS 16
+#endif
+
+#if defined(IN_RING3) && defined(VBOX_WITH_KVM_IRQCHIP_FULL)
+struct KVMPICSTATE
+{
+    uint8_t         last_irr;
+    uint8_t         irr;
+    uint8_t         imr;
+    uint8_t         isr;
+    uint8_t         priority_add;
+    uint8_t         irq_base;
+    uint8_t         read_reg_select;
+    uint8_t         poll;
+    uint8_t         special_mask;
+    uint8_t         init_state;
+    uint8_t         auto_eoi;
+    uint8_t         rotate_on_auto_eoi;
+    uint8_t         special_fully_nested_mode;
+    uint8_t         init4;
+    uint8_t         elcr;
+    uint8_t         elcr_mask;
+};
+
+enum class KVMIRQCHIP
+{
+    PIC_MASTER = 0,
+    PIC_SLAVE = 1,
+};
+
+struct KVMIOAPICSTATE
+{
+    uint64_t base_address;
+    uint32_t ioregsel;
+    uint32_t id;
+    uint32_t irr;
+
+    uint64_t redirtbl[KVM_IRQCHIP_NUM_IOAPIC_INTR_PINS];
+};
+#endif
+
 
 RT_C_DECLS_BEGIN
 
@@ -1747,6 +1790,35 @@ typedef struct PDMPICHLP
      */
     DECLCALLBACKMEMBER(void, pfnUnlock,(PPDMDEVINS pDevIns));
 
+#if defined(IN_RING3) && defined(VBOX_WITH_KVM_IRQCHIP_FULL)
+    /**
+     * Asserts a PIC INTR Line.
+     * @param   pDevIns The PIC device instance.
+     * @param   u16Gsu  The GSI of the line to assert.
+     * @param   iLevel  Either PDM_IRQ_LEVEL_HIGH, PDM_IRQ_LEVEL_LOW or PDM_IRQ_LEVEL_FLIP_FLOP.
+     * @return  Vbox status code.
+     */
+    DECLCALLBACKMEMBER(int, pfnKvmSetIrqLine,(PPDMDEVINS pDevIns, uint16_t u16Gsi, int iLevel));
+
+    /**
+     * Retrieves the PIC state from the in-kernel irqchip.
+     * @param   pDevIns The PIC device instance.
+     * @param   irqchip Whether to retrieve the state from the master or slave pic
+     * @param   state   Buffer to store the PIC state in.
+     * @returns VBox status code
+     */
+    DECLCALLBACKMEMBER(int, pfnKvmGetPicState,(PPDMDEVINS pDevIns, KVMIRQCHIP irqchip, KVMPICSTATE* state));
+
+    /**
+     * Configures the PIC state of the in-kernel irqchip.
+     * @param   pDevIns The PIC device instance.
+     * @param   irqchip Whether to set the state of the master or slave pic.
+     * @param   state   Pointer to the memory containing PIC state.
+     * @returns VBox status code
+     */
+    DECLCALLBACKMEMBER(int, pfnKvmSetPicState,(PPDMDEVINS pDevIns, KVMIRQCHIP irqchip, KVMPICSTATE* state));
+#endif
+
     /** Just a safety precaution. */
     uint32_t                u32TheEnd;
 } PDMPICHLP;
@@ -1974,6 +2046,55 @@ typedef struct PDMIOAPICHLP
      */
     DECLCALLBACKMEMBER(int, pfnIommuMsiRemap,(PPDMDEVINS pDevIns, uint16_t idDevice, PCMSIMSG pMsiIn, PMSIMSG pMsiOut));
 
+#if defined(IN_RING3) && defined(VBOX_WITH_KVM)
+    DECLCALLBACKMEMBER(int, pfnKvmSetIrqLine,(PPDMDEVINS pDevIns, uint16_t u16Gsi, int iLevel));
+    /**
+     * Private interface between IOAPIC and KVM Split Irq Chip
+     *
+     * @returns status code.
+     * @param pDevIns Device instance of the IOAPIC.
+     * @param pMsi The MSI to deliver to the KVM Split Irq Chip
+     */
+    DECLCALLBACKMEMBER(int, pfnKvmSplitIrqchipDeliverMsi,(PPDMDEVINS pDevIns, PCMSIMSG pMsi));
+
+    /**
+     * Add or Update Redirection Table Entry for the desired GSI
+     *
+     * @returns status code.
+     * @param pDevIns Device instance of the IOAPIC
+     * @param u16Gsi The GSI number to change the redirection table entry for.
+     * @param pMsi The MSI that should be sent when GSI is triggered
+     */
+    DECLCALLBACKMEMBER(int, pfnKvmSplitIrqchipAddUpdateRTE, (PPDMDEVINS pDevIns, uint16_t u16Gsi, PCMSIMSG pMsi));
+
+    /**
+     * Remove the entry from the Redirection Table indicated by the GSI number.
+     *
+     * @retruns status code.
+     * @param pDevIns Device instance of the IOAPIC
+     * @param u16Gsi The GSI number to remove from the Redirection Table
+     */
+    DECLCALLBACKMEMBER(int, pfnKvmSplitIrqchipRemoveRTE, (PPDMDEVINS pDevIns, uint16_t u16Gsi));
+#endif
+
+#if defined(IN_RING3) && defined(VBOX_WITH_KVM_IRQCHIP_FULL)
+    /**
+     * Retrieves the I/O APIC state from the in-kernel irqchip.
+     * @param   pDevIns The I/O APIC device instance.
+     * @param   state   Buffer to store the I/O APIC state in.
+     * @returns VBox status code
+     */
+    DECLCALLBACKMEMBER(int, pfnKvmGetIoApicState,(PPDMDEVINS pDevIns, KVMIOAPICSTATE* state));
+
+    /**
+     * Configures the I/O APIC state of the in-kernel irqchip.
+     * @param   pDevIns The I/O APIC device instance.
+     * @param   state Pointer to the memory containing I/O APIC state.
+     * @returns VBox status code
+     */
+    DECLCALLBACKMEMBER(int, pfnKvmSetIoApicState,(PPDMDEVINS pDevIns, KVMIOAPICSTATE* state));
+#endif
+
     /** Just a safety precaution. */
     uint32_t                u32TheEnd;
 } PDMIOAPICHLP;
diff --git a/include/VBox/vmm/pdmifs.h b/include/VBox/vmm/pdmifs.h
index c4eaeb1..86a3a94 100644
--- a/include/VBox/vmm/pdmifs.h
+++ b/include/VBox/vmm/pdmifs.h
@@ -42,6 +42,9 @@
 #include <iprt/sg.h>
 #include <VBox/types.h>
 
+// For VMMDevDisplayDef
+#include <VBox/VMMDev.h>
+
 
 RT_C_DECLS_BEGIN
 
@@ -552,6 +555,14 @@ typedef struct PDMIKEYBOARDCONNECTOR
 #define PDMIKEYBOARDCONNECTOR_IID               "db3f7bd5-953e-436f-9f8e-077905a92d82"
 
 
+typedef struct PDMIVIRTIOGPUPORT
+{
+    DECLR3CALLBACKMEMBER(void, pfnDisplayChanged, (PPDMDEVINS pDevIns, uint32_t numDisplays, VMMDevDisplayDef* displayDefs));
+} PDMIVIRTIOGPUPORT;
+
+typedef struct PDMIVIRTIOGPUPORT *PPDMIVIRTIOGPUPORT;
+
+# define PDMIVIRTIOGPUPORT_IID               "db3f7bd5-baba-436f-9f8e-077905a92d82"
 
 /** Pointer to a display port interface. */
 typedef struct PDMIDISPLAYPORT *PPDMIDISPLAYPORT;
diff --git a/include/VBox/vmm/vmmr3vtable-def.h b/include/VBox/vmm/vmmr3vtable-def.h
index e603a58..b420784 100644
--- a/include/VBox/vmm/vmmr3vtable-def.h
+++ b/include/VBox/vmm/vmmr3vtable-def.h
@@ -595,6 +595,7 @@ VTABLE_ENTRY(PDMR3DeviceDetach)
 VTABLE_ENTRY(PDMR3DriverAttach)
 VTABLE_ENTRY(PDMR3DriverDetach)
 VTABLE_ENTRY(PDMR3NsBwGroupSetLimit)
+VTABLE_ENTRY(PDMR3QueryDevice)
 VTABLE_ENTRY(PDMR3QueryDeviceLun)
 VTABLE_ENTRY(PDMR3QueryDriverOnLun)
 VTABLE_ENTRY(PDMR3QueryLun)
diff --git a/include/cyberus/edid.hpp b/include/cyberus/edid.hpp
new file mode 100644
index 0000000..b05b59e
--- /dev/null
+++ b/include/cyberus/edid.hpp
@@ -0,0 +1,423 @@
+#pragma once
+
+#include <array>
+#include <cassert>
+#include <cstdint>
+#include <cstring>
+#include <numeric>
+#include <string>
+
+/*
+ * The Extended Display Identification Data structure Version 1.4 Structure Definitions
+ * The EDID structures are implemented based on the VESA-EEDID-A2 Specification
+ * from https://glenwing.github.io/docs/VESA-EEDID-A2.pdf
+ */
+
+/*
+ * The EDID Standard Timings Definition (Section 3.9 VESA EEDID A2 Specification)
+ * For a list of Standard Codes please refer to the VESA DMT 1.13 Specification.
+ * Link: https://glenwing.github.io/docs/VESA-DMT-1.13.pdf
+ * The horizontal addressable pixels are calculated by the following formula:
+ * horizontalPixels = (pixelcount / 8) - 31;
+ */
+struct __attribute__((__packed__)) EdidStandardTiming
+{
+    uint8_t horizontalPixels;
+
+    /*
+     * The aspectRatio is stored in bits 6 and 7
+     */
+    enum __attribute__((__packed__)) AspectRatio : uint8_t
+    {
+        AR_16_10 = 0x0,
+        AR_4_3 = 0x1 << 6,
+        AR_5_4 = 0x2 << 6,
+        AR_16_9 = 0x3 << 6
+    };
+
+    /*
+     * The refresh rate is stored in the lower 5 bits and stored using this
+     * formula: refreshRate = <value> + 60 HZ
+     * Example 85 HZ: 0x19 + 60 = 85 hz; refresh rate = 0x19;
+     */
+    uint8_t aspectRatioAndRefreshRate;
+
+    EdidStandardTiming() = default;
+
+    EdidStandardTiming(uint32_t horizontalPixels_, AspectRatio ratio, uint8_t refreshRate)
+    {
+        assert(refreshRate >= 60);
+        horizontalPixels = (horizontalPixels_ / 8) - 31;
+        aspectRatioAndRefreshRate = (ratio & 0xc0) | ((refreshRate - 60) & 0x3f);
+    }
+};
+
+/*
+ * The Detailed Timing Descriptor (Section 3.10.2)
+ *
+ * The default values are extracted from a running GVT with its default EDID
+ */
+struct __attribute__((__packed__)) EdidDetailedTimingDescriptor
+{
+    uint16_t pixelClock {0};
+    uint8_t hVideoLow {0x80};
+    uint8_t hBlankingLow {0xa0};
+    uint8_t hVideoBlankingHigh {0x70};
+    uint8_t vVideoLow {0xb0};
+    uint8_t vVBlankingLow {0x23};
+    uint8_t vVideoBlankingHigh {0x40};
+    uint8_t hFrontPorchLow {0x30};
+    uint8_t hSyncPulseWidthLow {0x20};
+    uint8_t vFrontPorchSyncPulseWidthlow {0x36};
+    uint8_t vhFrontPorchSyncPulseHigh {0x00};
+    uint8_t hVideoImageSizeLow {0x06};
+    uint8_t vVideoImageSizeLow {0x44};
+    uint8_t vhVideoImageSizeHigh {0x21};
+    uint8_t horizontalBorder {0x00};  // (Section 3.12)
+    uint8_t verticalBorder {0x00};    // (Section 3.12)
+    uint8_t signalDefinitions {0x1a}; // (Table 3.22)
+};
+
+static_assert(sizeof(EdidDetailedTimingDescriptor) == 18,
+              "The size of the EdidDetailedTimingDescriptor must be 18 bytes!");
+
+/*
+ * The Display Descriptor Definitions (Section 3.10.3)
+ */
+struct __attribute__((__packed__)) EdidDisplayDescriptorDefinitions
+{
+    uint16_t reserved {0};
+    uint8_t reserved1 {0};
+
+    enum __attribute__((__packed__)) : uint8_t
+    {
+        DisplayProductName = 0xFC,
+        DisplayRangeLimits = 0xFD,
+        DisplaySerialNumber = 0xFF,
+    } tag {DisplayProductName};
+
+    union __attribute__((__packed__))
+    {
+        uint8_t reserved2 {0};    // for Serial Number and Product Name
+        uint8_t rangeLimitOffset; // for Display Range Limits (Table 3.26)
+    };
+
+    union __attribute__((__packed__))
+    {
+        char productName[13] {"CBS Display"};
+        char serialNumber[13];
+        struct __attribute__((__packed__))
+        {
+            uint8_t minimumVerticalRate;
+            uint8_t maximumVerticalRate;
+            uint8_t minimumHorizontalRate;
+            uint8_t maximumHorizontalRate;
+            uint8_t maximumPixelClock;
+            uint8_t videoTimingSupportFlags;
+            uint8_t videoTimingDataOrLineFeed; // (Table 3.27 and 3.28
+            uint8_t videoTimingDataOrSpace[6];
+        } rangeLimitsTimingDescriptor;
+    };
+};
+
+static_assert(sizeof(EdidDisplayDescriptorDefinitions) == 18,
+              "The size of the EdidDisplayDescriptorDefinitions must be 18 bytes!");
+
+/*
+ * The EDID Base Block.
+ * All definitions in this structure are based on the VESA-EEDID-A2 Specification.
+ * The structure is implemented Based on Table 3.1 in Section 3.i EDID Format Overview
+ */
+struct __attribute__((__packed__)) EdidBaseBlock
+{
+    uint64_t header {0x00ffffffffffff00}; // (Section 3.3)
+
+    /*
+     * Vendor and Product ID (Section 3.4)
+     */
+    uint16_t manufacturerName {0x530c};   // "CBS" (Section 3.4.1)
+    uint16_t productCode {0x1};           // (Section 3.4.2)
+    uint32_t serialNumber {0x1337};       // (Section 3.4.3)
+    uint16_t manufacturingDates {0x262d}; // (Section 3.4.4) ->(WW45 2022)
+                                          //
+    /*
+     * EDID Version and Revision (Section 3.5)
+     */
+    uint8_t version {0x1};
+    uint8_t revision {0x4};
+
+    /*
+     * Basic Display Parameters and Features (Section 3.6)
+     */
+    uint8_t videoInputDefinition {0xa5}; // (Section 3.6.1 and Table 3.11)
+
+    /*
+     * The Aspect ratio or screen size (Section 3.6.2 and Table 3.12) As we can't
+     * determine the aspect ratio nor the horizontal and vertical screen size
+     * We set the value to 0 which is per Specification used for variable or
+     * unknown ARs and Screen sizes.
+     */
+    uint16_t aspectRatio {0x0000};
+    uint8_t displayTransferCharacteristic {0x78}; // (Section 3.6.3)
+    uint8_t supportedFeatures {0x23};             // (Section 3.6.4 and Table 3.14)
+
+    /*
+     * Color Characteristics (Section 3.7)
+     * Note: these values are copied and modified from
+     * src/VBox/Additions/linux/drm/vbox_mode.c:vbox_set_edid
+     */
+    uint8_t redGreenLowOrder {0xfc};
+    uint8_t blueWhiteLowOrder {0x81};
+    uint8_t redXHighOrder {0xa4};
+    uint8_t redYHighOrder {0x55};
+    uint8_t greenXHighOrder {0x4d};
+    uint8_t greenYHighOrder {0x9d};
+    uint8_t blueXHighOrder {0x25};
+    uint8_t blueYHighOrder {0x12};
+    uint8_t whiteXHighOrder {0x50};
+    uint8_t whiteYHighOrder {0x54};
+
+    /*
+     * Established Timings (Section 3.8 and Table 3.18)
+     */
+    uint8_t establishedTimings1 {0x21}; // 640x480,60HZ; 800x600,60HZ
+    uint8_t establishedTimings2 {0x8};  // 1024x768,60HZ
+    uint8_t manufacturersTimings {0x0};
+
+    /*
+     * Standard Timings (Section 3.9)
+     */
+    EdidStandardTiming standardTimings[8];
+
+    /*
+     * The 18 Byte Descriptors (Section 3.10)
+     */
+    EdidDetailedTimingDescriptor preferredTimingMode {};
+
+    /*
+     * The Second to 4th 18 byte descriptor.
+     * At the Moment we use Display Descriptor Definitions only, but
+     * DetailedTimingDescriptors are possible here as well.
+     */
+    EdidDisplayDescriptorDefinitions displayDescriptors[3];
+
+    uint8_t extensionBlockCount {0};
+
+    uint8_t checksum;
+};
+
+constexpr uint32_t EDID_LENGTH {sizeof(EdidBaseBlock)};
+
+/*
+ * The EIA/CEA 861F Extended EDID Structures.
+ *
+ * The EDID contains the EDID Base Block and an additional EIA/CEA 861F
+ * Compliant EDID Block.
+ *
+ * The EIA/CEA 861G Block Layouts are specified in the CEA-861-F Specification (Section 7.5).
+ * Link:
+ * https://web.archive.org/web/20171201033424/https://standards.cta.tech/kwspub/published_docs/CTA-861-G_FINAL_revised_2017.pdf
+ */
+
+/*
+ *  The CEA Data Block Header Type Byte structure. (Table 54  CEA 861-G)
+ */
+struct __attribute__((__packed__)) CEADataBlockHeader
+{
+    /*
+     * The CEA Data Block Codes (Table 55 EIA/CEA 861-G Specification)
+     */
+    enum __attribute__((__packed__)) DataBlockTagCode : uint8_t
+    {
+        Audio = 1 << 5,
+        Video = 2 << 5,
+        VendorSpecific = 3 << 5,
+        SpeakerAllocation = 4 << 5,
+        VESADisplayTransferCharacteristic = 5 << 5,
+        UseExtendedTag = 7 << 5,
+    };
+
+    enum __attribute__((__packed__)) : uint8_t
+    {
+        LENGTH_MASK = 0x1F,
+        TAG_MASK = 0xE0,
+    };
+
+    uint8_t tagAndLength;
+};
+
+/*
+ * The Video Data Block of the EIA/CEA 861-G Specification (Section 7.5.1)
+ */
+struct __attribute__((__packed__)) CEAVideoDataBlock : public CEADataBlockHeader
+{
+    static constexpr uint8_t MAX_SHORT_VIDEO_DESCRIPTORS {0x1F};
+    std::array<uint8_t, MAX_SHORT_VIDEO_DESCRIPTORS> shortVideoDescriptors;
+};
+
+/*
+ * The CEA Timing Extension.
+ *
+ * The Timing Extension can contain the following CEA Data Blocks:
+ * - Video Data Block
+ * - Audio Data Block
+ * - Speaker Allocation Data Block
+ * - Vendor Specific Data Block
+ *
+ * Our current use case requires Video Data Blocks only.
+ * For simplicity the Structure contains Video Data Blocks only.
+ *
+ *
+ * The Basic Layout can be seen in Table 52 and Table 53 of the EIA/CEA-861-G Specification
+ */
+struct __attribute__((__packed__)) CEAExtendedEdid : public EdidBaseBlock
+{
+    uint8_t eiaCeaTag {0x2};
+    uint8_t eiaCeaRevision {0x3};
+    uint8_t eiaCeaDetailedTimingDescriptorOffset {0x0};
+    uint8_t eiaCeaNativeFormatsandFeatures {0x0};
+    CEAVideoDataBlock videoDataBlock;
+
+    /* padding or other data blocks or DTD's */
+    std::array<uint8_t, sizeof(EdidBaseBlock) - sizeof(videoDataBlock) - 5> padding;
+    uint8_t eiaCeaChecksum {0x0};
+};
+
+static_assert(sizeof(CEAExtendedEdid) == 256, "The CEAExtendedEdid is not 256 bytes large.");
+
+/**
+ * Generates a EDID (Extended Display Identification Data) where the Preferred
+ * Timing Mode has the given resolution.
+ *
+ * The mechanism works following way:
+ * - unplug the virtual display from the vGPU
+ * - set the new EDID generated from the given resolution
+ * - plug in the virtual display
+ *
+ * For the guest OS it looks like a new monitor is connected to the graphics
+ * controller.
+ *
+ *  The EDID is implemented based on the VESA-EEDID-A2 Specification.
+ *  https://glenwing.github.io/docs/VESA-EEDID-A2.pdf
+ *
+ * \param xRes horizontal resolution of the virtual display
+ * \param yRes vertical resolution of the virtual display
+ * \return A Edid where the Preferred Timing Mode has the given resolution
+ */
+template <typename EDID>
+static inline EDID prepareEdid(uint32_t xRes, uint32_t yRes, uint32_t extensionBlockCount = 0)
+{
+    EDID edid;
+
+    edid.standardTimings[0] = {1920, EdidStandardTiming::AR_16_10, 60}; // 1920x1200, 60hz
+    edid.standardTimings[1] = {1920, EdidStandardTiming::AR_16_9, 60};  // 1920x1080, 60hz
+    edid.standardTimings[2] = {1680, EdidStandardTiming::AR_16_10, 60}; // 1680x1050, 60hz
+    edid.standardTimings[3] = {1600, EdidStandardTiming::AR_16_9, 60};  // 1600x900, 60hz
+    edid.standardTimings[4] = {1600, EdidStandardTiming::AR_4_3, 60};   // 1600x1200, 60hz
+    edid.standardTimings[5] = {1024, EdidStandardTiming::AR_4_3, 60};   // 1024x768, 60hz
+    edid.standardTimings[6] = {800, EdidStandardTiming::AR_4_3, 60};    // 800x600, 60hz
+    edid.standardTimings[7] = {640, EdidStandardTiming::AR_4_3, 60};    // 640x480, 60hz
+
+    const uint32_t hblank =
+        ((edid.preferredTimingMode.hVideoBlankingHigh & 0x0f) << 8) | edid.preferredTimingMode.hBlankingLow;
+    const uint32_t vblank =
+        ((edid.preferredTimingMode.vVideoBlankingHigh & 0x0f) << 8) | edid.preferredTimingMode.vVBlankingLow;
+    const uint8_t refresh_rate = 60;
+    uint16_t clock = (xRes + hblank) * (yRes + vblank) * refresh_rate / 10000;
+
+    edid.preferredTimingMode.pixelClock = clock;
+
+    edid.preferredTimingMode.hVideoLow = xRes & 0xff;
+    edid.preferredTimingMode.hVideoBlankingHigh &= 0xf;
+    edid.preferredTimingMode.hVideoBlankingHigh |= (xRes >> 4) & 0xf0;
+
+    edid.preferredTimingMode.vVideoLow = yRes & 0xff;
+    edid.preferredTimingMode.vVideoBlankingHigh &= 0xf;
+    edid.preferredTimingMode.vVideoBlankingHigh |= (yRes >> 4) & 0xf0;
+
+    edid.displayDescriptors[0].tag = EdidDisplayDescriptorDefinitions::DisplayRangeLimits;
+    edid.displayDescriptors[0].rangeLimitOffset = 0x0;
+    edid.displayDescriptors[0].rangeLimitsTimingDescriptor.minimumVerticalRate = 0x18;
+    edid.displayDescriptors[0].rangeLimitsTimingDescriptor.maximumVerticalRate = 0x3c;
+    edid.displayDescriptors[0].rangeLimitsTimingDescriptor.minimumHorizontalRate = 0x18;
+    edid.displayDescriptors[0].rangeLimitsTimingDescriptor.maximumHorizontalRate = 0x50;
+    edid.displayDescriptors[0].rangeLimitsTimingDescriptor.maximumPixelClock = 0x11;
+    edid.displayDescriptors[0].rangeLimitsTimingDescriptor.videoTimingSupportFlags = 0x0;
+    edid.displayDescriptors[0].rangeLimitsTimingDescriptor.videoTimingDataOrLineFeed = 0x0a;
+    std::memset(&edid.displayDescriptors[0].rangeLimitsTimingDescriptor.videoTimingDataOrSpace, 0x20,
+                sizeof(edid.displayDescriptors[0].rangeLimitsTimingDescriptor.videoTimingDataOrSpace));
+
+    edid.displayDescriptors[1].tag = EdidDisplayDescriptorDefinitions::DisplayProductName;
+
+    edid.displayDescriptors[2].tag = EdidDisplayDescriptorDefinitions::DisplaySerialNumber;
+    /* The EDID requires a different serial number on change, thus we add the x Resolution to the serial number. */
+    std::string serialNumber = "Cyberus " + std::to_string(xRes);
+    std::strncpy(&edid.displayDescriptors[2].serialNumber[0], serialNumber.c_str(),
+                 std::min(serialNumber.length(), sizeof(edid.displayDescriptors[2].serialNumber)));
+
+    edid.extensionBlockCount = extensionBlockCount;
+
+    const uint8_t edidChecksumIndex {offsetof(EdidBaseBlock, checksum)};
+    auto edidPtr {reinterpret_cast<uint8_t*>(&edid)};
+    auto sum {std::accumulate(edidPtr, edidPtr + edidChecksumIndex, 0)};
+    edid.checksum = (0x100 - (sum & 0xff)) & 0xff;
+
+    return edid;
+}
+
+static inline std::array<uint8_t, EDID_LENGTH> generateEdid(uint32_t xRes, uint32_t yRes)
+{
+    auto edid {prepareEdid<EdidBaseBlock>(xRes, yRes)};
+
+    std::array<uint8_t, sizeof(edid)> array;
+    std::memcpy(array.data(), &edid, array.size());
+
+    return array;
+}
+
+static inline CEAExtendedEdid generateExtendedEdid(uint32_t xRes, uint32_t yRes)
+{
+    CEAExtendedEdid edid {prepareEdid<CEAExtendedEdid>(xRes, yRes, 1)};
+
+    uint8_t timingCount {0};
+
+    /*
+     * All timings that can be used in Short Video Descriptors are defined
+     * in (Table 3: Video Formats CEA-861-G Specifications) indexed by their Video ID Code (VIC)
+     */
+    auto add_timing = [&timingCount, &edid](const uint8_t vic, const bool native = false) {
+        /*
+         * The Video Data Block is able to support up to 0x1
+         */
+        if (timingCount <= CEAVideoDataBlock::MAX_SHORT_VIDEO_DESCRIPTORS) {
+            /*
+             * For timings with VIC < 65 a native indicator can be set (Refer Section 7.2.3 CEA 861-F Spec.)
+             * This requires a special handling.
+             */
+            if (vic < 65 and native) {
+                edid.videoDataBlock.shortVideoDescriptors[timingCount++] = (1 << 7) | (vic & 0x7f);
+            } else {
+                edid.videoDataBlock.shortVideoDescriptors[timingCount++] = vic;
+            }
+        }
+    };
+
+    /*
+     * The VIC numbers taken from (Table 3: Video Formats CEA 861-G Specification)
+     *
+     * A Native resolution basically means the displays standard resolution
+     */
+    add_timing(5, true); // 1920x1080, 60hz
+    add_timing(90);      // 2560x1080, 60hz
+    add_timing(97);      // 3840x2160, 60hz
+
+    edid.videoDataBlock.tagAndLength =
+        CEADataBlockHeader::DataBlockTagCode::Video | (timingCount & CEADataBlockHeader::LENGTH_MASK);
+    edid.eiaCeaDetailedTimingDescriptorOffset = 4 + sizeof(CEAVideoDataBlock);
+    const uint8_t checksumIndex {sizeof(CEAExtendedEdid) - sizeof(EdidBaseBlock) - 1};
+    auto edidPtr {reinterpret_cast<uint8_t*>(&edid) + sizeof(EdidBaseBlock)};
+    auto sum {std::accumulate(edidPtr, edidPtr + checksumIndex, 0)};
+    edid.eiaCeaChecksum = (0x100 - (sum & 0xff)) & 0xff;
+
+    return edid;
+}
diff --git a/include/cyberus/pci.h b/include/cyberus/pci.h
new file mode 100644
index 0000000..9a020b6
--- /dev/null
+++ b/include/cyberus/pci.h
@@ -0,0 +1,444 @@
+#pragma once
+
+#include <VBox/pci.h>
+#include <VBox/vmm/pdmdev.h>
+#include <VBox/vmm/pdmpcidev.h>
+
+#include <algorithm>
+#include <cassert>
+#include <iterator>
+#include <limits>
+#include <optional>
+#include <type_traits>
+
+typedef struct PCIBarRegion
+{
+    static_assert(std::is_same<IOMMMIOHANDLE, IOMIOPORTHANDLE>::value,
+                  "IOMMMIOHANDLE and IOMIOPORTHANDLE have different types now please extend this struct for the "
+                  "support of both!");
+    IOMMMIOHANDLE hRegion;
+    uint8_t iRegion;  ///< The bar index e.G Bar0.
+    uint64_t offset;  ///< The bar offset into the vfio device.
+    uint64_t size;    ///< The size of the bar.
+    RTGCPHYS address; ///< Base address of the bar.
+} PCIBARREGION;
+
+typedef PCIBARREGION* PPCIBARREGION;
+
+class PCIBar
+{
+public:
+    PCIBar() = delete;
+
+    PCIBar(uint64_t value_) : value(value_)
+    {
+        if (not is64BitBar()) {
+            value &= std::numeric_limits<uint32_t>::max();
+        }
+    }
+
+    bool isIoBar() const { return (value & PCI_BAR_TYPE_MASK) == PCI_ADDRESS_SPACE_IO; }
+    bool isMmioBar() const { return (value & PCI_BAR_TYPE_MASK) == PCI_ADDRESS_SPACE_MEM; }
+    bool is64BitBar() const { return (value & PCI_BAR_ADDRESS_MASK) == PCI_ADDRESS_SPACE_BAR64; }
+
+    uint64_t getBarAddress() const
+    {
+        if (isIoBar()) {
+            return value & ~PCI_CFG_IO_FLAGS_MASK;
+        } else if (isMmioBar()) {
+            return value & ~PCI_CFG_MMIO_FLAGS_MASK;
+        }
+
+        return 0;
+    }
+
+private:
+    static constexpr uint64_t PCI_CFG_IO_FLAGS_MASK {0x3};
+    static constexpr uint64_t PCI_CFG_MMIO_FLAGS_MASK {0xf};
+    static constexpr uint64_t PCI_BAR_TYPE_MASK {0x1};
+    static constexpr uint64_t PCI_BAR_ADDRESS_MASK {0x4};
+
+    uint64_t value;
+};
+
+/**
+ * Describes the generic part of a capability descriptor.
+ */
+struct __attribute__((__packed__)) CapabilityDescriptor
+{
+    uint8_t capID {0};
+    uint8_t nextPtr {0};
+};
+static_assert(sizeof(CapabilityDescriptor) == 0x2,
+              "The Capability Descriptor has incorrect size, did you forgot __attribute__ ((__packed__))");
+
+/*
+ * Read a specified type from the pci configuration space.
+ *
+ * \param offset offset into the pci configuration space
+ * \param readFn The function that should be used to read from the pci
+ *         configuration space.
+ *
+ * \return An object of the by template parameter specified type
+ */
+template <typename T>
+T readType(PPDMDEVINS pDevIns, uint32_t offset, PFNPCICONFIGREAD readFn)
+{
+    T t;
+
+    char* ptr {reinterpret_cast<char*>(&t)};
+
+    // TODO: can be optimized to minimize cfg space read accesses as we could read 4 bytes at once
+    for (size_t i = 0; i < sizeof(T); i++) {
+        uint8_t data;
+        readFn(pDevIns, nullptr, offset + i, 1u, reinterpret_cast<uint32_t*>(&data));
+        memcpy(ptr + i, &data, sizeof(data));
+    }
+
+    return t;
+}
+
+/*
+ * The pci configuration space capability list abstraction
+ *
+ * The abstraction makes an easy iteration of capabilities in the pci config space possible
+ * Additionally, a conversion from the basic CapabilityDescriptor to a special capability is possible
+ */
+class CapabilityList
+{
+public:
+    class CapabilityIterator
+    {
+    public:
+        using iterator_category = std::input_iterator_tag;
+        using value_type = CapabilityDescriptor;
+        using difference_type = size_t;
+        using pointer = CapabilityDescriptor*;
+        using reference = CapabilityDescriptor&;
+
+        CapabilityIterator(uint32_t capListPtr, PFNPCICONFIGREAD readFn_, PPDMDEVINS pDevIns_)
+            : offset(capListPtr), pDevIns(pDevIns_), readFn(readFn_)
+        {}
+
+        CapabilityIterator(const CapabilityIterator& o) : offset(o.offset), pDevIns(o.pDevIns), readFn(o.readFn) {}
+
+        value_type operator*() const
+        {
+            assert(offset);
+            return readType<CapabilityDescriptor>(pDevIns, offset, readFn);
+        }
+
+        CapabilityIterator& operator++()
+        {
+            assert(offset);
+            static constexpr uint32_t CAP_PTR_MASK {0x3};
+            auto capDescriptor {readType<CapabilityDescriptor>(pDevIns, offset, readFn)};
+            offset = capDescriptor.nextPtr & (~CAP_PTR_MASK);
+            return *this;
+        }
+
+        bool operator==(const CapabilityIterator& o) const { return offset == o.offset and readFn == o.readFn; }
+
+        bool operator!=(const CapabilityIterator& o) const { return not operator==(o); }
+
+        template <typename T>
+        T getCapability() const
+        {
+            assert(offset);
+            return readType<T>(pDevIns, offset, readFn);
+        }
+
+        uint32_t getOffset() const { return offset; }
+
+    private:
+        uint32_t offset;
+        PPDMDEVINS pDevIns;
+        PFNPCICONFIGREAD readFn;
+    };
+
+    CapabilityList(PFNPCICONFIGREAD readFn_, PPDMDEVINS pDevIns_ = nullptr) : pDevIns(pDevIns_), readFn(readFn_)
+    {
+        if (enabled()) {
+            readFn(pDevIns, nullptr, VBOX_PCI_CAPABILITY_LIST, PCI_CAPABILITY_LIST_PTR_SIZE, &capListPtr);
+        }
+    }
+
+    /**
+     * The function checks if the PCI device has support for capabilities
+     *
+     * \param pciStatus The value of the status register of the pci config space.
+     */
+    bool enabled()
+    {
+        static constexpr uint32_t PCI_STATUS_REGISTER_SIZE {0x2};
+        uint32_t pciStatus {0};
+
+        auto rc {readFn(pDevIns, nullptr, VBOX_PCI_STATUS, PCI_STATUS_REGISTER_SIZE, &pciStatus)};
+
+        return RT_SUCCESS(rc) ? (pciStatus & VBOX_PCI_STATUS_CAP_LIST) : false;
+    }
+
+    CapabilityIterator begin() { return {capListPtr, readFn, pDevIns}; }
+    CapabilityIterator end() { return {0x0, readFn, pDevIns}; }
+
+    std::optional<CapabilityIterator> getCapabilityIterator(uint8_t capId)
+    {
+        if (not enabled()) {
+            return std::nullopt;
+        }
+        auto it {std::find_if(begin(), end(), [capId](CapabilityDescriptor desc) { return desc.capID == capId; })};
+
+        if (it != end()) {
+            return it;
+        }
+
+        return std::nullopt;
+    }
+
+private:
+    static constexpr uint8_t PCI_CAPABILITY_LIST_PTR_SIZE {sizeof(uint8_t)};
+    PPDMDEVINS pDevIns;
+    PFNPCICONFIGREAD readFn;
+    uint32_t capListPtr {0x0};
+};
+
+/**
+ * MSI capability descriptor  based on the PCI Local Bus Specification REV 3.0
+ */
+class __attribute__((__packed__)) MSICapabilityDescriptor : public CapabilityDescriptor
+{
+private:
+    using CapabilityIterator = CapabilityList::CapabilityIterator;
+
+    uint16_t msgControl {0};
+    uint32_t msgAddress {0};
+
+    union __attribute__((__packed__))
+    {
+        uint16_t msgData32Bit;
+        struct
+        {
+            uint32_t msgAddressHigh;
+            uint16_t msgData;
+        } msi64bit;
+        struct
+        {
+            uint16_t msgData;
+            uint16_t reserved;
+            uint32_t maskBits;
+            uint32_t pendingBits;
+        } msiPerVectorMasking;
+        struct
+        {
+            uint32_t msgAddressHigh;
+            uint16_t msgData;
+            uint16_t reserved;
+            uint32_t maskBits;
+            uint32_t pendingBits;
+        } msi64BitPerVectorMasking {0, 0, 0, 0, 0};
+    };
+
+public:
+    MSICapabilityDescriptor() = default;
+    // We possibly read too much data here, if no all features of the MSI subsystem are supported.
+    // We accept this and treat the feature variables that are not activated in msgControl as garbage
+    MSICapabilityDescriptor(const CapabilityIterator& iterator)
+        : MSICapabilityDescriptor(iterator.getCapability<MSICapabilityDescriptor>())
+    {}
+
+    MSICapabilityDescriptor(const MSICapabilityDescriptor& o)
+        : msgControl(o.msgControl), msgAddress(o.msgAddress), msi64BitPerVectorMasking(o.msi64BitPerVectorMasking)
+    {}
+
+    bool enabled() const { return msgControl & VBOX_PCI_MSI_FLAGS_ENABLE; }
+
+    bool isPerVectorMaskable() const { return msgControl & VBOX_PCI_MSI_FLAGS_MASKBIT; }
+
+    bool is64Bit() const { return msgControl & VBOX_PCI_MSI_FLAGS_64BIT; }
+
+    uint8_t maxCount() const
+    {
+        static constexpr uint8_t PCI_MSI_FLAGS_QMASK_SHIFT {1u};
+        return 1 << ((msgControl & VBOX_PCI_MSI_FLAGS_QMASK) >> PCI_MSI_FLAGS_QMASK_SHIFT);
+    }
+
+    uint8_t count() const
+    {
+        static constexpr uint8_t PCI_MSI_FLAGS_QSIZE_SHIFT {4u};
+        return 1 << ((msgControl & VBOX_PCI_MSI_FLAGS_QSIZE) >> PCI_MSI_FLAGS_QSIZE_SHIFT);
+    }
+
+    uint64_t messageAddress() const
+    {
+        return is64Bit() ? static_cast<uint64_t>(msi64bit.msgAddressHigh) << 32 | msgAddress : msgAddress;
+    }
+
+    uint16_t messageData() const { return is64Bit() ? msi64bit.msgData : msgData32Bit; }
+
+    bool isMasked(uint32_t vector) const
+    {
+        if (not isPerVectorMaskable()) {
+            return false;
+        }
+
+        uint32_t maskBits {0};
+        if (is64Bit()) {
+            maskBits = msi64BitPerVectorMasking.maskBits;
+        } else {
+            maskBits = msiPerVectorMasking.maskBits;
+        }
+
+        return maskBits & (1u << vector);
+    }
+
+    std::optional<uint32_t> maskBitOffset() const
+    {
+        if (not isPerVectorMaskable()) {
+            return std::nullopt;
+        }
+
+        return is64Bit() ? 0x10 : 0xC;
+    }
+
+    std::optional<uint32_t> pendingBitOffset() const
+    {
+        if (not isPerVectorMaskable()) {
+            return std::nullopt;
+        }
+
+        return is64Bit() ? 0x14 : 0x10;
+    }
+};
+static_assert(sizeof(MSICapabilityDescriptor) == 0x18,
+              "The MSI Capability Descriptor has incorrect size, did you forgot __attribute__ ((__packed__))");
+
+/**
+ * MSIX capability descriptor  based on the PCI Local Bus Specification REV 3.0
+ */
+class __attribute__((__packed__)) MSIXCapabilityDescriptor : public CapabilityDescriptor
+{
+private:
+    using CapabilityIterator = CapabilityList::CapabilityIterator;
+
+    uint16_t msgControl {0};
+    uint32_t tableOffset {0};
+    uint32_t pendingBitArrayOffset {0};
+
+    static constexpr uint32_t MSIX_TABLE_OFFSET_MASK {~0x7u};
+
+public:
+    MSIXCapabilityDescriptor() = default;
+    MSIXCapabilityDescriptor(const MSIXCapabilityDescriptor& o)
+        : msgControl(o.msgControl), tableOffset(o.tableOffset), pendingBitArrayOffset(o.pendingBitArrayOffset)
+    {}
+
+    MSIXCapabilityDescriptor(const CapabilityIterator& iterator)
+        : MSIXCapabilityDescriptor(iterator.getCapability<MSIXCapabilityDescriptor>())
+    {}
+
+    bool enabled() const { return msgControl & VBOX_PCI_MSIX_FLAGS_ENABLE; }
+
+    bool allMasked() const { return msgControl & VBOX_PCI_MSIX_FLAGS_FUNCMASK; }
+
+    uint16_t tableSize() const
+    {
+        // According to the PCI Local Bus Specification REV 3.0
+        // the MSIX Table size is encoded as N-1  in the bits 0 to 10
+        // of message control, so we need to add 1 to
+        // get the actual table size.
+        static constexpr uint16_t MSIX_TABLE_SIZE_MASK {0x7ff};
+        return (msgControl & MSIX_TABLE_SIZE_MASK) + 1;
+    }
+
+    uint32_t getTableOffset() const { return tableOffset & MSIX_TABLE_OFFSET_MASK; }
+
+    uint32_t getBarIndex() const { return tableOffset & ~MSIX_TABLE_OFFSET_MASK; }
+};
+static_assert(sizeof(MSIXCapabilityDescriptor) == 0xc,
+              "The MSIX Capability Descriptor has incorrect size, did you forgot __attribute__ ((__packed__))");
+
+/**
+ * MSIX table entry based on the PCI Local Bus Specification REV 3.0
+ */
+class __attribute__((__packed__)) MSIXTableEntry
+{
+private:
+    uint32_t msgAddressLow {0};
+    uint32_t msgAddressHigh {0};
+    uint32_t msgData {0};
+    uint32_t vectorCtrl {0};
+
+public:
+    uint64_t messageAddress() const { return static_cast<uint64_t>(msgAddressHigh) << 32 | msgAddressLow; }
+
+    uint32_t messageData() const { return msgData; }
+};
+static_assert(sizeof(MSIXTableEntry) == 0x10,
+              "The MSIX Capability Descriptor has incorrect size, did you forgot __attribute__ ((__packed__))");
+
+/**
+ * This Function writes data to the PCI configuration space of VirtualBox
+ * The function is required for pass through or semi emulated devices to handle pci capabilities such as
+ * MSI support by VirtualBox.
+ *
+ * /param pPciDev The PCI device to which PCI configuration space should be written.
+ * /param offset the Offset into the Configuration Space. Refer to PCI Local Bus Specification REV 3.0 Figure 6-1 for an
+ * overview, /param cb The byte count to write, /param value The Value to write.
+ */
+inline void writePciConfigSpaceShadow(PPDMPCIDEV pPciDev, uint32_t offset, unsigned cb, uint64_t value)
+{
+    if (pPciDev) {
+        switch (cb) {
+        case sizeof(uint8_t): PDMPciDevSetByte(pPciDev, offset, value); break;
+        case sizeof(uint16_t): PDMPciDevSetWord(pPciDev, offset, value); break;
+        case sizeof(uint32_t): PDMPciDevSetDWord(pPciDev, offset, value); break;
+        case sizeof(uint64_t): PDMPciDevSetQWord(pPciDev, offset, value); break;
+        default:
+            AssertLogRelMsgFailed(("SuperNova-PCI: Could not write PCI Config Space Shadow due to an unsupported byte "
+                                   "count of %u bytes.\n",
+                                   cb));
+        };
+    }
+}
+
+/**
+ * Register the MSI(X) system for the pass through pci device in the VirtualBox PCI Subsystem.
+ *
+ * /param pDevIns The VirtualBox PCI Device instance data
+ * /param msiCapabilityIterator The MSI Capability iterator of the pci device.
+ * /param msixCapabilityIterator The MSIX Capability iterator of the pci device.
+ */
+
+inline int registerMsi(PPDMDEVINS pDevIns, std::optional<CapabilityList::CapabilityIterator> msiCapabilityIterator,
+                       std::optional<CapabilityList::CapabilityIterator> msixCapabilityIterator)
+{
+    PDMMSIREG msiReg;
+    RT_ZERO(msiReg);
+
+    if (msiCapabilityIterator) {
+        MSICapabilityDescriptor msiCap {*msiCapabilityIterator};
+
+        msiReg.cMsiVectors = msiCap.maxCount();
+        msiReg.iMsiCapOffset = msiCapabilityIterator->getOffset();
+        msiReg.iMsiNextOffset = msiCap.nextPtr;
+        msiReg.fMsi64bit = msiCap.is64Bit();
+        msiReg.fMsiNoMasking = not msiCap.isPerVectorMaskable();
+    }
+
+    if (msixCapabilityIterator) {
+        MSIXCapabilityDescriptor msixCap {*msiCapabilityIterator};
+        msiReg.cMsixVectors = msixCap.tableSize();
+        msiReg.iMsixCapOffset = msixCapabilityIterator->getOffset();
+        msiReg.iMsixNextOffset = msixCap.nextPtr;
+        msiReg.iMsixBar = msixCap.getBarIndex();
+    }
+
+    if (msiCapabilityIterator or msixCapabilityIterator) {
+        return PDMDevHlpPCIRegisterMsi(pDevIns, &msiReg);
+    }
+
+    /*
+     * If we end up here, the device either do not support MSI or MSIX or the Device Capabilitys are not present.
+     */
+    return VINF_SUCCESS;
+}
diff --git a/include/iprt/mangling.h b/include/iprt/mangling.h
index 0c8c027..7b27bba 100644
--- a/include/iprt/mangling.h
+++ b/include/iprt/mangling.h
@@ -2555,6 +2555,7 @@
 # define RTThreadIsSelfKnown                            RT_MANGLER(RTThreadIsSelfKnown)
 # define RTThreadNativeSelf                             RT_MANGLER(RTThreadNativeSelf)
 # define RTThreadControlPokeSignal                      RT_MANGLER(RTThreadControlPokeSignal) /* not-win not-os2 */
+# define RTThreadPokeSignal                             RT_MANGLER(RTThreadPokeSignal) /* not-win not-os2 */
 # define RTThreadPoke                                   RT_MANGLER(RTThreadPoke) /* not-win not-os2 */
 # define RTThreadPreemptDisable                         RT_MANGLER(RTThreadPreemptDisable)     /* r0drv */
 # define RTThreadPreemptIsEnabled                       RT_MANGLER(RTThreadPreemptIsEnabled)   /* r0drv */
diff --git a/include/iprt/thread.h b/include/iprt/thread.h
index 7d9257e..243d76d 100644
--- a/include/iprt/thread.h
+++ b/include/iprt/thread.h
@@ -555,6 +555,12 @@ RTDECL(int) RTThreadPoke(RTTHREAD hThread);
  */
 RTDECL(int) RTThreadControlPokeSignal(RTTHREAD hThread, bool fEnable);
 
+/**
+ * Returns the signal that is used to poke threads.
+ *
+ * @returns a signal number or -1.
+ */
+RTDECL(int) RTThreadPokeSignal(void);
 
 # ifdef IN_RING0
 
diff --git a/include/iprt/x86.h b/include/iprt/x86.h
index 95ab7b4..96c7d1b 100644
--- a/include/iprt/x86.h
+++ b/include/iprt/x86.h
@@ -667,6 +667,8 @@ typedef const X86CPUIDFEATEDX *PCX86CPUIDFEATEDX;
 #define X86_CPUID_STEXT_FEATURE_EBX_SMAP              RT_BIT_32(20)
 /** EBX Bit 23 - CLFLUSHOPT - Supports CLFLUSHOPT (Cache Line Flush). */
 #define X86_CPUID_STEXT_FEATURE_EBX_CLFLUSHOPT        RT_BIT_32(23)
+/** EBX Bit 24 - CLWB - Supports CLWB (Cache Line write-back). */
+#define X86_CPUID_STEXT_FEATURE_EBX_CLWB              RT_BIT_32(24)
 /** EBX Bit 25 - INTEL_PT - Supports Intel Processor Trace. */
 #define X86_CPUID_STEXT_FEATURE_EBX_INTEL_PT          RT_BIT_32(25)
 /** EBX Bit 26 - AVX512PF - Supports AVX512PF. */
@@ -686,6 +688,8 @@ typedef const X86CPUIDFEATEDX *PCX86CPUIDFEATEDX;
 #define X86_CPUID_STEXT_FEATURE_ECX_PKU               RT_BIT_32(3)
 /** ECX Bit 4 - OSPKE - Protection keys for user mode pages enabled. */
 #define X86_CPUID_STEXT_FEATURE_ECX_OSPKE             RT_BIT_32(4)
+/** ECX Bit 8 - GFNI - Supports Galois Field instructions . */
+#define X86_CPUID_STEXT_FEATURE_ECX_GFNI              RT_BIT_32(8)
 /** ECX Bits 17-21 - MAWAU - Value used by BNDLDX and BNDSTX. */
 #define X86_CPUID_STEXT_FEATURE_ECX_MAWAU             UINT32_C(0x003e0000)
 /** ECX Bit 22 - RDPID - Support pread process ID. */
@@ -693,8 +697,12 @@ typedef const X86CPUIDFEATEDX *PCX86CPUIDFEATEDX;
 /** ECX Bit 30 - SGX_LC - Supports SGX launch configuration. */
 #define X86_CPUID_STEXT_FEATURE_ECX_SGX_LC            RT_BIT_32(30)
 
+/** EDX Bit 4 - FSRM - Supports Fast Short REP MOVSB */
+#define X86_CPUID_STEXT_FEATURE_EDX_FSRM              RT_BIT(4)
 /** EDX Bit 10 - MD_CLEAR - Supports flushing MDS related buffers. */
 #define X86_CPUID_STEXT_FEATURE_EDX_MD_CLEAR          RT_BIT_32(10)
+/** EDX Bit 14 - SERIALIZE - Supports the SERIALIZE CPU instruction. */
+#define X86_CPUID_STEXT_FEATURE_EDX_SERIALIZE         RT_BIT_32(14)
 /** EDX Bit 26 - IBRS & IBPB - Supports the IBRS flag in IA32_SPEC_CTRL and
  *  IBPB command in IA32_PRED_CMD. */
 #define X86_CPUID_STEXT_FEATURE_EDX_IBRS_IBPB         RT_BIT_32(26)
diff --git a/src/VBox/Devices/Bus/DevVfio.cpp b/src/VBox/Devices/Bus/DevVfio.cpp
new file mode 100644
index 0000000..f93fcd7
--- /dev/null
+++ b/src/VBox/Devices/Bus/DevVfio.cpp
@@ -0,0 +1,154 @@
+/*
+ * Copyright (C) Cyberus Technology GmbH.
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <https://www.gnu.org/licenses/>.
+ *
+ * SPDX-License-Identifier: GPL-3.0-or-later
+ */
+
+#define LOG_GROUP LOG_GROUP_DEV_VFIO
+#include "DevVfio.h"
+
+#include <VBox/log.h>
+#include <VBox/vmm/mm.h>
+#include <VBox/vmm/pdmdev.h>
+
+#include <string>
+
+static DECLCALLBACK(int) devVfioConstruct(PPDMDEVINS pDevIns, int iInstance, PCFGMNODE pCfg)
+{
+    /*
+     * Check that the device instance and device helper structures are compatible.
+     */
+    PDMDEV_CHECK_VERSIONS_RETURN(pDevIns);
+
+    PVFIODEV pThis {PDMDEVINS_2_DATA(pDevIns, PVFIODEV)};
+    PCPDMDEVHLPR3 pHlp {pDevIns->pHlpR3};
+    int rc;
+    uint16_t bus, device, function;
+    char* sysfsPath;
+
+    constexpr char validation[] = "sysfsPath"
+                                  "|GuestPCIBusNo"
+                                  "|GuestPCIDeviceNo"
+                                  "|GuestPCIFunctionNo";
+
+    PDMDEV_VALIDATE_CONFIG_RETURN(pDevIns, validation, "Invalid configuration");
+    rc = pHlp->pfnCFGMQueryStringAlloc(pCfg, "sysfsPath", &sysfsPath);
+    if (RT_FAILURE(rc))
+    {
+        return PDMDEV_SET_ERROR(pDevIns, rc, N_("Configuration error: Querying sysfsPath as a string failed"));
+    }
+
+    std::string sysfsPathString {sysfsPath};
+    MMR3HeapFree(sysfsPath);
+
+    rc = pHlp->pfnCFGMQueryU16(pCfg, "GuestPCIBusNo", &bus);
+    if (RT_FAILURE(rc))
+    {
+        return PDMDEV_SET_ERROR(pDevIns, rc, N_("Configuration error: Querying GuestPCIBusNo as a uint16_t failed"));
+    }
+
+    rc = pHlp->pfnCFGMQueryU16(pCfg, "GuestPCIDeviceNo", &device);
+    if (RT_FAILURE(rc))
+    {
+        return PDMDEV_SET_ERROR(pDevIns, rc, N_("Configuration error: Querying GuestPCIDeviceNo as a uint16_t failed"));
+    }
+
+    rc = pHlp->pfnCFGMQueryU16(pCfg, "GuestPCIFunctionNo", &function);
+    if (RT_FAILURE(rc))
+    {
+        return PDMDEV_SET_ERROR(pDevIns, rc, N_("Configuration error: Querying GuestPCIFunctionNo as a uint16_t failed"));
+    }
+
+    LogRel(("VFIO: Constructing VFIO PCI device with path %s Guest BDF: %02hx:%02hx.%hx\n",
+            sysfsPathString.c_str(), bus, device, function));
+
+    rc = pThis->init(pDevIns, sysfsPathString);
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+
+    NOREF(iInstance);
+
+    return VINF_SUCCESS;
+}
+
+static DECLCALLBACK(int) devVfioDestruct(PPDMDEVINS pDevIns)
+{
+    /*
+     * Check the versions here as well since the destructor is *always* called.
+     */
+    PDMDEV_CHECK_VERSIONS_RETURN_QUIET(pDevIns);
+
+    PVFIODEV pThis {PDMDEVINS_2_DATA(pDevIns, PVFIODEV)};
+
+    pThis->terminate(pDevIns);
+
+    return VINF_SUCCESS;
+}
+
+static DECLCALLBACK(int) devVfioInitComplete(PPDMDEVINS pDevIns)
+{
+    PDMDEV_CHECK_VERSIONS_RETURN_QUIET(pDevIns);
+
+    PVFIODEV pThis {PDMDEVINS_2_DATA(pDevIns, PVFIODEV)};
+
+    return pThis->initializeDma(pDevIns);
+}
+
+/**
+ * The device registration structure.
+ */
+extern "C" const PDMDEVREG g_DeviceVfioDev =
+{
+    /* .u32Version = */             PDM_DEVREG_VERSION,
+    /* .uReserved0 = */             0,
+    /* .szName = */                 "VfioDev",
+    /* .fFlags = */                 PDM_DEVREG_FLAGS_DEFAULT_BITS | PDM_DEVREG_FLAGS_NEW_STYLE,
+
+    /* .fClass = */                 PDM_DEVREG_CLASS_HOST_DEV,
+    /* .cMaxInstances = */          1,
+    /* .uSharedVersion = */         1,
+    /* .cbInstanceShared = */       sizeof(VFIODEV),
+    /* .cbInstanceR0 = */           0,
+    /* .cbInstanceRC = */           0,
+    /* .cMaxPciDevices = */         1,
+    /* .cMaxMsixVectors = */        0,
+    /* .pszDescription = */         "VirtualBox Vfio Passthrough Device\n",
+    /* .pszRCMod = */               "",
+    /* .pszR0Mod = */               "",
+    /* .pfnConstruct = */           devVfioConstruct,
+    /* .pfnDestruct = */            devVfioDestruct,
+    /* .pfnRelocate = */            NULL,
+    /* .pfnMemSetup = */            NULL,
+    /* .pfnPowerOn = */             NULL,
+    /* .pfnReset = */               NULL,
+    /* .pfnSuspend = */             NULL,
+    /* .pfnResume = */              NULL,
+    /* .pfnAttach = */              NULL,
+    /* .pfnDetach = */              NULL,
+    /* .pfnQueryInterface. = */     NULL,
+    /* .pfnInitComplete = */        devVfioInitComplete,
+    /* .pfnPowerOff = */            NULL,
+    /* .pfnSoftReset = */           NULL,
+    /* .pfnReserved0 = */           NULL,
+    /* .pfnReserved1 = */           NULL,
+    /* .pfnReserved2 = */           NULL,
+    /* .pfnReserved3 = */           NULL,
+    /* .pfnReserved4 = */           NULL,
+    /* .pfnReserved5 = */           NULL,
+    /* .pfnReserved6 = */           NULL,
+    /* .pfnReserved7 = */           NULL,
+    /* .u32VersionEnd = */          PDM_DEVREG_VERSION
+};
diff --git a/src/VBox/Devices/Bus/DevVfio.h b/src/VBox/Devices/Bus/DevVfio.h
new file mode 100644
index 0000000..d6bfb0a
--- /dev/null
+++ b/src/VBox/Devices/Bus/DevVfio.h
@@ -0,0 +1,412 @@
+/*
+ * Copyright (C) Cyberus Technology GmbH.
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <https://www.gnu.org/licenses/>.
+ *
+ * SPDX-License-Identifier: GPL-3.0-or-later
+ */
+
+#pragma once
+
+#include <cyberus/pci.h>
+
+#include <VBox/err.h>
+#include <VBox/pci.h>
+#include <VBox/vmm/pdmdev.h>
+
+#include <linux/vfio.h>
+#include <sys/ioctl.h>
+#include <unistd.h>
+
+#include <array>
+#include <atomic>
+#include <filesystem>
+#include <mutex>
+#include <vector>
+
+class VfioDevice
+{
+public:
+    /*
+     * The IRQ Type information, required for the interrupt handler.
+     */
+    enum class IrqType
+    {
+        VFIO_INTX = VFIO_PCI_INTX_IRQ_INDEX,
+        VFIO_MSI  = VFIO_PCI_MSI_IRQ_INDEX,
+        VFIO_MSIX = VFIO_PCI_MSIX_IRQ_INDEX,
+        VFIO_NONE,
+    };
+
+    /**
+     * Interrupt Handler function
+     *
+     * \param pDevIns The PCI Device Instance
+     *
+     * \return VBox status code
+     */
+    int handleInterrupts(PPDMDEVINS pDevIns);
+
+    /**
+     * Initialize the VfioDevice
+     *
+     * \param pDevIns The PCI Device Instance
+     *
+     * \return VBox status code
+     */
+    int init(PPDMDEVINS pDevIns, std::filesystem::path sysfsPath);
+
+    /**
+     * Initialize DMA
+     * As the ram preallocation is required to initialize the DMA regions for the
+     * VFIO device, the function have to be called **after** pgmR3RamPreAlloc
+     *
+     * \param pDevIns The PCI Device Instance
+     *
+     * \return VBox status code
+     */
+    int initializeDma(PPDMDEVINS pDevIns);
+
+    /**
+     *  Terminates the VFIO device and closes the file descriptors
+     *
+     *  \param pDevIns The PCI Device Instance
+     *
+     *  \return VBox status code
+     */
+    int terminate(PPDMDEVINS pDevIns);
+
+    /**
+     * Read from the Vfio Device file descriptor
+     *
+     * \param pData data to read
+     * \param bytes count of bytes to read
+     * \param uAddress address to read from
+     *
+     * \return VBOX status code
+     */
+    int readFromDevice(void* pData, unsigned bytes, uint64_t uAddress)
+    {
+        return handleDeviceAccess(pread64, pData, bytes, uAddress);
+    }
+
+    /**
+     * Write to the Vfio Device file descriptor
+     *
+     * \param pData data to write
+     * \param bytes count of bytes to write
+     * \param uAddress address to write to
+     *
+     * \return VBOX status code
+     */
+    int writeToDevice(const void* pData, unsigned bytes, uint64_t uAddress)
+    {
+        return handleDeviceAccess(pwrite64, const_cast<void*>(pData), bytes, uAddress);
+    }
+
+    /**
+     * Read from the actual PCI Config Space of the VFIO device
+     *
+     * \param data data to read
+     * \param bytes count of bytes to read
+     * \param uAddress address to read from
+     *
+     * \return VBOX status code
+     */
+    template <typename T>
+    int readConfigSpace(T& data, unsigned bytes, uint64_t uAddress)
+    {
+        return readFromDevice(&data, bytes, mcfgOffset + uAddress);
+    }
+
+    /**
+     * Write to the actual PCI Config Space of the VFIO device
+     *
+     * \param data data to write
+     * \param bytes count of bytes to write
+     * \param uAddress address to write to
+     *
+     * \return VBOX status code
+     */
+    template <typename T>
+    int writeConfigSpace(T& data, unsigned bytes, uint64_t uAddress)
+    {
+        return writeToDevice(&data, bytes, mcfgOffset + uAddress);
+    }
+
+private:
+    using LockGuard = std::lock_guard<std::mutex>;
+
+    /**
+     * The interrupt information structure is a bookkeeping structure for the
+     * interrupt handling.
+     * It maps the interrupt event file descriptor to an internal interrupt
+     * index and contains the interrupt type (INTX, MSI, MSIX) for the handler thread.
+     */
+    struct InterruptInformation
+    {
+        int fd;
+        uint32_t index;
+
+        bool operator==(const InterruptInformation& o) const
+        {
+            return o.fd == fd and o.index == index;
+        }
+    };
+
+    template<typename FN>
+    int handleDeviceAccess(FN& fn, void* data, unsigned bytes, uint64_t uAddress)
+    {
+        AssertLogRelMsgReturn(vfioDeviceFd > 0, ("The Vfio Device is not open \n"), VERR_GENERAL_FAILURE);
+        auto rc {fn(vfioDeviceFd, data, bytes, uAddress)};
+
+        return rc < 0 ? VERR_ACCESS_DENIED : VINF_SUCCESS;
+    }
+
+    /**
+     * Initialize VFIO container and device
+     *
+     * \param pDevIns The PCI Device Instance
+     * \param sysfsPath path to the sysfs device
+     *
+     * \return VBox status code
+     */
+    int initializeVfio(PPDMDEVINS pDevIns, std::filesystem::path sysfsPath);
+
+    /**
+     * Initialize the VirtualBox PCI Device Information
+     *
+     * \param pDevIns The PCI Device Instance
+     *
+     * \return VBox status code
+     */
+    int initializePci(PPDMDEVINS pDevIns);
+
+    /**
+     * Initialize VFIO Memory Regions
+     *
+     * Such regions are either PCI Bar regions or VFIO specific regions to
+     * provide device Information or device state such as graphics output
+     *
+     * \param pDevIns The PCI Instance Data
+     * \param deviceInfo The vfio device information
+     *
+     * \return VBox status code
+     */
+    int initializeMemoryRegions(PPDMDEVINS pDevIns, vfio_device_info& deviceInfo);
+
+    /**
+     * Initialize interrupt handling
+     *
+     * \param pDevIns The PCI Device Instance
+     *
+     * \return VBox status code
+     */
+    int initializeInterrupts(PPDMDEVINS pDevIns);
+
+    /**
+     * Activate the corresponding interrupt type. The current interrupt type must be disabled before.
+     *
+     * \param pDevIns The PCI Device Instance
+     * \param vfuiIrqIndexType the irq type that should be activated
+     * \param irqCount count of irqs to register
+     *
+     * \return VBox status code
+     */
+    int activateInterrupts(PPDMDEVINS pDevIns, const IrqType vfioIrqIndexType, uint32_t irqCount = 1);
+
+    /**
+     * Disable the corresponding interrupt type
+     *
+     * \param pDevIns The PCI Device Instance
+     *
+     * \return VBox status code
+     */
+    int disableInterrupts(PPDMDEVINS pDevIns);
+
+    /**
+     * Inject a MSI
+     *
+     * \param pDevIns The PCI Device Instance
+     * \param irqInfo The interrupt information of the pending interrupt
+     *
+     * \return VBOX status code
+     */
+    int injectMsi(PPDMDEVINS pDevIns, InterruptInformation& irqInfo);
+
+    /**
+     * Inject a MSIX
+     *
+     * \param pDevIns The PCI Device Instance
+     * \param irqInfo The interrupt information of the pending interrupt
+     *
+     * \return VBOX status code
+     */
+    int injectMsix(PPDMDEVINS pDevIns, InterruptInformation& irqInfo);
+
+    /**
+     * The configuration space write handler.
+     *
+     * \param pDevIns The PCI Device Instance
+     * \param uAddress offset in the configuration space to write
+     * \param cb count of bytes to write
+     * \param u32Value The value to write
+     *
+     * \return VBox status code
+     */
+    int configSpaceWriteHandler(PPDMDEVINS pDevIns, uint32_t uAddress, unsigned cb, uint32_t u32Value);
+
+    /**
+     * The memory mapped IO access handler function.
+     *
+     * \param pDevIns The PCI Device Instance
+     * \param barRegion The reference to the PCI Bar region
+     * \param barOffset The offset in the PCI bar
+     * \param pv The pointer to the data to be read
+     * \param cb The size of the data to be read
+     * \param write Indicator of access direction
+     *
+     * \return Vbox Status code
+     */
+    int mmioAccessHandler(PPDMDEVINS pDevIns, PCIBarRegion& barRegion, RTGCPHYS barOffset, void* pv, unsigned cb, bool writeAccess);
+
+    /**
+     * Start inteception of Guest VM PCI Config Space Accesses
+     *
+     * \param pDevIns the VBox Device Instance
+     *
+     * \return VBox status code
+     */
+    int interceptConfigSpaceAccesses(PPDMDEVINS pDevIns);
+
+    /**
+     * Register a Guest Physical Memory range at the vfio container
+     *
+     * \param pVM Pointer to the VM structure
+     * \param startGCPhys Guest physical address of the start of the ram range
+     * \param endGCPhys Guest physical address of the end of the region
+     *
+     * \return VBOX status code
+     */
+    int registerDmaRange(PVM pVM, RTGCPHYS startGCPhys, RTGCPHYS endGCPhys);
+
+    /**
+     * Try handling of PCI Bar interception
+     *
+     * \param pDevIns PDM Device Instance
+     * \param pciConfigCommandValue value of the command register of the PCI config space
+     */
+    void tryHandleBarInterception(PPDMDEVINS pDevIns, const uint32_t pciConfigCommandValue);
+
+    /**
+     * Register a PCI Bar at the corresponding subsystem (IO or MMIO).
+     *
+     * \param mapFn function used to map the Bar at the corrseponding Subsystem
+     * \param unmapFn function to unmap the old Bar region if the bar was present before
+     * \param pDevIns the PDM Device Instance Data structure
+     * \param barRegion the region bookkeeping data structure
+     * \param mapAddress the new address of the Bar
+     */
+    template <uint64_t INVALID_ELEM, typename MapFN, typename UnmapFN>
+    void registerPCIBar(MapFN& mapFn, UnmapFN& unmapFn, PPDMDEVINS pDevIns, PCIBarRegion& barRegion, uint64_t mapAddress) {
+        LogRel(("VFIO: RegisterBar %#llx \n", mapAddress));
+        if (barRegion.address == mapAddress)
+        {
+            return;
+        }
+
+        if (barRegion.address != INVALID_ELEM)
+        {
+            unmapFn(pDevIns, barRegion.hRegion);
+            barRegion.address = INVALID_ELEM;
+        }
+
+        mapFn(pDevIns, barRegion.hRegion, mapAddress);
+        barRegion.address = mapAddress;
+    }
+
+    /**
+    * Read the Bar value from the PCI config space
+    *
+    * \param barNumber The bar which value should be read
+    *
+    * \return PCIBar information
+    */
+    const PCIBar getBarInfo(unsigned barNumber);
+
+    /**
+     * Ioctl wrapper with meaningfull error return
+     * \param fd file descriptor to interact with
+     * \param request ioct request number
+     * \param errorStr string to set in the log in case of an error
+     * \param args variadic template args for the ioctl
+     *
+     * \return Vbox error code
+     */
+    template <typename ...ARGS>
+    int vfioControl(PPDMDEVINS pDevIns, int fd, unsigned long request, const char* errorString, ARGS&& ...args)
+    {
+        if (ioctl(fd, request, std::forward<ARGS>(args) ...) < 0)
+        {
+            return PDMDEV_SET_ERROR(pDevIns, VERR_INVALID_PARAMETER, errorString);
+        }
+
+        return VINF_SUCCESS;
+    }
+
+    /**
+     * Ioctl device wrapper for accesses on the vfio device file descriptor
+     *
+     * \param pDevIns the VBox Device Instance
+     * \param request ioct request number
+     * \param errorStr string to set in the log in case of an error
+     * \param args variadic template args for the ioctl
+     *
+     * \return VBOX status code
+     */
+    template <typename ...ARGS>
+    int deviceControl(PPDMDEVINS pDevIns, unsigned long request, const char* errorString, ARGS&& ...args)
+    {
+        AssertLogRelMsgReturn(vfioDeviceFd > 0, ("The Vfio Device is not open \n"), VERR_GENERAL_FAILURE);
+        return vfioControl(pDevIns, vfioDeviceFd, request, errorString, std::forward<ARGS>(args)...);
+    }
+
+    /** Vfio File descriptors */
+    int vfioContainerFd{-1};
+    int vfioGroupFd{-1};
+    int vfioDeviceFd {-1};
+
+    /** PCI device members. */
+    PPDMPCIDEV pPciDev;
+    uint64_t mcfgOffset; ///< The offset to the PCI Config Space Page in the vfio device
+    std::atomic<bool> pciConfigMemoryDecodingEnabled {false}; ///< The PCI Memory decoding indicator
+    std::atomic<bool> pciConfigIODecodingEnabled {false}; ///< The PCI IO decoding indicator
+    std::array<PCIBarRegion, VBOX_PCI_MAX_BARS> pciBars;
+
+    /** IRQ handling */
+    RTTHREAD hIrqDeliveryThread;
+    // Even if only one INTX interrupt is supported handling it as a vector reduce the code complexity by a lot.
+    std::vector<InterruptInformation> aIrqInformation;
+    std::vector<MSIXTableEntry> aMsixTable;
+    IrqType activeInterruptType {IrqType::VFIO_NONE};
+    std::mutex irqDisable;
+
+    std::optional<CapabilityList::CapabilityIterator> msiCapabilityIterator;
+    std::optional<CapabilityList::CapabilityIterator> msixCapabilityIterator;
+
+    std::atomic<bool> exit{false};
+};
+typedef VfioDevice VFIODEV;
+
+typedef VFIODEV *PVFIODEV;
diff --git a/src/VBox/Devices/Bus/VfioDevice.cpp b/src/VBox/Devices/Bus/VfioDevice.cpp
new file mode 100644
index 0000000..d8cf3ef
--- /dev/null
+++ b/src/VBox/Devices/Bus/VfioDevice.cpp
@@ -0,0 +1,910 @@
+/*
+ * Copyright (C) Cyberus Technology GmbH.
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <https://www.gnu.org/licenses/>.
+ *
+ * SPDX-License-Identifier: GPL-3.0-or-later
+ */
+
+#include "DevVfio.h"
+
+#include <iprt/mem.h>
+#include <VBox/log.h>
+#include <VBox/vmm/pgm.h>
+#include <VBox/vmm/pdmapi.h>
+#include <VBox/vmm/pdmdev.h>
+#include <VBox/vmm/pdmpcidevint.h>
+#include "DevPciInternal.h"
+
+#include <fcntl.h>
+#include <sys/eventfd.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+
+#include <cstring>
+#include <optional>
+
+namespace {
+    using IrqType = VfioDevice::IrqType;
+
+    VBOXSTRICTRC vfioConfigSpaceRead(PPDMDEVINS pDev, PPDMPCIDEV pPciDev, uint32_t uAddress, unsigned cb, uint32_t* pu32Value)
+    {
+        PVFIODEV pThis {PDMDEVINS_2_DATA(pDev, PVFIODEV)};
+
+        AssertLogRelMsgReturn(pu32Value, ("VFIO: PCi config space read: value pointer is zero!"), VERR_INVALID_POINTER);
+
+        int rc { pThis->readConfigSpace(*pu32Value, cb, uAddress) };
+        writePciConfigSpaceShadow(pPciDev, uAddress, cb, *pu32Value);
+        return rc;
+    }
+
+    std::underlying_type_t<IrqType> toUnderlying(const IrqType& t)
+    {
+        return static_cast<std::underlying_type_t<IrqType>>(t);
+    }
+
+}
+
+int VfioDevice::initializeVfio(PPDMDEVINS pDevIns, std::filesystem::path sysfsPath)
+{
+    namespace fs = std::filesystem;
+    const std::filesystem::path VFIO_PATH {"/dev/vfio"};
+
+    int rc {VINF_SUCCESS};
+
+    vfioContainerFd = open((VFIO_PATH / "vfio").c_str(), O_RDWR | O_CLOEXEC);
+    AssertLogRelMsgReturn(vfioContainerFd > 0, ("VFIO: Could not open VFIO Container\n"), VERR_INVALID_PARAMETER);
+
+    const int vfioApiVersion {ioctl(vfioContainerFd, VFIO_GET_API_VERSION)};
+
+    LogRel(("VFIO: Detected VFIO Api Version %d\n", vfioApiVersion));
+
+    const int iommuTypePresent {ioctl(vfioContainerFd, VFIO_CHECK_EXTENSION, VFIO_TYPE1_IOMMU)};
+    AssertLogRelMsgReturn(iommuTypePresent, ("VFIO: Requested IOMMU type is not supported.\n"), VERR_NOT_AVAILABLE);
+
+    const auto iommuGroupLink {fs::read_symlink(sysfsPath / "iommu_group")};
+    vfioGroupFd = open((VFIO_PATH / iommuGroupLink.filename()).c_str(), O_RDWR, O_CLOEXEC);
+    AssertLogRelMsgReturn(vfioGroupFd > 0, ("VFIO: Could not open VFIO Container\n"), VERR_INVALID_PARAMETER);
+
+    rc = vfioControl(pDevIns, vfioGroupFd, VFIO_GROUP_SET_CONTAINER,
+                    "VFIO: Unable to assign the VFIO container to the VFIO Group \n", &vfioContainerFd);
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    rc = vfioControl(pDevIns, vfioContainerFd, VFIO_SET_IOMMU, "VFIO: Unable to set VFIO IOMMU Type \n", VFIO_TYPE1_IOMMU);
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    vfioDeviceFd = ioctl(vfioGroupFd, VFIO_GROUP_GET_DEVICE_FD, sysfsPath.filename().c_str());
+    AssertLogRelMsgReturn(vfioDeviceFd > 0, ("VFIO: Unable to open VFIO device \n"), VERR_INVALID_PARAMETER);
+
+    rc = deviceControl(pDevIns, VFIO_DEVICE_RESET, "Unable to reset VFIO device");
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    return rc;
+}
+
+int VfioDevice::initializePci(PPDMDEVINS pDevIns)
+{
+    int rc {VINF_SUCCESS};
+
+    pPciDev = pDevIns->apPciDevs[0];
+    PDMPCIDEV_ASSERT_VALID(pDevIns, pPciDev);
+
+    vfio_region_info regionInfo;
+    regionInfo.argsz = sizeof(regionInfo);
+    regionInfo.index = VFIO_PCI_CONFIG_REGION_INDEX;
+
+    rc = deviceControl(pDevIns, VFIO_DEVICE_GET_REGION_INFO, "VFIO: Could not retrieve VFIO Device MCFG region\n", &regionInfo);
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+    AssertLogRelMsgReturn(regionInfo.size != 0, ("VFIO: MCFG Region size is zero\n"), VERR_INVALID_PARAMETER);
+
+    mcfgOffset = regionInfo.offset;
+
+    uint16_t vendorId, deviceId;
+    uint8_t classBase, classSub, headerType, interruptPin, interruptLine;
+
+    readConfigSpace(vendorId, sizeof(vendorId), VBOX_PCI_VENDOR_ID);
+    readConfigSpace(deviceId, sizeof(deviceId), VBOX_PCI_DEVICE_ID);
+    readConfigSpace(classBase, sizeof(classBase), VBOX_PCI_CLASS_BASE);
+    readConfigSpace(classSub, sizeof(classSub), VBOX_PCI_CLASS_SUB);
+    readConfigSpace(headerType, sizeof(headerType), VBOX_PCI_HEADER_TYPE);
+    readConfigSpace(interruptLine, sizeof(interruptLine), VBOX_PCI_INTERRUPT_LINE);
+    readConfigSpace(interruptPin, sizeof(interruptPin), VBOX_PCI_INTERRUPT_PIN);
+
+    PDMPciDevSetVendorId(pPciDev, vendorId);
+    PDMPciDevSetDeviceId(pPciDev, deviceId);
+    PDMPciDevSetClassBase(pPciDev, classBase);
+    PDMPciDevSetClassSub(pPciDev, classSub);
+    PDMPciDevSetHeaderType(pPciDev, headerType);
+    PDMPciDevSetInterruptLine(pPciDev, interruptLine);
+    PDMPciDevSetInterruptPin(pPciDev, interruptPin);
+
+    rc = PDMDevHlpPCIRegister(pDevIns, pPciDev);
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    CapabilityList capList {vfioConfigSpaceRead, pDevIns};
+    msiCapabilityIterator = capList.getCapabilityIterator(VBOX_PCI_CAP_ID_MSI);
+    msixCapabilityIterator = capList.getCapabilityIterator(VBOX_PCI_CAP_ID_MSIX);
+
+
+    if (msiCapabilityIterator)
+    {
+        MSICapabilityDescriptor msiCap {*msiCapabilityIterator};
+        AssertLogRelMsgReturn(msiCap.maxCount() == 1, ("VFIO: Multiple Message MSI supporting devices are not supported yet!\n"), VERR_NOT_SUPPORTED);
+    }
+
+
+    return rc;
+}
+
+int VfioDevice::initializeMemoryRegions(PPDMDEVINS pDevIns, vfio_device_info& deviceInfo)
+{
+    int rc {VINF_SUCCESS};
+    for (auto i {0u}; i < deviceInfo.num_regions; ++i)
+    {
+        /**
+         * Currently only PCI Bar regions are supported.
+         * VFIO places the bar region information at indices
+         * 0 <= i <= VBOX_PCI_MAX_BARS, so we can stop if the
+         * limit is reached
+         *
+         * TODO implement special region handling
+         */
+        if (i >= VBOX_PCI_MAX_BARS)
+        {
+            break;
+        }
+
+        vfio_region_info regionInfo;
+        regionInfo.argsz = sizeof(regionInfo);
+        regionInfo.index = i;
+
+        rc = deviceControl(pDevIns, VFIO_DEVICE_GET_REGION_INFO, "VFIO: Unable to retrieve VFIO region info",  &regionInfo);
+        AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+        if (regionInfo.size == 0)
+        {
+            continue;
+        }
+
+        const auto barInfo {getBarInfo(i)};
+
+        PCIBarRegion& region {pciBars[i]};
+        region.offset = regionInfo.offset;
+        region.size = regionInfo.size;
+        region.iRegion = i;
+
+        if (barInfo.isIoBar())
+        {
+            auto portIoRead = [](PPDMDEVINS pDev, void* pvUser , RTIOPORT offsetPort, uint32_t* pu32, unsigned cb) -> VBOXSTRICTRC
+            {
+                PVFIODEV pThis {PDMDEVINS_2_DATA(pDev, PVFIODEV)};
+                auto pBar {static_cast<PPCIBARREGION>(pvUser)};
+
+                AssertLogRelReturn(pu32, VERR_INVALID_POINTER);
+                AssertLogRelReturn(pBar, VERR_INVALID_POINTER);
+
+                return pThis->readFromDevice(pu32, cb, pBar->offset + offsetPort);
+            };
+
+            auto portIoWrite = [](PPDMDEVINS pDev, void* pvUser, RTIOPORT offsetPort, uint32_t u32, unsigned cb) -> VBOXSTRICTRC
+            {
+                PVFIODEV pThis {PDMDEVINS_2_DATA(pDev, PVFIODEV)};
+                auto pBar {static_cast<PPCIBARREGION>(pvUser)};
+
+                AssertLogRelReturn(pBar, VERR_INVALID_POINTER);
+
+                return pThis->writeToDevice(&u32, cb, pBar->offset + offsetPort);
+            };
+
+            rc = PDMDevHlpPCIIORegionCreateIo(pDevIns, i, region.size, portIoWrite, portIoRead,
+                                              &region, "VFIO Port IO", nullptr, &region.hRegion);
+            AssertLogRelReturn(RT_SUCCESS(rc), rc);
+        }
+        else if (barInfo.isMmioBar())
+        {
+            region.address = NIL_RTGCPHYS;
+
+            auto mmioRead = [](PPDMDEVINS pDev, void* pvUser, RTGCPHYS barOffset, void* pv, unsigned cb) -> VBOXSTRICTRC
+            {
+                PVFIODEV pThis {PDMDEVINS_2_DATA(pDev, PVFIODEV)};
+                auto pBar {static_cast<PPCIBARREGION>(pvUser)};
+
+                AssertLogRelReturn(pBar, VERR_INVALID_POINTER);
+
+                return pThis->mmioAccessHandler(pDev, *pBar, barOffset, pv, cb, false);
+            };
+
+            auto mmioWrite = [](PPDMDEVINS pDev, void* pvUser, RTGCPHYS barOffset, const void * pv, unsigned cb) -> VBOXSTRICTRC
+            {
+                PVFIODEV pThis {PDMDEVINS_2_DATA(pDev, PVFIODEV)};
+                auto pBar {static_cast<PPCIBARREGION>(pvUser)};
+
+                AssertLogRelReturn(pBar, VERR_INVALID_POINTER);
+
+                return pThis->mmioAccessHandler(pDev, *pBar, barOffset, const_cast<void*>(pv), cb, true);
+            };
+
+            rc = PDMDevHlpMmioCreate(pDevIns,
+                                     region.size,
+                                     NULL,
+                                     UINT32_MAX,
+                                     mmioWrite,
+                                     mmioRead,
+                                     &region,
+                                     IOMMMIO_FLAGS_READ_PASSTHRU | IOMMMIO_FLAGS_WRITE_PASSTHRU,
+                                     "VFIO MMIO BAR",
+                                     &region.hRegion);
+        }
+
+    }
+    return rc;
+}
+
+int VfioDevice::handleInterrupts(PPDMDEVINS pDevIns)
+{
+    // Waits for input on a file descriptor with a given timeout.
+    // Taken from https://www.gnu.org/software/libc/manual/html_node/Waiting-for-I_002fO.html
+    // Returns the first file descriptor that has input
+    auto waitForInput = [&] (std::chrono::microseconds delay) -> std::optional<InterruptInformation>
+    {
+        fd_set set;
+        struct timeval timeout {0, 0};
+
+        /* Initialize the file descriptor set. */
+        FD_ZERO(&set);
+
+        /*
+         * We use a copy of the interrupts here to avoid firing interrupts that are deactivated already.
+         */
+        irqDisable.lock();
+        std::vector<InterruptInformation> aCurrentIrqInformation {aIrqInformation};
+        irqDisable.unlock();
+
+        for (const auto efd : aCurrentIrqInformation)
+        {
+            if (efd.fd > 0)
+            {
+                FD_SET(efd.fd, &set);
+            }
+        }
+
+        /* Initialize the timeout data structure. */
+        const auto seconds {std::chrono::duration_cast<std::chrono::seconds>(delay)};
+        const auto us {std::chrono::duration_cast<std::chrono::microseconds>(delay - seconds)};
+
+        timeout.tv_sec = seconds.count();
+        timeout.tv_usec = us.count();
+
+        /* select returns 0 if timeout, 1 if input available, -1 if error. */
+        int error = TEMP_FAILURE_RETRY(select(FD_SETSIZE,
+                                       &set, NULL, NULL,
+                                       &timeout));
+
+        if (error == -1)
+        {
+            perror("select on fds failed");
+        }
+
+        Assert(error != -1);
+
+        {
+            LockGuard _ {irqDisable};
+
+            /*
+             * skip delivering non active interrupts
+             */
+            if (aCurrentIrqInformation != aIrqInformation)
+            {
+                return std::nullopt;
+            }
+
+            for (const auto efd : aCurrentIrqInformation)
+            {
+                if (efd.fd >= 0 and FD_ISSET(efd.fd, &set))
+                {
+                    return efd;
+                }
+            }
+        }
+
+        return std::nullopt;
+    };
+
+    while (not exit.load())
+    {
+        if (auto irqInfo = waitForInput(std::chrono::duration_cast<std::chrono::microseconds>(std::chrono::seconds(1))); irqInfo)
+        {
+            uint64_t value;
+            const ssize_t s {read(irqInfo->fd, &value, sizeof(value))};
+            AssertLogRelMsgReturn(s == sizeof(value), ("VFIO: Read on event FD returned wrong size."), VERR_GENERAL_FAILURE);
+            AssertLogRelReturn(value != 0, VERR_INTERRUPTED);
+            int rc {VINF_SUCCESS};
+            switch (activeInterruptType)
+            {
+            case IrqType::VFIO_INTX:
+                PDMDevHlpPCISetIrqNoWait(pDevIns, 0, PDM_IRQ_LEVEL_FLIP_FLOP);
+                break;
+            case IrqType::VFIO_MSI:
+                rc = injectMsi(pDevIns, *irqInfo);
+                break;
+            case IrqType::VFIO_MSIX:
+                rc = injectMsix(pDevIns, *irqInfo);
+                break;
+            default:
+                AssertLogRelMsgFailedReturn(("VFIO: Unsupported interrupt type in IRQ delivery thread detected %u\n", toUnderlying(activeInterruptType)), VERR_NOT_SUPPORTED);
+            }
+            AssertLogRelReturn(RT_SUCCESS(rc), rc);
+        }
+    }
+
+    return VINF_SUCCESS;
+}
+
+int VfioDevice::initializeInterrupts(PPDMDEVINS pDevIns)
+{
+    int rc {activateInterrupts(pDevIns, IrqType::VFIO_INTX)};
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    /*
+     *  We need to shadow the MSIX table, as a read access on the table returns invalid data.
+     *  Thus we need to allocate MSIX table entries upfront, to be able to handle MSIX table writes.
+     */
+    PDMMSIREG MsiReg;
+    RT_ZERO(MsiReg);
+
+    if (msiCapabilityIterator)
+    {
+        MSICapabilityDescriptor msiCap {*msiCapabilityIterator};
+
+        MsiReg.cMsiVectors = msiCap.maxCount();
+        MsiReg.iMsiCapOffset = msiCapabilityIterator->getOffset();
+        MsiReg.iMsiNextOffset = msiCap.nextPtr;
+        MsiReg.fMsi64bit = msiCap.is64Bit();
+        MsiReg.fMsiNoMasking = not msiCap.isPerVectorMaskable();
+    }
+
+    // if (msixCapabilityIterator)
+    // {
+        // MSIXCapabilityDescriptor msixCap {*msixCapabilityIterator};
+        // aMsixTable.resize(msixCap.tableSize());
+        // MsiReg.cMsixVectors = msixCap.tableSize();
+        // MsiReg.iMsixCapOffset = msixCapabilityIterator->getOffset();
+        // MsiReg.iMsixNextOffset = msixCap.nextPtr;
+        // MsiReg.iMsixBar = msixCap.getBarIndex();
+    // }
+
+    if (msixCapabilityIterator or msiCapabilityIterator)
+    {
+        rc = PDMDevHlpPCIRegisterMsi(pDevIns, &MsiReg);
+    }
+
+    auto handleIrqs = [](RTTHREAD /*hSelf*/, void* pvUser) -> int
+    {
+        PPDMDEVINS pDev {static_cast<PPDMDEVINS>(pvUser)};
+        PVFIODEV pThis {PDMDEVINS_2_DATA(pDev, PVFIODEV)};
+
+        return pThis->handleInterrupts(pDev);
+    };
+
+    rc = RTThreadCreate(&hIrqDeliveryThread, handleIrqs, pDevIns, 0, RTTHREADTYPE_IO, RTTHREADFLAGS_WAITABLE, "vfio IRQ");
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    return rc;
+}
+
+int VfioDevice::activateInterrupts(PPDMDEVINS pDevIns, const IrqType irqType, uint32_t irqCount)
+{
+    LockGuard _ {irqDisable};
+
+    int rc;
+    vfio_irq_info irqInfo;
+    irqInfo.argsz = sizeof(irqInfo);
+    irqInfo.index = toUnderlying(irqType);
+
+    /**
+     * The call of this function requires that the interrupts are disabled.
+     */
+    AssertLogRelMsgReturn(aIrqInformation.size() == 0,
+        ("VFIO: Trying to activate interrupts without deactivating the previous irqs! Disable irqs before activate new ones!"),
+        VERR_NOT_SUPPORTED);
+
+    /**
+     * If the IRQ is not enabled in the VFIO device the call will return unsuccessful
+     * and we don't need to set up something for this IRQ and can just continue
+     */
+    if (RT_FAILURE(deviceControl(pDevIns, VFIO_DEVICE_GET_IRQ_INFO, "", &irqInfo)))
+    {
+        return VERR_NOT_AVAILABLE;
+    }
+
+    /**
+     * Some devices, (e.G SRIOV virtual functions does not have legacy interrupts enabled.
+     * We can skip interrupt activation if we find a device without legacy interrupts.
+     */
+    if (irqType == IrqType::VFIO_INTX and irqInfo.count == 0)
+    {
+        uint8_t interruptPin;
+        readConfigSpace(interruptPin, sizeof(interruptPin), VBOX_PCI_INTERRUPT_PIN);
+        AssertLogRelMsgReturn(interruptPin == 0, ("VFIO: Found device without INTX information, but INTX is marked as supported in the PCI Config space"), VERR_NOT_AVAILABLE);
+        return VINF_SUCCESS;
+    }
+
+    /**
+     * If we try to activate an interrupt type that is not enabled, or supported by vfio we get an interrupt count of 0
+     * We bail out here, as we are not able to enable an interrupt type with no interrupts.
+     */
+    if (irqInfo.count == 0)
+    {
+        LogRel(("VFIO: Trying to activate IRQ type %u, but no IRQs of that type are configured\n", toUnderlying(irqType)));
+        return VERR_NOT_AVAILABLE;
+    }
+
+    /**
+     * Sanity check: If we request a larger number of interrutps, the VFIO device is able to support we bail out here.
+     */
+    if (irqInfo.count < irqCount)
+    {
+        LogRel(("VFIO: Trying to register %lu irqs, but %lu are supported for type %u.\n", irqCount, irqInfo.count, toUnderlying(irqType)));
+        return VERR_NOT_SUPPORTED;
+    }
+
+    AssertLogRelReturn(irqInfo.flags & VFIO_IRQ_INFO_EVENTFD, VERR_NOT_AVAILABLE);
+
+    const auto setSize {sizeof(vfio_irq_set) + sizeof(int) * irqCount};
+    std::vector<uint8_t> buf(setSize);
+    vfio_irq_set& irqSet {*reinterpret_cast<vfio_irq_set*>(buf.data())};
+
+    irqSet.argsz = setSize;
+    irqSet.flags = VFIO_IRQ_SET_DATA_EVENTFD | VFIO_IRQ_SET_ACTION_TRIGGER;
+    irqSet.index = irqInfo.index;
+    irqSet.start = 0;
+    irqSet.count = irqCount;
+
+    /*
+     * Logging and sanity checking only.
+     */
+    switch (irqType)
+    {
+    case IrqType::VFIO_INTX:
+        AssertLogRelMsgReturn(irqInfo.count == 1,
+                              ("VFIO: Only a single INTX is supported! Detected Count: %u\n", irqInfo.count),
+                              VERR_NOT_IMPLEMENTED);
+        LogRel(("VFIO: Activate INTX\n"));
+        break;
+    case IrqType::VFIO_MSI:
+        LogRel(("VFIO: Activate MSI count: %u\n", irqCount));
+        break;
+    case IrqType::VFIO_MSIX:
+        LogRel(("VFIO: Activate MSIX: count %u\n", irqCount));
+        break;
+    default:
+        AssertLogRelMsgFailedReturn(("VFIO: Found unsupported vfio IRQ type: %u, count: %u\n", irqInfo.index, irqInfo.count), VERR_NOT_IMPLEMENTED);
+    }
+
+    activeInterruptType = irqType;
+
+    for (uint32_t i {0ul}; i < irqCount; ++i)
+    {
+        int eventFd {eventfd(0, 0)};
+
+        AssertLogRelMsgReturn(eventFd > 0,("VFIO: could not request additional eventfds\n"), VERR_ACCESS_DENIED);
+        aIrqInformation.push_back({eventFd, i});
+    }
+
+    for (auto i {0ul}; i < aIrqInformation.size(); ++i)
+    {
+        reinterpret_cast<int*>(irqSet.data)[i] = aIrqInformation[i].fd;
+    }
+
+    rc = deviceControl(pDevIns, VFIO_DEVICE_SET_IRQS, "VFIO: Could not set irq info\n", &irqSet);
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    return rc;
+}
+
+int VfioDevice::disableInterrupts(PPDMDEVINS pDevIns)
+{
+    LockGuard _ {irqDisable};
+
+    if (aIrqInformation.size() != 0 and activeInterruptType != IrqType::VFIO_NONE)
+    {
+        const auto setSize {sizeof(vfio_irq_set)};
+        std::vector<uint8_t> buf(setSize);
+        vfio_irq_set& irqSet {*reinterpret_cast<vfio_irq_set*>(buf.data())};
+
+        irqSet.argsz = setSize;
+        irqSet.flags = VFIO_IRQ_SET_DATA_NONE | VFIO_IRQ_SET_ACTION_TRIGGER;
+        irqSet.index = toUnderlying(activeInterruptType);
+        irqSet.start = 0;
+        irqSet.count = 0;
+
+        int rc {deviceControl(pDevIns, VFIO_DEVICE_SET_IRQS, "VFIO: Could not set irq info for deactivation\n", &irqSet)};
+        AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+        for(auto info: aIrqInformation)
+        {
+            close(info.fd);
+        }
+
+        aIrqInformation.clear();
+    }
+
+    return VINF_SUCCESS;
+}
+
+
+int VfioDevice::injectMsi(PPDMDEVINS pDevIns, InterruptInformation& irqInfo)
+{
+
+    AssertLogRelMsgReturn(msiCapabilityIterator, ("VFIO: Pending MSI, but the capability is not provided \n"), VERR_NOT_SUPPORTED);
+    MSICapabilityDescriptor cap(*msiCapabilityIterator);
+
+    AssertLogRelMsgReturn(cap.enabled(), ("VFIO: Pending MSI, but the capability is disabled \n"), VERR_NOT_SUPPORTED);
+
+    if (not cap.isMasked(irqInfo.index))
+    {
+        PDMDevHlpPCISetIrqNoWait(pDevIns, 0, PDM_IRQ_LEVEL_HIGH);
+    }
+
+    return VINF_SUCCESS;
+}
+
+int VfioDevice::injectMsix(PPDMDEVINS pDevIns, InterruptInformation& irqInfo)
+{
+    AssertLogRelMsgReturn(msixCapabilityIterator, ("VFIO: Pending MSIX, but the capability is not provided \n"), VERR_NOT_SUPPORTED);
+    MSIXCapabilityDescriptor cap(*msixCapabilityIterator);
+
+    AssertLogRelMsgReturn(cap.enabled(), ("VFIO: Pending MSIX, but the capability is disabled \n"), VERR_NOT_SUPPORTED);
+
+    PDMDevHlpPCISetIrqNoWait(pDevIns,  irqInfo.index, PDM_IRQ_LEVEL_HIGH);
+    return VINF_SUCCESS;
+}
+
+int VfioDevice::configSpaceWriteHandler(PPDMDEVINS pDevIns, uint32_t uAddress, unsigned cb, uint32_t u32Value)
+{
+    int rc {VINF_SUCCESS};
+
+    if (uAddress == VBOX_PCI_COMMAND)
+    {
+        tryHandleBarInterception(pDevIns, u32Value);
+    }
+    else if (msiCapabilityIterator and  (uAddress >= msiCapabilityIterator->getOffset() and uAddress < (msiCapabilityIterator->getOffset() + sizeof(MSICapabilityDescriptor))))
+    {
+        MSICapabilityDescriptor lastCap {*msiCapabilityIterator};
+
+        MSICapabilityDescriptor updatedCap {*msiCapabilityIterator};
+        std::memcpy(reinterpret_cast<void*>(reinterpret_cast<uintptr_t>(&updatedCap) + (uAddress - msiCapabilityIterator->getOffset())), &u32Value, cb);
+
+        if (not updatedCap.enabled() and lastCap.enabled())
+        {
+            rc = disableInterrupts(pDevIns);
+            AssertLogRelReturn(RT_SUCCESS(rc), rc);
+            rc = activateInterrupts(pDevIns, IrqType::VFIO_INTX);
+            AssertLogRelReturn(RT_SUCCESS(rc), rc);
+        }
+        else if (updatedCap.enabled())
+        {
+            rc = disableInterrupts(pDevIns);
+            AssertLogRelReturn(RT_SUCCESS(rc), rc);
+            rc = activateInterrupts(pDevIns, IrqType::VFIO_MSI, updatedCap.count());
+            AssertLogRelReturn(RT_SUCCESS(rc), rc);
+        }
+    }
+    else if (msixCapabilityIterator and (uAddress >= msixCapabilityIterator->getOffset() and uAddress < (msixCapabilityIterator->getOffset() + sizeof(MSIXCapabilityDescriptor))))
+    {
+        MSIXCapabilityDescriptor lastCap {*msixCapabilityIterator};
+
+        MSIXCapabilityDescriptor updatedCap {lastCap};
+        std::memcpy(reinterpret_cast<void*>(reinterpret_cast<uintptr_t>(&updatedCap) + (uAddress - msixCapabilityIterator->getOffset())), &u32Value, cb);
+
+        if (not updatedCap.enabled() and lastCap.enabled())
+        {
+            rc = disableInterrupts(pDevIns);
+            AssertLogRelReturn(RT_SUCCESS(rc), rc);
+            rc = activateInterrupts(pDevIns, IrqType::VFIO_INTX);
+            AssertLogRelReturn(RT_SUCCESS(rc), rc);
+        }
+        else if (updatedCap.enabled())
+        {
+            rc = disableInterrupts(pDevIns);
+            AssertLogRelReturn(RT_SUCCESS(rc), rc);
+            rc = activateInterrupts(pDevIns, IrqType::VFIO_MSIX, updatedCap.tableSize());
+            AssertLogRelReturn(RT_SUCCESS(rc), rc);
+        }
+    }
+
+    return writeConfigSpace(u32Value, cb, uAddress);
+}
+
+int VfioDevice::mmioAccessHandler(PPDMDEVINS /*pDevIns*/, PCIBarRegion& barRegion, RTGCPHYS barOffset, void* pv, unsigned cb, bool writeAccess)
+{
+    if (msixCapabilityIterator)
+    {
+        MSIXCapabilityDescriptor cap {*msixCapabilityIterator};
+
+        if (cap.getBarIndex() == barRegion.iRegion and barOffset >= cap.getTableOffset()
+            and barOffset < cap.getTableOffset() + (sizeof(MSIXTableEntry) * cap.tableSize()))
+        {
+            AssertLogRelMsgReturn(cap.tableSize() == aMsixTable.size(),
+                ("VFIO: The MSIX table size mismatches the hardware table size. Assumed table size: %hu Hardware table size: %hu\n",
+                    aMsixTable.size(),
+                    cap.tableSize()),
+                VERR_NOT_SUPPORTED);
+            uint64_t msixTableEntryOffset {barOffset - cap.getTableOffset()};
+            void* shadowMsixTableOffset {reinterpret_cast<void*>(reinterpret_cast<uintptr_t>(aMsixTable.data()) + msixTableEntryOffset)};
+            if (writeAccess)
+            {
+                /*
+                 * We need to shadow the MSIX table as explained in the else path, but we need to provide the VFIO device
+                 * with data written to the VFIO device.
+                 * Because of this we need to write the data through.
+                 */
+                std::memcpy(shadowMsixTableOffset, pv, cb);
+            }
+            else
+            {
+                std::memcpy(pv, shadowMsixTableOffset, cb);
+                /**
+                 * The VFIO Device returns invalid data in case of a read from the MSIX table.
+                 * Because of this, we need to shadow the table and return early without reading
+                 * from the actual VFIO device here.
+                 */
+                return VINF_SUCCESS;
+            }
+        }
+    }
+
+    if (writeAccess)
+    {
+        return writeToDevice(pv, cb, barRegion.offset + barOffset);
+    }
+    else
+    {
+       return readFromDevice(pv, cb, barRegion.offset + barOffset);
+    }
+
+}
+
+int VfioDevice::interceptConfigSpaceAccesses(PPDMDEVINS pDevIns)
+{
+    int rc {VINF_SUCCESS};
+
+    auto configSpaceWrite = [](PPDMDEVINS pDev, PPDMPCIDEV pPciDev_, uint32_t uAddress, unsigned cb, uint32_t u32Value) -> VBOXSTRICTRC
+    {
+        PVFIODEV pThis {PDMDEVINS_2_DATA(pDev, PVFIODEV)};
+        writePciConfigSpaceShadow(pPciDev_, uAddress, cb, u32Value);
+        return pThis->configSpaceWriteHandler(pDev, uAddress, cb, u32Value);
+    };
+
+    rc = PDMDevHlpPCIInterceptConfigAccesses(pDevIns, pPciDev, vfioConfigSpaceRead, configSpaceWrite);
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    return rc;
+}
+
+int VfioDevice::init(PPDMDEVINS pDevIns, std::filesystem::path sysfsPath)
+{
+    int rc {VINF_SUCCESS};
+
+    rc = initializeVfio(pDevIns, sysfsPath);
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    rc = initializePci(pDevIns);
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    vfio_group_status groupStatus;
+    groupStatus.argsz = sizeof(groupStatus);
+
+    rc = vfioControl(pDevIns, vfioGroupFd, VFIO_GROUP_GET_STATUS, "VFIO: Unable to retrieve VFIO group status\n" , &groupStatus);
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    vfio_device_info deviceInfo;
+    deviceInfo.argsz = sizeof(deviceInfo);
+
+    rc = deviceControl(pDevIns, VFIO_DEVICE_GET_INFO, "VFIO: Unable to retrieve VFIO Device information\n", &deviceInfo);
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    LogRel(("VFIO: Successfully opened VFIO Device: Group Status Flags: %#x Device Flags: %#x, Num BARs: %u, Num IRQ's %u \n",
+           groupStatus.flags, deviceInfo.flags, deviceInfo.num_regions, deviceInfo.num_irqs));
+
+    rc = initializeMemoryRegions(pDevIns, deviceInfo);
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    rc = initializeInterrupts(pDevIns);
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    rc = interceptConfigSpaceAccesses(pDevIns);
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    return rc;
+}
+
+int VfioDevice::registerDmaRange(PVM pVM, RTGCPHYS startGCPhys, RTGCPHYS endGCPhys)
+{
+    AssertLogRelReturn(RT_VALID_ALIGNED_PTR(startGCPhys, PAGE_SIZE) || startGCPhys == 0, VERR_INVALID_POINTER);
+    AssertLogRelReturn(RT_VALID_ALIGNED_PTR(endGCPhys + 1 , PAGE_SIZE), VERR_INVALID_POINTER);
+
+    auto registerDma = [](uintptr_t hva, RTGCPHYS gpa, uint64_t size, int containerFd) -> int
+    {
+        struct vfio_iommu_type1_dma_map dma;
+        dma.argsz = sizeof(dma);
+        dma.flags = VFIO_DMA_MAP_FLAG_READ | VFIO_DMA_MAP_FLAG_WRITE;
+        dma.vaddr = hva;
+        dma.iova = gpa;
+        dma.size = static_cast<uint64_t>(size);
+        int rc  {ioctl(containerFd, VFIO_IOMMU_MAP_DMA, &dma)};
+        AssertLogRelMsgReturn(rc == 0, ("VFIO: Could not acquire enough memory to map the Guest Physical address space. Adapt your ulimit\n"), VERR_NO_MEMORY);
+
+        return VINF_SUCCESS;
+    };
+
+    uintptr_t continousPagesStart {0};
+    RTGCPHYS continousPagesStartGCPhys {0};
+    uintptr_t continousPagesLast {0};
+    uint64_t continousRangeSize {0};
+
+    auto reset = [&]()
+    {
+        continousRangeSize = 0;
+        continousPagesStart = 0;
+        continousPagesLast = 0;
+        continousPagesStartGCPhys = 0;
+    };
+
+    for (RTGCPHYS pageAddress {startGCPhys}; pageAddress < endGCPhys; pageAddress += PAGE_SIZE)
+    {
+        void* ptr;
+        if (RT_SUCCESS(PGMR3PhysTlbGCPhys2Ptr(pVM, pageAddress, true, &ptr)))
+        {
+            uintptr_t hcVirt(reinterpret_cast<uintptr_t>(ptr));
+            if (continousRangeSize > 0 and continousPagesLast + PAGE_SIZE == hcVirt)
+            {
+                continousPagesLast = hcVirt;
+                continousRangeSize += PAGE_SIZE;
+                continue;
+            }
+            else if (continousRangeSize != 0)
+            {
+                int rc {registerDma(continousPagesStart, continousPagesStartGCPhys, continousRangeSize, vfioContainerFd)};
+                AssertLogRelReturn(RT_SUCCESS(rc), rc);
+            }
+            continousPagesStart = hcVirt;
+            continousPagesLast = hcVirt;
+            continousPagesStartGCPhys = pageAddress;
+            continousRangeSize = PAGE_SIZE;
+        }
+        else if (continousRangeSize != 0)
+        {
+            int rc {registerDma(continousPagesStart, continousPagesStartGCPhys, continousRangeSize, vfioContainerFd)};
+            AssertLogRelReturn(RT_SUCCESS(rc), rc);
+            reset();
+        }
+    }
+
+    if (continousRangeSize != 0)
+    {
+        int rc {registerDma(continousPagesStart, continousPagesStartGCPhys, continousRangeSize, vfioContainerFd)};
+        AssertLogRelReturn(RT_SUCCESS(rc), rc);
+        reset();
+    }
+
+    return VINF_SUCCESS;
+}
+
+int VfioDevice::initializeDma(PPDMDEVINS pDevIns)
+{
+    auto pVM {PDMDevHlpGetVM(pDevIns)};
+    uint32_t ramRangeCount {PGMR3PhysGetRamRangeCount(pVM)};
+
+    for (uint32_t i {0u}; i < ramRangeCount; ++i)
+    {
+        RTGCPHYS start, end;
+        bool isMMioRange;
+        if (RT_SUCCESS(PGMR3PhysGetRange(pVM, i, &start, &end, nullptr, &isMMioRange)) and not isMMioRange)
+        {
+            int rc {registerDmaRange(pVM, start, end)};
+            AssertLogRelReturn(RT_SUCCESS(rc), rc);
+        }
+
+    }
+
+    return VINF_SUCCESS;
+}
+
+int VfioDevice::terminate(PPDMDEVINS pDevIns)
+{
+    int rc {VINF_SUCCESS};
+
+    rc = disableInterrupts(pDevIns);
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    exit = true;
+    rc = RTThreadWaitNoResume(hIrqDeliveryThread, RT_INDEFINITE_WAIT, nullptr);
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+    exit = false;
+
+    aMsixTable.clear();
+    msiCapabilityIterator = std::nullopt;
+    msixCapabilityIterator = std::nullopt;
+
+    rc = close(vfioDeviceFd);
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+    rc = close(vfioGroupFd);
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+    rc = close(vfioContainerFd);
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    vfioDeviceFd = -1;
+    vfioGroupFd = -1;
+    vfioContainerFd = -1;
+
+
+    return rc;
+}
+
+void VfioDevice::tryHandleBarInterception(PPDMDEVINS pDevIns, uint32_t pciConfigCommandValue)
+{
+    if (pciConfigCommandValue & VBOX_PCI_COMMAND_IO and not pciConfigIODecodingEnabled)
+    {
+        pciConfigIODecodingEnabled = true;
+    }
+    else
+    {
+        pciConfigIODecodingEnabled = false;
+    }
+
+    if (pciConfigCommandValue & VBOX_PCI_COMMAND_MEMORY and not pciConfigMemoryDecodingEnabled)
+    {
+        pciConfigMemoryDecodingEnabled = true;
+    }
+    else
+    {
+        pciConfigMemoryDecodingEnabled = false;
+    }
+
+    if (pciConfigIODecodingEnabled or pciConfigMemoryDecodingEnabled)
+    {
+        for (auto i {0u}; i < VBOX_PCI_MAX_BARS; ++i)
+        {
+            const auto barInfo {getBarInfo(i)};
+            if (not (pciBars[i].hRegion == NIL_IOMMMIOHANDLE or pciBars[i].hRegion == 0))
+            {
+                if (barInfo.isIoBar() and pciConfigIODecodingEnabled)
+                {
+                    registerPCIBar<0>(PDMDevHlpIoPortMap, PDMDevHlpIoPortUnmap, pDevIns, pciBars[i], barInfo.getBarAddress());
+                }
+                else if (barInfo.isMmioBar() and pciConfigMemoryDecodingEnabled)
+                {
+                    registerPCIBar<NIL_RTGCPHYS>(PDMDevHlpMmioMap, PDMDevHlpMmioUnmap, pDevIns, pciBars[i], barInfo.getBarAddress());
+                }
+            }
+        }
+    }
+}
+
+const PCIBar VfioDevice::getBarInfo(unsigned barNumber)
+{
+    uint64_t barOffset { VBOX_PCI_BASE_ADDRESS_0 + barNumber * sizeof(uint32_t)};
+    uint64_t barValue;
+
+    readConfigSpace(barValue, sizeof(barValue), barOffset);
+
+    PCIBar bar {barValue};
+
+    if (bar.is64BitBar()) {
+        return bar;
+    }
+
+    return {barValue & std::numeric_limits<uint32_t>::max()};
+}
diff --git a/src/VBox/Devices/Graphics/DevVGA.cpp b/src/VBox/Devices/Graphics/DevVGA.cpp
index e106078..0e02788 100644
--- a/src/VBox/Devices/Graphics/DevVGA.cpp
+++ b/src/VBox/Devices/Graphics/DevVGA.cpp
@@ -6217,6 +6217,49 @@ static DECLCALLBACK(void) vgaR3Relocate(PPDMDEVINS pDevIns, RTGCINTPTR offDelta)
 # endif
 }
 
+template <typename CLASS, typename... ARGS>
+auto generateDummy(int (*CLASS::*)(ARGS...))
+{
+    return [](ARGS...) -> int { return VERR_NOT_IMPLEMENTED; };
+}
+
+template <typename CLASS, typename... ARGS>
+auto generateDummy(void (*CLASS::*)(ARGS...))
+{
+    return [](ARGS...) -> void {};
+}
+
+#define DUMMY_MEMBER(x) dummyConnector.x = generateDummy(&PDMIDISPLAYCONNECTOR::x)
+
+/**
+ * Get a dummy display connector which either does nothing or returns an error
+ * code.
+ */
+static PPDMIDISPLAYCONNECTOR getDummyDisplayConnector()
+{
+    static PDMIDISPLAYCONNECTOR dummyConnector;
+
+    DUMMY_MEMBER(pfnResize);
+    DUMMY_MEMBER(pfnUpdateRect);
+    DUMMY_MEMBER(pfnRefresh);
+    DUMMY_MEMBER(pfnReset);
+    DUMMY_MEMBER(pfnLFBModeChange);
+    DUMMY_MEMBER(pfnProcessAdapterData);
+    DUMMY_MEMBER(pfnProcessDisplayData);
+    DUMMY_MEMBER(pfnVHWACommandProcess);
+    DUMMY_MEMBER(pfnVBVAEnable);
+    DUMMY_MEMBER(pfnVBVADisable);
+    DUMMY_MEMBER(pfnVBVAUpdateBegin);
+    DUMMY_MEMBER(pfnVBVAUpdateProcess);
+    DUMMY_MEMBER(pfnVBVAUpdateEnd);
+    DUMMY_MEMBER(pfnVBVAResize);
+    DUMMY_MEMBER(pfnVBVAMousePointerShape);
+    DUMMY_MEMBER(pfnVBVAGuestCapabilityUpdate);
+    DUMMY_MEMBER(pfnVBVAInputMappingUpdate);
+    DUMMY_MEMBER(pfnVBVAReportCursorPosition);
+
+    return &dummyConnector;
+}
 
 /**
  * @interface_method_impl{PDMDEVREG,pfnAttach}
@@ -6230,6 +6273,11 @@ static DECLCALLBACK(int)  vgaAttach(PPDMDEVINS pDevIns, unsigned iLUN, uint32_t
 
     RT_NOREF(pThis);
 
+    if (fFlags & PDM_ATTACH_DUMMY_DRIVER) {
+        pThisCC->pDrv = getDummyDisplayConnector();
+        return VINF_SUCCESS;
+    }
+
     AssertMsgReturn(fFlags & PDM_TACH_FLAGS_NOT_HOT_PLUG,
                     ("VGA device does not support hotplugging\n"),
                     VERR_INVALID_PARAMETER);
diff --git a/src/VBox/Devices/Graphics/DevVirtioGpu.cpp b/src/VBox/Devices/Graphics/DevVirtioGpu.cpp
new file mode 100644
index 0000000..20f3e54
--- /dev/null
+++ b/src/VBox/Devices/Graphics/DevVirtioGpu.cpp
@@ -0,0 +1,407 @@
+/*
+ * Copyright (C) Cyberus Technology GmbH.
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <https://www.gnu.org/licenses/>.
+ *
+ * SPDX-License-Identifier: GPL-3.0-or-later
+ */
+
+#define LOG_GROUP LOG_GROUP_DEV_VIRTIO_GPU
+#include "DevVirtioGpu.hpp"
+#include "DevVirtioGpuVBoxStubs.hpp"
+
+#include <VBox/log.h>
+#include <VBox/vmm/pdmcommon.h>
+
+#include <iprt/semaphore.h>
+#include <iprt/string.h>
+
+#include <array>
+#include <numeric>
+
+int VirtioGpuDevice::init(PPDMDEVINS pDevIns, int iInstance, uint32_t u32VRamSize, uint32_t cMonitorCount,
+                          bool secondaryController)
+{
+    std::string sInstanceName = std::string {"VIRTIOGPU"} + std::to_string(iInstance);
+    szInst = sInstanceName;
+
+    int rc {VINF_SUCCESS};
+
+    gpuConfig.uNumScanouts = cMonitorCount;
+
+    rc = initializeVirtio(pDevIns);
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    rc = initializeVirtQueues();
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    rc = initializeDisplay(u32VRamSize, cMonitorCount);
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    pMemoryAdapter = std::make_unique<VirtioGpuMemoryAdapter>(virtio.pDevInsR3);
+    AssertLogRelReturn(pMemoryAdapter != nullptr, VERR_NO_MEMORY);
+
+    pCmdHandler = std::make_unique<VirtioGpuCmdHandler>(*pVirtioAdapter, *pDisplayManager, *pMemoryAdapter,
+                                                        cMonitorCount, secondaryController);
+    AssertLogRelReturn(pCmdHandler != nullptr, VERR_NO_MEMORY);
+
+    return rc;
+}
+
+int VirtioGpuDevice::initializeVirtio(PPDMDEVINS pDevIns)
+{
+    VIRTIOPCIPARAMS virtioPciParams;
+    virtioPciParams.uDeviceId = virtioGpu::PCI_DEVICE_ID;
+    virtioPciParams.uSubsystemId =
+        virtioGpu::PCI_DEVICE_ID; /* Virtio 1.2 - 4.1.2.1 subsystem id may reflect device id */
+    virtioPciParams.uClassBase = virtioGpu::PCI_CLASS_BASE;
+    virtioPciParams.uClassSub = virtioGpu::PCI_CLASS_SUB;
+    virtioPciParams.uClassProg = virtioGpu::PCI_CLASS_PROG;
+
+    virtioPciParams.uInterruptLine = virtioGpu::PCI_INTERRUPT_LINE;
+    virtioPciParams.uInterruptPin = virtioGpu::PCI_INTERRUPT_PIN;
+
+    PVIRTIOGPUDEVCC pThisCC {PDMDEVINS_2_DATA_CC(pDevIns, PVIRTIOGPUDEVCC)};
+
+    pThisCC->virtio.pfnStatusChanged = virtioGpuStatusChanged;
+    pThisCC->virtio.pfnDevCapRead = virtioGpuDevCapRead;
+    pThisCC->virtio.pfnDevCapWrite = virtioGpuDevCapWrite;
+    pThisCC->virtio.pfnVirtqNotified = virtioGpuVirtqNotified;
+
+    int rc = virtioCoreR3Init(pDevIns, &this->virtio, &pThisCC->virtio, &virtioPciParams, szInst.c_str(),
+                              FEATURES_OFFERED, 0, &this->gpuConfig, sizeof(gpuConfig));
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    pVirtioAdapter = std::make_unique<VirtioCoreVirtioAdapter>(&virtio);
+    AssertLogRelReturn(pVirtioAdapter != nullptr, VERR_NO_MEMORY);
+
+    return rc;
+}
+
+int VirtioGpuDevice::initializeVirtQueues()
+{
+    for (size_t uVirtqNbr {0u}; uVirtqNbr < virtioGpu::NUM_VIRTQUEUES; uVirtqNbr++) {
+        PVIRTIOGPU_VIRTQ pVirtq {&aVirtqs[uVirtqNbr]};
+        PVIRTIOGPU_WORKER pWorker {&aWorkers[uVirtqNbr]};
+
+        int rc = RTSemEventCreate(&pWorker->hEvent);
+        AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+        std::string sVirtqName {uVirtqNbr == virtioGpu::VirtqIdx::CONTROLQ ? std::string {"controlq"}
+                                                                           : std::string {"cursorq"}};
+        pVirtq->szName = sVirtqName;
+        pVirtq->uIdx = uVirtqNbr;
+        pWorker->uIdx = uVirtqNbr;
+    }
+    return VINF_SUCCESS;
+}
+
+int VirtioGpuDevice::initializeDisplay(uint32_t u32VRamSize, uint32_t u32MonitorCount)
+{
+    PPDMDEVINS pDevIns {virtio.pDevInsR3};
+
+    pDevIns->IBase.pfnQueryInterface = virtioGpuQueryInterface;
+    IBase.pfnQueryInterface = virtioGpuPortQueryInterface;
+    IPort.pfnUpdateDisplay = virtioGpuUpdateDisplay;
+
+    IPort.pfnUpdateDisplayAll = virtioGpuPortUpdateDisplayAll;
+    IPort.pfnQueryVideoMode = virtioGpuPortQueryVideoMode;
+    IPort.pfnSetRefreshRate = virtioGpuPortSetRefreshRate;
+    IPort.pfnTakeScreenshot = virtioGpuPortTakeScreenshot;
+    IPort.pfnFreeScreenshot = virtioGpuPortFreeScreenshot;
+    IPort.pfnDisplayBlt = virtioGpuPortDisplayBlt;
+    IPort.pfnUpdateDisplayRect = virtioGpuPortUpdateDisplayRect;
+    IPort.pfnCopyRect = virtioGpuPortCopyRect;
+    IPort.pfnSetRenderVRAM = virtioGpuPortSetRenderVRAM;
+    // used for SVGA only
+    IPort.pfnSetViewport = NULL;
+    IPort.pfnSendModeHint = vbvavirtioGpuPortSendModeHint;
+    IPort.pfnReportHostCursorCapabilities = vbvavirtioGpuPortReportHostCursorCapabilities;
+    IPort.pfnReportHostCursorPosition = vbvavirtioGpuPortReportHostCursorPosition;
+
+    IVirtioGpuPort.pfnDisplayChanged = virtioGpuDisplayChanged;
+
+    pDisplayManager =
+        std::make_unique<VirtioGpuDisplayManager>(pDevIns, 0 /*iLUN*/, IBase, u32VRamSize, u32MonitorCount);
+    AssertLogRelReturn(pDisplayManager != nullptr, VERR_NO_MEMORY);
+    return VINF_SUCCESS;
+}
+
+int VirtioGpuDevice::terminate(PPDMDEVINS)
+{
+    int rc {VINF_SUCCESS};
+
+    stop();
+    for (size_t uVirtqNbr {0u}; uVirtqNbr < virtioGpu::NUM_VIRTQUEUES; uVirtqNbr++) {
+        rc = RTSemEventDestroy(aWorkers[uVirtqNbr].hEvent);
+        AssertLogRelReturn(RT_SUCCESS(rc), rc);
+    }
+
+    pCmdHandler.reset();
+    pVirtioAdapter.reset();
+    pDisplayManager.reset();
+    pMemoryAdapter.reset();
+
+    return rc;
+}
+
+int VirtioGpuDevice::start()
+{
+    fNegotiatedFeatures = virtioCoreGetNegotiatedFeatures(&virtio);
+    return startVirtQueues();
+}
+
+int VirtioGpuDevice::stop()
+{
+    int rc {stopVirtQueues()};
+
+    gpuConfig.uEventsRead = 0;
+    gpuConfig.uEventsClear = 0;
+
+    pCmdHandler->clearResources();
+    return rc;
+}
+
+/*
+ * virtioMmioRead and virtioMmioWrite both return VINF_IOM_MMIO_UNUSED_00 in case
+ * of a bad access, thus we use this return value too.
+ */
+
+int VirtioGpuDevice::accessCap(uint32_t uOffset, std::function<void(uint32_t*)> accessFn)
+{
+    switch (uOffset) {
+    case 0: accessFn(&gpuConfig.uEventsRead); return VINF_SUCCESS;
+    case 4:
+        accessFn(&gpuConfig.uEventsClear);
+        /*
+         * uEventsRead has write-to-clear semantics, i.e. when the driver writes
+         * a bit to uEventsClear, we clear the bit in uEventsRead and clear uEventsClear
+         */
+        gpuConfig.uEventsRead &= ~gpuConfig.uEventsClear;
+        gpuConfig.uEventsClear = 0u;
+        return VINF_SUCCESS;
+    case 8: accessFn(&gpuConfig.uNumScanouts); return VINF_SUCCESS;
+    case 12: accessFn(&gpuConfig.uNumCapsets); return VINF_SUCCESS;
+    default:
+        LogRel(("%s: Invalid offset while accessing capabilties: %u\n", szInst.c_str(), uOffset));
+        return VINF_IOM_MMIO_UNUSED_00;
+    }
+}
+
+/*
+ * Virtio 1.2 - 4.1.3.1: For device configuration access, the driver MUST use [...]
+ * 32-bit wide and aligned accesses for 32-bit and 64-bit wide fields.
+ */
+int VirtioGpuDevice::readCap(uint32_t uOffset, void* pvBuf, uint32_t cbToRead)
+{
+    if (pvBuf == nullptr) {
+        LogRel(("%s: readCap: buffer to write to is a nullptr.\n", szInst.c_str()));
+        return VINF_IOM_MMIO_UNUSED_00;
+    }
+    if (cbToRead != sizeof(uint32_t)) {
+        LogRel(("%s: readCap: invalid access size. Tried to read %u bytes.\n", szInst.c_str(), cbToRead));
+        return VINF_IOM_MMIO_UNUSED_00;
+    }
+
+    std::function<void(uint32_t*)> accessFn = [pvBuf](uint32_t* pMember) { *static_cast<uint32_t*>(pvBuf) = *pMember; };
+
+    return accessCap(uOffset, accessFn);
+}
+
+int VirtioGpuDevice::writeCap(uint32_t uOffset, const void* pvBuf, uint32_t cbToWrite)
+{
+    if (pvBuf == nullptr) {
+        LogRel(("%s: writeCap: buffer to write to is a nullptr.\n", szInst.c_str()));
+        return VINF_IOM_MMIO_UNUSED_00;
+    }
+    if (cbToWrite != sizeof(uint32_t)) {
+        LogRel(("%s: writeCap: invalid access size. Tried to write %u bytes.\n", szInst.c_str(), cbToWrite));
+        return VINF_IOM_MMIO_UNUSED_00;
+    }
+    if (uOffset != 4) {
+        /* the driver is only allowed to write to uEventsClear */
+        LogRel(("%s: writeCap: invalid access: the driver may only write to offset 4 (offset was %u).\n",
+                szInst.c_str(), uOffset));
+        return VINF_IOM_MMIO_UNUSED_00;
+    }
+
+    std::function<void(uint32_t*)> accessFn = [pvBuf](uint32_t* pMember) {
+        *pMember = *static_cast<const uint32_t*>(pvBuf);
+    };
+
+    return accessCap(uOffset, accessFn);
+}
+
+void VirtioGpuDevice::displayChanged(uint32_t numDisplays, VMMDevDisplayDef* displayDefs)
+{
+    for (uint32_t i = 0; i < numDisplays; i++) {
+        bool enabled {not(displayDefs[i].fDisplayFlags & VMMDEV_DISPLAY_DISABLED)};
+
+        pCmdHandler->requestResize(i, enabled, displayDefs[i].cx, displayDefs[i].cy);
+    }
+
+    gpuConfig.uEventsRead |= virtioGpu::EVENT_DISPLAY;
+    LogRel5(("%s: device configuration has changed.\n", szInst.c_str()));
+
+    virtioCoreNotifyConfigChanged(&virtio);
+}
+
+void VirtioGpuDevice::wakeupWorker(uint16_t uVirtqNbr)
+{
+    if (uVirtqNbr != virtioGpu::VirtqIdx::CONTROLQ and uVirtqNbr != virtioGpu::VirtqIdx::CURSORQ) {
+        LogRel(("%s: tried to wake up unrecognized queue number: %d.\n", szInst.c_str(), uVirtqNbr));
+        return;
+    }
+
+    PVIRTIOGPU_WORKER pWorker {&aWorkers[uVirtqNbr]};
+
+    if (not ASMAtomicXchgBool(&pWorker->fNotified, true)) {
+        /*
+         * Two atomic variables to avoid (at least some) unnecessary signals.
+         * The fNotified variable should suffice to avoid lost signals.
+         */
+        if (ASMAtomicReadBool(&pWorker->fSleeping)) {
+            int rc {RTSemEventSignal(pWorker->hEvent)};
+            AssertRC(rc);
+        }
+    }
+}
+
+template <uint16_t uVirtqNbr>
+static DECLCALLBACK(int) virtQueueHandleFn(RTTHREAD /*hSelf*/, void* pvUser)
+{
+    PVIRTIOGPUDEV pThis {static_cast<PVIRTIOGPUDEV>(pvUser)};
+    return pThis->handleVirtQueue(uVirtqNbr);
+}
+
+auto controlQueueHandleFn {virtQueueHandleFn<virtioGpu::VirtqIdx::CONTROLQ>};
+auto cursorQueueHandleFn {virtQueueHandleFn<virtioGpu::VirtqIdx::CURSORQ>};
+
+int VirtioGpuDevice::startVirtQueues()
+{
+    fTerminateVirtQueues.store(false);
+
+    for (size_t uVirtqNbr {0u}; uVirtqNbr < virtioGpu::NUM_VIRTQUEUES; uVirtqNbr++) {
+        PVIRTIOGPU_VIRTQ pVirtq {&aVirtqs[uVirtqNbr]};
+        PVIRTIOGPU_WORKER pWorker {&aWorkers[uVirtqNbr]};
+
+        auto handlerFn = uVirtqNbr == virtioGpu::VirtqIdx::CONTROLQ ? controlQueueHandleFn : cursorQueueHandleFn;
+        int rc {RTThreadCreate(&pWorker->hThread, handlerFn, this, 0, RTTHREADTYPE_IO, RTTHREADFLAGS_WAITABLE,
+                               pVirtq->szName.c_str())};
+        AssertLogRelReturn(RT_SUCCESS(rc), rc);
+        pWorker->fAssigned = true;
+
+        rc = virtioCoreR3VirtqAttach(&virtio, pVirtq->uIdx, pVirtq->szName.c_str());
+        AssertLogRelReturn(RT_SUCCESS(rc), rc);
+        virtioCoreVirtqEnableNotify(&virtio, pVirtq->uIdx, true);
+        pVirtq->fAttachedToVirtioCore = true;
+    }
+
+    return VINF_SUCCESS;
+}
+
+int VirtioGpuDevice::stopVirtQueues()
+{
+    fTerminateVirtQueues.store(true);
+
+    for (size_t uVirtqNbr {0u}; uVirtqNbr < virtioGpu::NUM_VIRTQUEUES; uVirtqNbr++) {
+        PVIRTIOGPU_VIRTQ pVirtq {&aVirtqs[uVirtqNbr]};
+        PVIRTIOGPU_WORKER pWorker {&aWorkers[uVirtqNbr]};
+
+        if (not pWorker->fAssigned) {
+            continue;
+        }
+
+        int rc = RTSemEventSignal(pWorker->hEvent);
+        AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+        rc = RTThreadWaitNoResume(pWorker->hThread, RT_INDEFINITE_WAIT, nullptr);
+        AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+        pWorker->fAssigned = false;
+        pVirtq->fAttachedToVirtioCore = false;
+    }
+
+    return VINF_SUCCESS;
+}
+
+int VirtioGpuDevice::handleVirtQueue(uint16_t uVirtqNbr)
+{
+    PVIRTIOGPU_VIRTQ pVirtq {&aVirtqs[uVirtqNbr]};
+    PVIRTIOGPU_WORKER pWorker {&aWorkers[uVirtqNbr]};
+    PPDMDEVINS pDevIns {virtio.pDevInsR3};
+
+    LogRel2(("%s: worker thread %d started for %s (virtq idx=%d).\n", szInst.c_str(), pWorker->uIdx,
+             pVirtq->szName.c_str(), pVirtq->uIdx));
+
+    auto is_virtq_empty = [this, &pDevIns, uVirtqNbr]() -> bool {
+        return virtioCoreVirtqAvailBufCount(pDevIns, &virtio, uVirtqNbr) == 0;
+    };
+
+    while (not fTerminateVirtQueues.load()) {
+        if (is_virtq_empty()) {
+            /*
+             * Two atomic variables to avoid (at least some) unnecessary signals.
+             * The fNotified variable should suffice to avoid lost signals.
+             */
+            ASMAtomicWriteBool(&pWorker->fSleeping, true);
+            if (not ASMAtomicXchgBool(&pWorker->fNotified, false)) {
+                int rc {RTSemEventWait(pWorker->hEvent, RT_INDEFINITE_WAIT)};
+                AssertLogRelReturn(RT_SUCCESS(rc) or rc == VERR_INTERRUPTED, rc);
+
+                if (rc == VERR_INTERRUPTED) {
+                    continue;
+                }
+
+                ASMAtomicWriteBool(&pWorker->fNotified, false);
+            }
+            ASMAtomicWriteBool(&pWorker->fSleeping, false);
+        }
+
+        if (RT_UNLIKELY(fTerminateVirtQueues.load())) {
+            break;
+        }
+
+        if (is_virtq_empty()) {
+            /*
+             * It may happen that we got an unnecessary signal, thus we double-check
+             * wether the virtq is empty.
+             */
+            continue;
+        }
+
+#ifdef VIRTIO_VBUF_ON_STACK
+        PVIRTQBUF pVirtqBuf = virtioCoreR3VirtqBufAlloc();
+        if (!pVirtqBuf) {
+            LogRel(("Failed to allocate memory for VIRTQBUF\n"));
+            break; /* No point in trying to allocate memory for other descriptor
+                      chains */
+        }
+        int rc {virtioCoreR3VirtqAvailBufGet(pDevIns, &virtio, pVirtq->uIdx, pVirtqBuf, true)};
+#else
+        // The virtq is not empty, we take a buffer from it and handle it.
+        PVIRTQBUF pVirtqBuf {nullptr};
+        int rc {virtioCoreR3VirtqAvailBufGet(pDevIns, &virtio, pVirtq->uIdx, &pVirtqBuf, true)};
+#endif
+
+        if (rc == VERR_NOT_AVAILABLE) {
+            continue;
+        }
+
+        pCmdHandler->handleBuffer(pVirtqBuf);
+        virtioCoreR3VirtqBufRelease(&virtio, pVirtqBuf);
+    }
+
+    return VINF_SUCCESS;
+}
diff --git a/src/VBox/Devices/Graphics/DevVirtioGpu.hpp b/src/VBox/Devices/Graphics/DevVirtioGpu.hpp
new file mode 100644
index 0000000..72474ed
--- /dev/null
+++ b/src/VBox/Devices/Graphics/DevVirtioGpu.hpp
@@ -0,0 +1,373 @@
+/*
+ * Copyright (C) Cyberus Technology GmbH.
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <https://www.gnu.org/licenses/>.
+ *
+ * SPDX-License-Identifier: GPL-3.0-or-later
+ */
+
+#pragma once
+
+#include <iprt/mem.h>
+
+#include <VBox/vmm/pdmapi.h>
+#include <VBox/vmm/pdmdev.h>
+#include <VBox/vmm/vm.h>
+
+#include "../VirtIO/VirtioCore.h"
+#include "DevVirtioGpuDefinitions.hpp"
+#include "DevVirtioGpuDisplayManager.hpp"
+#include "DevVirtioGpuCmdHandler.hpp"
+#include "DevVirtioGpuResource.hpp"
+
+#include <atomic>
+#include <cstdint>
+#include <functional>
+#include <memory>
+#include <string>
+
+class VirtioCoreVirtioAdapter;
+class VirtioGpuMemoryAdapter;
+
+/**
+ * Logging-Level rules for anything inside LOG_GROUP_DEV_VIRTIO_GPU:
+ *   LogRel  - conditions that lead to functions returning early or returning anything other than VINF_SUCCESS
+ *   LogRel2 - logging of things that should only happen once or very few, e.g. creation of a queue or taking over the
+ * driver LogRel5 - informative logging from the virtio-gpu (only DevVirtioGpu.hpp and DevVirtioGpu.cpp, but not the
+ * adapters) LogRel6 - informative logging from any adapter LogRel7 - informative logging from the cmd-handler LogRel8 -
+ * informative logging inside the VBox-Stubs (DevVirtioGpuVBoxStubs.hpp and DevVirtioGpuVBoxStubs.cpp)
+ *
+ * Enabling logging levels 1 and 2 shouldn't lead to too much output (common sense applies), while the other logging
+ * levels may lead to a lot of output.
+ *
+ * If you have access to VirtioGpuDevice::szInst, start your messages with ("%s: ...", virtioGpuDevice.szInst.c_str()).
+ * Otherwise start your messages with a prefix for easy grepping.
+ *
+ * Enable logging for only the virtio-gpu with: 'export VBOX_RELEASE_LOG="-all+dev_virtio_gpu.e.lA.lB" where A and B are
+ * the desired logging levels. You can of course add more logging levels with ".lC.lD...". ".e" automatically enables
+ * logging level 1, i.e. LogRel.
+ *
+ */
+
+class VirtioGpuDevice
+{
+    static constexpr uint16_t FEATURES_OFFERED {virtioGpu::Features::EDID}; ///< The features offered to the guest
+                                                                            ///
+public:
+    /**
+     * Initialize the Virtio GPU
+     *
+     * \param pDevIns The PCI Device Instance
+     * \param iInstance The instance number.
+     * \param u32VRamSize The size of the VRam.
+     * \param cMonitorCount The amount of displays configured for the VM.
+     * \param secondaryController True if this is a secondary graphics controller, e.g. if the active graphics
+     * controller is VGAWithVirtioGpu, false if this is the only graphics controller.
+     *
+     * \return VBox status code
+     */
+    int init(PPDMDEVINS pDevIns, int iInstance, uint32_t u32VRamSize, uint32_t cMonitorCount, bool secondaryController);
+
+    /**
+     * Terminates the Virtio GPU.
+     *
+     * \param pDevIns The PCI Device Instance
+     *
+     * \return VBox status code
+     */
+    int terminate(PPDMDEVINS pDevIns);
+
+    /**
+     * Start the Virtio GPU. This function is called when the driver calls
+     * pfnStatusChanged with fDriverOk != 0.
+     *
+     * \return VBox Status Code
+     */
+    int start();
+
+    /**
+     * Stop the Virtio GPU. This function is called when the driver calls
+     * pfnStatusChanged with fDriverOk == 0.
+     *
+     * \return VBox Status Code
+     */
+    int stop();
+
+    /**
+     * Read from the device-specific configuration.
+     *
+     * \param uOffset The offset into the device-specific configuration
+     * \param pvBuf The buffer in which to save the read data
+     * \param cbToRead The number of bytes to read
+     *
+     * \return VBox Status Code
+     */
+    int readCap(uint32_t uOffset, void* pvBuf, uint32_t cbToRead);
+
+    /**
+     * Write to the device-specific configuration.
+     *
+     * \param uOffset The offset into the device-specific configuration
+     * \param pvBuf The buffer with the bytes to write
+     * \param cbToWrite The number of bytes to write
+     *
+     * \return VBox Status Code
+     */
+    int writeCap(uint32_t uOffset, const void* pvBuf, uint32_t cbToWrite);
+
+    /**
+     * Informs the worker of a virtqueue that it has new buffers.
+     *
+     * \param uVirtqNbr The number of the virtqueue that has new buffers.
+     */
+    void wakeupWorker(uint16_t uVirtqNbr);
+
+    /**
+     * The handler function for the virtqueues.
+     *
+     * \param uVirtqNbr The index of the associcated virtqueue
+     * \param pDevIns The PCI Device Instance
+     *
+     * \return VBox status code
+     */
+    int handleVirtQueue(uint16_t uVirtqNbr);
+
+private:
+    /**
+     * Initialize the Virtio-Core part of the Virtio GPU
+     *
+     * \param pDevIns The PCI Device Instance
+     *
+     * \return VBox status code
+     */
+    int initializeVirtio(PPDMDEVINS pDevIns);
+
+    /**
+     * Initialize the virtqueues, but do NOT start them.
+     *
+     * \return VBox status code.
+     */
+    int initializeVirtQueues();
+
+    /**
+     * Initializes the display, i.e. assigns functions to the driver etc.
+     *
+     * \param u32VRamSize The size of the VRam
+     * \param u32MonitorCount The maximum of attachable monitors
+     *
+     * \return VBox status code.
+     */
+    int initializeDisplay(uint32_t u32VRamSize, uint32_t u32MonitorCount);
+
+    /**
+     * Start the virtqueues, i.e. start the worker-threads and attach the
+     * virtqueues to virtio core.
+     *
+     * \return VBox status code
+     */
+    int startVirtQueues();
+
+    /**
+     * Stop the virtqueues, i.e. stop the worker-threads.
+     *
+     * \return VBox status code
+     */
+    int stopVirtQueues();
+
+    /**
+     * Accesses the device-specific configuration at the given offset using the
+     * given function.
+     *
+     * \param uOffset The offset into the device-specific configuration
+     * \param accessFn The function that is used to access the device-specific configuration
+     *
+     * \return VBox status code
+     */
+    int accessCap(uint32_t uOffset, std::function<void(uint32_t*)> accessFn);
+
+public:
+    /* device-specific queue info */
+    typedef struct VirtioGpuVirtQueue
+    {
+        uint16_t uIdx; ///< The index of this virtqueue
+        uint16_t uPadding;
+        std::string szName;         ///< The name of this virtqueue
+        bool fHasWorker;            ///< If set this virtqueue has an associated worker
+        bool fAttachedToVirtioCore; ///< If set this virtqueue is attached to virtio core
+    } VIRTIOGPU_VIRTQ, *PVIRTIOGPU_VIRTQ;
+
+    /* a worker thread of a virtqueue */
+    typedef struct VirtioGpuWorker
+    {
+        RTSEMEVENT hEvent;       ///< The handle of the associated sleep/wake-up semaphore
+        RTTHREAD hThread;        ///< The handle of the associated worker-thread
+        uint16_t uIdx;           ///< The index of this worker (should be the same as the index of the associated virtq)
+        bool volatile fSleeping; ///< If set this thread is sleeping
+        bool volatile fNotified; ///< If set this thread has been notified that there is work to do
+        bool fAssigned;          ///< If set this thread has been set up
+    } VIRTIOGPU_WORKER, *PVIRTIOGPU_WORKER;
+
+public:
+    /* virtio core requires that members are public.*/
+    VIRTIOCORE virtio;           // core virtio state
+    virtioGpu::Config gpuConfig; // device specific configuration of the virtio GPU
+
+    VirtioGpuVirtQueue aVirtqs[virtioGpu::NUM_VIRTQUEUES];
+    VirtioGpuWorker aWorkers[virtioGpu::NUM_VIRTQUEUES];
+    std::atomic<bool> fTerminateVirtQueues;
+
+    std::string szInst; // instance name
+
+    uint64_t fNegotiatedFeatures; // features negotiated with the guest
+
+    /* The commands send by the driver are handled by the VirtioGpuCmdHandler. To be able
+     * to test this class using unit-tests, the handler needs a few adapters to be able to control
+     * how pages are mapped, displays are handled and the commands are read.
+     */
+    std::unique_ptr<VirtioGpuCmdHandler> pCmdHandler;
+    std::unique_ptr<VirtioCoreVirtioAdapter> pVirtioAdapter;
+    std::unique_ptr<VirtioGpuDisplayManager> pDisplayManager;
+    std::unique_ptr<VirtioGpuMemoryAdapter> pMemoryAdapter;
+
+public:
+    PDMIBASE IBase;
+    PDMIDISPLAYPORT IPort;
+    PDMIDISPLAYVBVACALLBACKS IVBVACallbacks;
+    PDMIVIRTIOGPUPORT IVirtioGpuPort;
+
+    /**
+     * Signals to the driver that the resolution or the monitor status
+     * (enabled, disabled) has changed.
+     *
+     * \param numDisplays Number of displays available
+     * \param displayDefs Array of display definitions describing the
+     *                    configuration of each display
+     */
+    void displayChanged(uint32_t numDisplays, VMMDevDisplayDef* displayDefs);
+
+    /**
+     * Attaches the Virtio-GPU to the VBox-window.
+     *
+     * \param iLUN The LUN to attach to. This must be 0.
+     *
+     * \return VBox status code
+     */
+    int attachDisplay(unsigned iLUN);
+
+    /**
+     * Detaches the Virtio-GPU driver.
+     *
+     * \param iLUN The LUN to detach from.
+     */
+    void detachDisplay(unsigned iLUN);
+};
+
+/**
+ *  VirtioCore needs a separate class that holds the R3 state
+ */
+class VirtioGpuDeviceR3
+{
+public:
+    VIRTIOCORER3 virtio; // core virtio state R3
+};
+
+typedef VirtioGpuDevice VIRTIOGPUDEV;
+typedef VIRTIOGPUDEV* PVIRTIOGPUDEV;
+
+typedef VirtioGpuDeviceR3 VIRTIOGPUDEVCC;
+typedef VIRTIOGPUDEVCC* PVIRTIOGPUDEVCC;
+
+class VirtioCoreVirtioAdapter final : public VirtioGpuCmdHandler::VirtioAdapter
+{
+    PVIRTIOCORE pVirtio_ {nullptr};
+
+public:
+    VirtioCoreVirtioAdapter() = delete;
+    VirtioCoreVirtioAdapter(PVIRTIOCORE pVirtio) : pVirtio_(pVirtio) {}
+
+    void virtqBufDrain(PVIRTQBUF pVirtqBuf, void* pv, size_t cb) final
+    {
+        virtioCoreR3VirtqBufDrain(pVirtio_, pVirtqBuf, pv, cb);
+    }
+
+    void virtqBufPut(PVIRTQBUF pVirtqBuf, void* pv, size_t cb) final
+    {
+        PRTSGSEG pReturnSeg = static_cast<PRTSGSEG>(RTMemAllocZ(sizeof(RTSGSEG)));
+        AssertReleaseMsg(pReturnSeg != nullptr, ("Out of memory"));
+
+        pReturnSeg->pvSeg = RTMemAllocZ(cb);
+        AssertReleaseMsg(pReturnSeg->pvSeg != nullptr, ("Out of memory"));
+        memcpy(pReturnSeg->pvSeg, pv, cb);
+        pReturnSeg->cbSeg = cb;
+
+        PRTSGBUF pReturnSegBuf = static_cast<PRTSGBUF>(RTMemAllocZ(sizeof(RTSGBUF)));
+        AssertReleaseMsg(pReturnSegBuf, ("Out of memory"));
+
+        RTSgBufInit(pReturnSegBuf, pReturnSeg, 1);
+
+        virtioCoreR3VirtqUsedBufPut(pVirtio_->pDevInsR3, pVirtio_, pVirtqBuf->uVirtq, pReturnSegBuf, pVirtqBuf,
+                                    true /* fFence */);
+
+        RTMemFree(pReturnSeg->pvSeg);
+        RTMemFree(pReturnSeg);
+        RTMemFree(pReturnSegBuf);
+    }
+
+    void virtqSyncRings(PVIRTQBUF pVirtqBuf) final
+    {
+        virtioCoreVirtqUsedRingSync(pVirtio_->pDevInsR3, pVirtio_, pVirtqBuf->uVirtq);
+    }
+};
+
+class VirtioGpuMemoryAdapter final : public VirtioGpuCmdHandler::MemoryAdapter
+{
+    PPDMDEVINS pDevIns_ {nullptr};
+
+public:
+    VirtioGpuMemoryAdapter() = delete;
+    VirtioGpuMemoryAdapter(PPDMDEVINS pDevIns) : pDevIns_(pDevIns) {}
+
+    VecMappings mapGCPhys2HCVirt(const VecMemEntries& vBacking)
+    {
+        VecMappings vMapping;
+        vMapping.reserve(vBacking.size());
+
+        for (const auto& backing : vBacking) {
+            size_t currSize {backing.uLength_};
+            /*
+             * PDMDevHlpPhysGCPhys2CCPtr always maps exactly one page, thus it may
+             * happen that we need multiple mappings for one backing-entry
+             */
+            while (currSize != 0) {
+                PPGMPAGEMAPLOCK pLock {new PGMPAGEMAPLOCK};
+                void* vAddr {nullptr};
+                int rc {PDMDevHlpPhysGCPhys2CCPtr(pDevIns_, backing.uAddr_, 0, &vAddr, pLock)};
+                AssertRC(rc);
+                vMapping.emplace_back(vAddr, PAGE_SIZE, pLock);
+                currSize -= PAGE_SIZE;
+            }
+        }
+
+        return vMapping;
+    }
+
+    void releaseMappings(const VecMappings& vMapping)
+    {
+        for (const auto& mapping : vMapping) {
+            PPGMPAGEMAPLOCK pLock {reinterpret_cast<PPGMPAGEMAPLOCK>(mapping.pv_)};
+            PDMDevHlpPhysReleasePageMappingLock(pDevIns_, pLock);
+            delete pLock;
+        }
+    }
+};
diff --git a/src/VBox/Devices/Graphics/DevVirtioGpuCmdHandler.cpp b/src/VBox/Devices/Graphics/DevVirtioGpuCmdHandler.cpp
new file mode 100644
index 0000000..4db05af
--- /dev/null
+++ b/src/VBox/Devices/Graphics/DevVirtioGpuCmdHandler.cpp
@@ -0,0 +1,687 @@
+/*
+ * Copyright (C) Cyberus Technology GmbH.
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <https://www.gnu.org/licenses/>.
+ *
+ * SPDX-License-Identifier: GPL-3.0-or-later
+ */
+
+#define LOG_GROUP LOG_GROUP_DEV_VIRTIO_GPU
+#include "DevVirtioGpuCmdHandler.hpp"
+
+#include <iprt/assert.h>
+
+#include <VBox/log.h>
+#include <VBox/types.h>
+
+#include <cyberus/edid.hpp>
+
+#include <algorithm>
+#include <cstring>
+
+VirtioGpuCmdHandler::VirtioGpuCmdHandler(VirtioAdapter& vAdapter, DisplayManager& dManager, MemoryAdapter& mAdapter,
+                                         uint32_t numScanouts, bool attachDisplayLater)
+    : virtioAdapter_(vAdapter), displayManager_(dManager), memoryAdapter_(mAdapter), numScanouts_(numScanouts)
+{
+    for (unsigned currentScanout {0u}; currentScanout < numScanouts_; currentScanout++) {
+        Scanout scanout {displayManager_};
+        scanout.uScanoutId = currentScanout;
+
+        /* if this is the only graphics controller we want to attach immediately to the display. */
+        if (not attachDisplayLater and scanout.hasDisplay() and not scanout.isAttachedToDisplay()) {
+            scanout.attachDisplay();
+        }
+
+        if (scanout.hasDisplay()) {
+            auto [uWidth, uHeight] = scanout.isAttachedToDisplay() ? scanout.displayDimensions() : getDummySize();
+            scanout.uCurrentWidth = uWidth;
+            scanout.uCurrentHeight = uHeight;
+        }
+
+        activeScanouts.push_back(scanout);
+    }
+
+    LogRel2(("virtio-gpu cmd handler: created. Num of scanouts is %u.\n", activeScanouts.size()));
+}
+
+inline bool VirtioGpuCmdHandler::scanoutExists(uint32_t uScanout)
+{
+    return uScanout <= numScanouts_ - 1;
+}
+
+inline std::optional<VirtioGpuCmdHandler::ScanoutRef> VirtioGpuCmdHandler::getScanout(uint32_t uScanout)
+{
+    if (not scanoutExists(uScanout)) {
+        return {};
+    }
+
+    return activeScanouts.at(uScanout);
+}
+
+inline std::vector<VirtioGpuCmdHandler::ScanoutRef> VirtioGpuCmdHandler::getScanoutsByResource(uint32_t uResourceId)
+{
+    std::vector<ScanoutRef> results;
+    for (auto& scanout : activeScanouts) {
+        if (not(scanout.uResourceId == uResourceId)) {
+            continue;
+        }
+
+        results.emplace_back(std::ref(scanout));
+    }
+
+    return results;
+}
+
+std::optional<VirtioGpuCmdHandler::ScanoutCRef> VirtioGpuCmdHandler::getCScanout(uint32_t uScanout)
+{
+    auto maybeScanout {getScanout(uScanout)};
+
+    if (not maybeScanout.has_value()) {
+        return {};
+    }
+
+    return {std::cref(maybeScanout->get())};
+}
+
+void VirtioGpuCmdHandler::requestResize(uint32_t uScanout, bool enabled, uint32_t uWidth, uint32_t uHeight)
+{
+    auto maybeScanout {getScanout(uScanout)};
+    if (not maybeScanout.has_value()) {
+        LogRel(("virtio-gpu cmd handler: Scanout %d not available\n", uScanout));
+        return;
+    }
+
+    auto& currentScanout {maybeScanout->get()};
+
+    currentScanout.fActive = enabled;
+    if (!enabled) {
+        currentScanout.detachDisplay();
+    }
+
+    currentScanout.uResizedWidth = uWidth;
+    currentScanout.uResizedHeight = uHeight;
+    currentScanout.fResizeRequested = true;
+}
+
+inline void VirtioGpuCmdHandler::resizeScanout(uint32_t uScanout, uint32_t uWidth, uint32_t uHeight)
+{
+    auto maybeScanout {getScanout(uScanout)};
+    if (not maybeScanout.has_value()) {
+        return;
+    }
+
+    auto& currentScanout {maybeScanout->get()};
+    if (uWidth != currentScanout.uCurrentWidth or uHeight != currentScanout.uCurrentHeight
+        or currentScanout.fNeedsResize) {
+        currentScanout.uCurrentWidth = uWidth;
+        currentScanout.uCurrentHeight = uHeight;
+
+        if (currentScanout.isAttachedToDisplay()) {
+            currentScanout.fNeedsResize = false;
+            currentScanout.resizeDisplay();
+        }
+    }
+}
+
+inline VirtioGpuResource* VirtioGpuCmdHandler::getResource(uint32_t uResourceId)
+{
+    auto result {std::find_if(std::begin(vResources_), std::end(vResources_),
+                              [uResourceId](const auto& it) { return uResourceId == it->resourceId(); })};
+
+    return result == std::end(vResources_) ? nullptr : result->get();
+}
+
+inline bool VirtioGpuCmdHandler::createResource(uint32_t uResourceId)
+{
+    if (getResource(uResourceId) != nullptr) {
+        return false;
+    }
+
+    vResources_.emplace_back(new VirtioGpuResource(uResourceId));
+    return true;
+}
+
+inline void VirtioGpuCmdHandler::removeResource(uint32_t uResourceId)
+{
+    auto result {std::find_if(std::begin(vResources_), std::end(vResources_),
+                              [uResourceId](const auto& it) { return uResourceId == it->resourceId(); })};
+
+    if (result != std::end(vResources_)) {
+        vResources_.erase(result);
+    }
+
+    auto scanouts {getScanoutsByResource(uResourceId)};
+    for (auto& scanout : scanouts) {
+        scanout.get().uResourceId = 0;
+    }
+}
+
+void VirtioGpuCmdHandler::handleBuffer(PVIRTQBUF pVirtqBuf)
+{
+    if (pVirtqBuf->cbPhysSend < sizeof(virtioGpu::CtrlHdr)) {
+        LogRel(("virtio-gpu cmd handler: handleBuffer: request buffer of command in virtq %u too small\n",
+                pVirtqBuf->uVirtq));
+        returnResponseNoData(pVirtqBuf, nullptr, virtioGpu::CtrlType::Response::ERR_OUT_OF_MEMORY);
+        return;
+    }
+
+    /*
+     * This lock is a precaution to avoid race conditions. If done right, there are never more than two threads calling
+     * this function, and those two threads shouldn't interfere even if they call this function at the same time.
+     */
+    RTCLock guard(mutex_);
+
+    virtioGpu::CtrlHdr hdr;
+    virtioAdapter_.virtqBufDrain(pVirtqBuf, &hdr, sizeof(hdr));
+
+    switch (static_cast<virtioGpu::CtrlType::Cmd>(hdr.uType)) {
+    case virtioGpu::CtrlType::Cmd::GET_DISPLAY_INFO: cmdGetDisplayInfo(pVirtqBuf, &hdr); break;
+    case virtioGpu::CtrlType::Cmd::GET_EDID: cmdGetEdid(pVirtqBuf, &hdr); break;
+    case virtioGpu::CtrlType::Cmd::RESOURCE_CREATE_2D: cmdResourceCreate2d(pVirtqBuf, &hdr); break;
+    case virtioGpu::CtrlType::Cmd::RESOURCE_UNREF: cmdResourceUnref(pVirtqBuf, &hdr); break;
+    case virtioGpu::CtrlType::Cmd::SET_SCANOUT: cmdSetScanout(pVirtqBuf, &hdr); break;
+    case virtioGpu::CtrlType::Cmd::RESOURCE_FLUSH: cmdResourceFlush(pVirtqBuf, &hdr); break;
+    case virtioGpu::CtrlType::Cmd::TRANSFER_TO_HOST_2D: cmdTransferToHost2d(pVirtqBuf, &hdr); break;
+    case virtioGpu::CtrlType::Cmd::RESOURCE_ATTACH_BACKING: cmdResourceAttachBacking(pVirtqBuf, &hdr); break;
+    case virtioGpu::CtrlType::Cmd::RESOURCE_DETACH_BACKING: cmdResourceDetachBacking(pVirtqBuf, &hdr); break;
+    case virtioGpu::CtrlType::Cmd::UPDATE_CURSOR:
+    case virtioGpu::CtrlType::Cmd::MOVE_CURSOR:
+        if (pVirtqBuf->uVirtq != virtioGpu::VirtqIdx::CURSORQ) {
+            /*
+             * Not sure wether ERR_UNSPEC is the right thing here, but this is
+             * also an odd error.
+             */
+            returnResponseNoData(pVirtqBuf, &hdr, virtioGpu::CtrlType::Response::ERR_UNSPEC);
+        } else {
+            returnResponseNoData(pVirtqBuf, &hdr, virtioGpu::CtrlType::Response::OK_NODATA);
+        }
+        break;
+    default:
+        returnResponseNoData(pVirtqBuf, &hdr, virtioGpu::CtrlType::Response::ERR_UNSPEC);
+        LogRel(("virtio-gpu cmd handler: handleBuffer: got an unrecognized command in virtq %u: %#x\n",
+                pVirtqBuf->uVirtq, hdr.uType));
+    }
+}
+
+inline bool VirtioGpuCmdHandler::checkCtrlqCmd(const char* cmdName, PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr,
+                                               size_t cbSend, size_t cbReturn)
+{
+    /*
+     * we subtract sizeof(virtioGpu::CtrlHdr) from cbSend, because we want to know
+     * wether we are able to drain to payload of a given command from pVirtqBuf.
+     * That way we can write e.g. sizeof(virtioGpu::getEdid) as the fourth argument,
+     * instead of writing sizeof(virtioGpu::getEdid) - sizeof(virtioGpu::CtrlHdr)
+     * every time
+     */
+    cbSend = cbSend == 0 ? 0 : cbSend - sizeof(virtioGpu::CtrlHdr);
+
+    if (pVirtqBuf->uVirtq != virtioGpu::VirtqIdx::CONTROLQ) {
+        LogRel(("virtio-gpu cmd handler: %s: command was in the wrong virtq.\n", cmdName));
+        returnResponseNoData(pVirtqBuf, pCtrlHdr, virtioGpu::CtrlType::Response::ERR_UNSPEC);
+        return false;
+    }
+
+    if (cbSend > 0 and pVirtqBuf->cbPhysSend < cbSend) {
+        LogRel(("virtio-gpu cmd handler: %s: request buffer was too small.\n", cmdName));
+        returnResponseNoData(pVirtqBuf, pCtrlHdr, virtioGpu::CtrlType::Response::ERR_OUT_OF_MEMORY);
+        return false;
+    }
+
+    if (cbReturn > 0 and pVirtqBuf->cbPhysReturn < cbReturn) {
+        LogRel(("virtio-gpu cmd handler: %s: response buffer was too small.\n", cmdName));
+        returnResponseNoData(pVirtqBuf, pCtrlHdr, virtioGpu::CtrlType::Response::ERR_OUT_OF_MEMORY);
+        return false;
+    }
+
+    return true;
+}
+
+inline bool VirtioGpuCmdHandler::checkScanoutId(const char* cmdName, PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr,
+                                                uint32_t uScanoutId)
+{
+    auto maybeScanout {getScanout(uScanoutId)};
+    if (not maybeScanout.has_value()) {
+        LogRel(("virtio-gpu cmd handler: %s: unknown scanout id %u\n", cmdName, uScanoutId));
+        returnResponseNoData(pVirtqBuf, pCtrlHdr, virtioGpu::CtrlType::Response::ERR_INVALID_SCANOUT_ID);
+        return false;
+    }
+
+    auto& currentScanout {maybeScanout->get()};
+    if (not currentScanout.hasDisplay()) {
+        LogRel(("virtio-gpu cmd handler: %s: scanout %u has no display.\n", cmdName, uScanoutId));
+        returnResponseNoData(pVirtqBuf, pCtrlHdr, virtioGpu::CtrlType::Response::ERR_INVALID_SCANOUT_ID);
+        return false;
+    }
+
+    return true;
+}
+
+inline bool VirtioGpuCmdHandler::checkResourceId(const char* cmdName, PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr,
+                                                 uint32_t uResourceId)
+{
+    if (getResource(uResourceId) == nullptr) {
+        LogRel(("virtio-gpu cmd handler: %s: resource id %u does not exist.\n", cmdName, uResourceId));
+        returnResponseNoData(pVirtqBuf, pCtrlHdr, virtioGpu::CtrlType::Response::ERR_INVALID_RESOURCE_ID);
+        return false;
+    }
+    return true;
+}
+
+inline void VirtioGpuCmdHandler::returnResponseOkEarly(PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr)
+{
+    if (not pCtrlHdr->has_flag(virtioGpu::CtrlHdr::Flags::FENCE)) {
+        returnResponseNoData(pVirtqBuf, pCtrlHdr, virtioGpu::CtrlType::Response::OK_NODATA);
+    }
+}
+
+inline void VirtioGpuCmdHandler::returnResponseOkLate(PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr)
+{
+    if (pCtrlHdr->has_flag(virtioGpu::CtrlHdr::Flags::FENCE)) {
+        returnResponseNoData(pVirtqBuf, pCtrlHdr, virtioGpu::CtrlType::Response::OK_NODATA);
+    }
+}
+
+inline void VirtioGpuCmdHandler::returnResponseNoData(PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr,
+                                                      virtioGpu::CtrlType::Response responseType)
+{
+    if (pVirtqBuf->cbPhysReturn < sizeof(virtioGpu::CtrlHdr)) {
+        return;
+    }
+
+    virtioGpu::CtrlHdr response {responseType};
+
+    if (pCtrlHdr != nullptr) {
+        /*
+         * It may happen that the caller of this functions passes a nullptr if
+         * the request buffer of pVirtqBuf is too small for a header.
+         */
+        response.transfer_fence(pCtrlHdr);
+    }
+
+    returnResponseBuf(pVirtqBuf, &response, sizeof(virtioGpu::CtrlHdr));
+}
+
+inline void VirtioGpuCmdHandler::returnResponseBuf(PVIRTQBUF pVirtqBuf, void* pv, size_t cb)
+{
+    virtioAdapter_.virtqBufPut(pVirtqBuf, pv, cb);
+    virtioAdapter_.virtqSyncRings(pVirtqBuf);
+}
+
+void VirtioGpuCmdHandler::cmdGetDisplayInfo(PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr)
+{
+    if (not checkCtrlqCmd("GetDisplayInfo", pVirtqBuf, pCtrlHdr, 0,
+                          virtioGpu::ResponseDisplayInfo::size(numScanouts_))) {
+        return;
+    }
+
+    LogRel7(("virtio-gpu cmd handler: Got GET_DISPLAY_INFO command.\n"));
+    virtioGpu::ResponseDisplayInfo response;
+
+    for (unsigned i {0}; i < numScanouts_; i++) {
+        auto& pmode {response.pmodes[i]};
+        if (scanoutExists(i)) {
+            auto& currentScanout {getScanout(i)->get()};
+
+            /*
+             * Here we should only report scanouts that are already attached to a
+             * display. But this doesn't work if a driver is started later, because
+             * then it wouldn't see any scanouts.
+             */
+            if (not currentScanout.hasDisplay()) {
+                LogRel7(("virtio-gpu cmd handler: Scanout %u has no display.\n", i));
+                continue;
+            }
+
+            if (currentScanout.fResizeRequested) {
+                resizeScanout(i, currentScanout.uResizedWidth, currentScanout.uResizedHeight);
+                currentScanout.fResizeRequested = false;
+            }
+
+            pmode.r.width = currentScanout.uCurrentWidth;
+            pmode.r.height = currentScanout.uCurrentHeight;
+
+            pmode.enabled = currentScanout.fActive;
+
+            continue;
+        }
+    }
+
+    returnResponseBuf(pVirtqBuf, &response, virtioGpu::ResponseDisplayInfo::size(numScanouts_));
+}
+
+template <typename VIRTIO_GPU_CMD>
+static size_t sizeofPayload(VIRTIO_GPU_CMD cmd)
+{
+    return sizeof(cmd) - sizeof(virtioGpu::CtrlHdr);
+}
+
+void VirtioGpuCmdHandler::cmdGetEdid(PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr)
+{
+    if (not checkCtrlqCmd("GetEdid", pVirtqBuf, pCtrlHdr, sizeof(virtioGpu::GetEdid),
+                          sizeof(virtioGpu::ResponseEdid))) {
+        return;
+    }
+
+    virtioGpu::GetEdid request;
+    virtioAdapter_.virtqBufDrain(pVirtqBuf, request.payload(), sizeofPayload(request));
+    LogRel7(("virtio-gpu cmd handler: Got GET_EDID command for scanout %u.\n", request.uScanout));
+
+    if (not checkScanoutId("GetEdid", pVirtqBuf, pCtrlHdr, request.uScanout)) {
+        return;
+    }
+
+    virtioGpu::ResponseEdid response;
+
+    auto& currentScanout {getScanout(request.uScanout)->get()};
+    if (currentScanout.fResizeRequested) {
+        resizeScanout(0, currentScanout.uResizedWidth, currentScanout.uResizedHeight);
+        currentScanout.fResizeRequested = false;
+    }
+
+    auto edid {generateExtendedEdid(currentScanout.uResizedWidth, currentScanout.uResizedHeight)};
+    AssertReleaseMsg(sizeof(edid) <= sizeof(response.aEdid),
+                     ("virtio-gpu cmd handler: GetEdid: Given EDID is too big to be returned to the driver!"));
+    response.uSize = std::min(sizeof(edid), sizeof(response.aEdid));
+    std::memcpy(&response.aEdid, &edid, response.uSize);
+
+    returnResponseBuf(pVirtqBuf, &response, sizeof(virtioGpu::ResponseEdid));
+}
+
+void VirtioGpuCmdHandler::cmdResourceCreate2d(PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr)
+{
+    if (not checkCtrlqCmd("ResourceCreate2D", pVirtqBuf, pCtrlHdr, sizeof(virtioGpu::ResourceCreate2d),
+                          sizeof(virtioGpu::CtrlHdr))) {
+        return;
+    }
+
+    virtioGpu::ResourceCreate2d request;
+    virtioAdapter_.virtqBufDrain(pVirtqBuf, request.payload(), sizeofPayload(request));
+    LogRel7(("virtio-gpu cmd handler: Got RESOURCE_CREATE_2D command. (resource=%u, format=%u, width=%u, height=%u)\n",
+             request.uResourceId, request.uFormat, request.uWidth, request.uHeight));
+
+    if (request.uResourceId == 0) {
+        /*
+         * The driver can disable a scanout in SET_SCANOUT by setting uResourceId to 0. Thus
+         * (even though the specification doesn't say anything about this) we disallow creating
+         * resources with an Id of 0 here.
+         */
+        LogRel(("virtio-gpu cmd handler: ResourceCreate2D: resource id %u can not be used.\n", request.uResourceId));
+        returnResponseNoData(pVirtqBuf, pCtrlHdr, virtioGpu::CtrlType::Response::ERR_INVALID_RESOURCE_ID);
+        return;
+    }
+
+    if (not createResource(request.uResourceId)) {
+        LogRel(("virtio-gpu cmd handler: ResourceCreate2D: resource id %u already in use.\n", request.uResourceId));
+        returnResponseNoData(pVirtqBuf, pCtrlHdr, virtioGpu::CtrlType::Response::ERR_INVALID_RESOURCE_ID);
+        return;
+    }
+
+    /* We currently only support the B8G8R8X8_UNORM pixel format. Thus, in case
+     * the driver uses another format, we print a message to the log.
+     * For some reason, the customers driver uses the B8G8R8A8_UNORM in the first
+     * resource it creates. Thus this format has to be enabled too.
+     */
+    if ((request.uFormat & (virtioGpu::Format::B8G8R8A8_UNORM | virtioGpu::Format::B8G8R8X8_UNORM)) == 0) {
+        LogRel(("virtio-gpu cmd handler: ResourceCreate2D: An unsupported pixel-format has been set. This virtio-gpu "
+                "currently only supports B8G8R8X8_UNORM.\n"));
+    }
+
+    returnResponseOkEarly(pVirtqBuf, pCtrlHdr);
+
+    auto* resource {getResource(request.uResourceId)};
+    resource->format(request.uFormat);
+    resource->size(request.uWidth, request.uHeight);
+
+    returnResponseOkLate(pVirtqBuf, pCtrlHdr);
+}
+
+void VirtioGpuCmdHandler::cmdResourceUnref(PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr)
+{
+    if (not checkCtrlqCmd("ResourceUnref", pVirtqBuf, pCtrlHdr, sizeof(virtioGpu::ResourceUnref),
+                          sizeof(virtioGpu::CtrlHdr))) {
+        return;
+    }
+
+    virtioGpu::ResourceUnref request;
+    virtioAdapter_.virtqBufDrain(pVirtqBuf, request.payload(), sizeofPayload(request));
+    LogRel7(("virtio-gpu cmd handler: Got RESOURCE_UNREF command. (resource=%u)\n", request.uResourceId));
+
+    if (not checkResourceId("ResourceUnref", pVirtqBuf, pCtrlHdr, request.uResourceId)) {
+        return;
+    }
+
+    returnResponseOkEarly(pVirtqBuf, pCtrlHdr);
+
+    removeResource(request.uResourceId);
+
+    returnResponseOkLate(pVirtqBuf, pCtrlHdr);
+}
+
+void VirtioGpuCmdHandler::cmdSetScanout(PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr)
+{
+    if (not checkCtrlqCmd("SetScanout", pVirtqBuf, pCtrlHdr, sizeof(virtioGpu::SetScanout),
+                          sizeof(virtioGpu::CtrlHdr))) {
+        return;
+    }
+
+    virtioGpu::SetScanout request;
+    virtioAdapter_.virtqBufDrain(pVirtqBuf, request.payload(), sizeofPayload(request));
+    LogRel7(("virtio-gpu cmd handler: Got SET_SCANOUT command. (scanout=%u, resource=%u, rect=w:%u,h:%u,x:%u,y:%u)\n",
+             request.uScanoutId, request.uResourceId, request.r.width, request.r.height, request.r.x, request.r.y));
+
+    if (not checkScanoutId("SetScanout", pVirtqBuf, pCtrlHdr, request.uScanoutId)) {
+        return;
+    }
+
+    auto& currentScanout {getScanout(request.uScanoutId)->get()};
+    if (request.uResourceId == 0) {
+        LogRel2(("virtio-gpu cmd handler: SetScanout: Driver disabled scanout %u\n", request.uScanoutId));
+        currentScanout.fActive = false;
+        currentScanout.fNeedsResize = true;
+        currentScanout.detachDisplay();
+        returnResponseNoData(pVirtqBuf, pCtrlHdr, virtioGpu::CtrlType::Response::OK_NODATA);
+        return;
+    }
+
+    if (not checkResourceId("SetScanout", pVirtqBuf, pCtrlHdr, request.uResourceId)) {
+        return;
+    }
+
+    returnResponseOkEarly(pVirtqBuf, pCtrlHdr);
+
+    currentScanout.fActive = true;
+    currentScanout.uResourceId = request.uResourceId;
+    if (not currentScanout.isAttachedToDisplay()) {
+        currentScanout.attachDisplay();
+        currentScanout.fNeedsResize = true;
+    }
+
+    resizeScanout(request.uScanoutId, request.r.width, request.r.height);
+
+    returnResponseOkLate(pVirtqBuf, pCtrlHdr);
+}
+
+void VirtioGpuCmdHandler::cmdResourceFlush(PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr)
+{
+    if (not checkCtrlqCmd("ResourceFlush", pVirtqBuf, pCtrlHdr, sizeof(virtioGpu::ResourceFlush),
+                          sizeof(virtioGpu::CtrlHdr))) {
+        return;
+    }
+
+    virtioGpu::ResourceFlush request;
+    virtioAdapter_.virtqBufDrain(pVirtqBuf, request.payload(), sizeofPayload(request));
+    LogRel7(("virtio-gpu cmd handler: Got RESOURCE_FLUSH command. (resource=%u, rect=w:%u,h:%u,x:%u,y:%u)\n",
+             request.uResourceId, request.r.width, request.r.height, request.r.x, request.r.y));
+
+    if (not checkResourceId("ResourceFlush", pVirtqBuf, pCtrlHdr, request.uResourceId)) {
+        return;
+    }
+
+    auto scanouts {getScanoutsByResource(request.uResourceId)};
+    if (scanouts.empty()) {
+        LogRel(
+            ("virtio-gpu cmd handler: ResourceFlush: No scanout is assigned to resource %u.\n", request.uResourceId));
+        returnResponseNoData(pVirtqBuf, pCtrlHdr, virtioGpu::CtrlType::Response::ERR_INVALID_RESOURCE_ID);
+        return;
+    }
+
+    returnResponseOkEarly(pVirtqBuf, pCtrlHdr);
+
+    for (auto& scanout : scanouts) {
+        if (scanout.get().hasDisplay()) {
+            scanout.get().flush();
+        }
+    }
+
+    returnResponseOkLate(pVirtqBuf, pCtrlHdr);
+}
+
+void VirtioGpuCmdHandler::cmdTransferToHost2d(PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr)
+{
+    if (not checkCtrlqCmd("TransferToHost2D", pVirtqBuf, pCtrlHdr, sizeof(virtioGpu::TransferToHost2d),
+                          sizeof(virtioGpu::CtrlHdr))) {
+        return;
+    }
+
+    virtioGpu::TransferToHost2d request;
+    virtioAdapter_.virtqBufDrain(pVirtqBuf, request.payload(), sizeofPayload(request));
+    LogRel7(("virtio-gpu cmd handler: Got TRANSFER_TO_HOST_2D command. (resource=%u, offset=%lu, "
+             "rect=w:%u,h:%u,x:%u,y:%u)\n",
+             request.uResourceId, request.uOffset, request.r.width, request.r.height, request.r.x, request.r.y));
+
+    if (not checkResourceId("TransferToHost2D", pVirtqBuf, pCtrlHdr, request.uResourceId)) {
+        return;
+    }
+
+    auto scanouts {getScanoutsByResource(request.uResourceId)};
+    if (scanouts.empty()) {
+        LogRel(
+            ("virtio-gpu cmd handler: ResourceFlush: No scanout is assigned to resource %u.\n", request.uResourceId));
+        returnResponseNoData(pVirtqBuf, pCtrlHdr, virtioGpu::CtrlType::Response::ERR_INVALID_RESOURCE_ID);
+        return;
+    }
+
+    returnResponseOkEarly(pVirtqBuf, pCtrlHdr);
+
+    auto* resource {getResource(request.uResourceId)};
+    auto vMapping {memoryAdapter_.mapGCPhys2HCVirt(resource->getBacking())};
+
+    PRTSGSEG paSegments {static_cast<PRTSGSEG>(RTMemAllocZ(sizeof(RTSGSEG) * vMapping.size()))};
+    for (auto idx {0u}; idx < vMapping.size(); idx++) {
+        const auto& mapping {vMapping.at(idx)};
+        paSegments[idx].pvSeg = mapping.uAddr_;
+        paSegments[idx].cbSeg = mapping.uLength_;
+    }
+
+    PRTSGBUF pSegBuf {static_cast<PRTSGBUF>(RTMemAllocZ(sizeof(RTSGBUF)))};
+
+    for (auto& wrappedScanout : scanouts) {
+        auto& scanout {wrappedScanout.get()};
+        if (not scanout.fActive) {
+            LogRel(("virtio-gpu cmd handler: TransferToHost2D: Prevented copying into disabled scanout %u.\n",
+                    scanout.uScanoutId));
+            continue;
+        }
+
+        /*
+         * If the size is 64x64, then this is the resource of the mouse cursor.
+         * As we currently ignore the cursorq, we just do nothing in this case.
+         */
+        if ((resource->width() > 64u and resource->height() > 64u) and scanout.hasDisplay()
+            and resource->getBacking().size() > 0
+            /*
+             * TODO: at the moment we always assume that offset=0 and r.x=0 and r.y=0,
+             * i.e. the driver always sends a full frame, not just parts of a frame.
+             * This is currently only used by Linux and not by the customers driver,
+             * thus we ignore cases where this assumption isn't true.
+             */
+            and request.r == virtioGpu::Rect {resource->width(), resource->height()}) {
+            RTSgBufInit(pSegBuf, paSegments, vMapping.size());
+            auto [pFrameBuffer, cbFrameBuffer] {scanout.rDisplayManager.acquireBackingStore(scanout.uScanoutId)};
+            if (pFrameBuffer != nullptr) {
+                RTSgBufCopyToBuf(pSegBuf, pFrameBuffer, cbFrameBuffer);
+            }
+            scanout.rDisplayManager.releaseBackingStore();
+        }
+    }
+
+    RTMemFree(pSegBuf);
+    RTMemFree(paSegments);
+
+    memoryAdapter_.releaseMappings(vMapping);
+
+    returnResponseOkLate(pVirtqBuf, pCtrlHdr);
+}
+
+void VirtioGpuCmdHandler::cmdResourceAttachBacking(PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr)
+{
+    if (not checkCtrlqCmd("ResourceAttachBacking", pVirtqBuf, pCtrlHdr, sizeof(virtioGpu::ResourceAttachBacking),
+                          sizeof(virtioGpu::CtrlHdr))) {
+        return;
+    }
+
+    virtioGpu::ResourceAttachBacking request;
+    virtioAdapter_.virtqBufDrain(pVirtqBuf, request.payload(), sizeofPayload(request));
+    LogRel7(("virtio-gpu cmd handler: Got RESOURCE_ATTACH_BACKING command. (resource=%u)\n", request.uResourceId));
+
+    if (pVirtqBuf->cbPhysSend < (request.uNrEntries * sizeof(virtioGpu::ResourceMemEntry))) {
+        LogRel(("virtio-gpu cmd handler: ResourceAttachBacking: request buffer too small for all memory entries.\n"));
+        returnResponseNoData(pVirtqBuf, pCtrlHdr, virtioGpu::CtrlType::Response::ERR_OUT_OF_MEMORY);
+        return;
+    }
+
+    if (not checkResourceId("ResourceAttachBacking", pVirtqBuf, pCtrlHdr, request.uResourceId)) {
+        return;
+    }
+
+    returnResponseOkEarly(pVirtqBuf, pCtrlHdr);
+
+    auto* resource {getResource(request.uResourceId)};
+    resource->reserveBacking(request.uNrEntries);
+
+    const size_t cbEntries {sizeof(virtioGpu::ResourceMemEntry) * request.uNrEntries};
+    virtioGpu::ResourceMemEntry* pEntries {static_cast<virtioGpu::ResourceMemEntry*>(RTMemAlloc(cbEntries))};
+    virtioAdapter_.virtqBufDrain(pVirtqBuf, pEntries, cbEntries);
+
+    for (auto idx {0u}; idx < request.uNrEntries; idx++) {
+        resource->addBacking(pEntries[idx].uAddr, pEntries[idx].uLength);
+    }
+
+    RTMemFree(pEntries);
+
+    returnResponseOkLate(pVirtqBuf, pCtrlHdr);
+}
+
+void VirtioGpuCmdHandler::cmdResourceDetachBacking(PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr)
+{
+    if (not checkCtrlqCmd("ResourceDetachBacking", pVirtqBuf, pCtrlHdr, sizeof(virtioGpu::ResourceDetachBacking),
+                          sizeof(virtioGpu::CtrlHdr))) {
+        return;
+    }
+
+    virtioGpu::ResourceDetachBacking request;
+    virtioAdapter_.virtqBufDrain(pVirtqBuf, request.payload(), sizeofPayload(request));
+    LogRel7(("virtio-gpu cmd handler: Got RESOURCE_DETACH_BACKING command. (resource=%u)\n", request.uResourceId));
+
+    if (not checkResourceId("ResourceDetachBacking", pVirtqBuf, pCtrlHdr, request.uResourceId)) {
+        return;
+    }
+
+    returnResponseOkEarly(pVirtqBuf, pCtrlHdr);
+
+    auto* resource {getResource(request.uResourceId)};
+    resource->clearBacking();
+
+    returnResponseOkLate(pVirtqBuf, pCtrlHdr);
+}
diff --git a/src/VBox/Devices/Graphics/DevVirtioGpuCmdHandler.hpp b/src/VBox/Devices/Graphics/DevVirtioGpuCmdHandler.hpp
new file mode 100644
index 0000000..7cf4bf5
--- /dev/null
+++ b/src/VBox/Devices/Graphics/DevVirtioGpuCmdHandler.hpp
@@ -0,0 +1,353 @@
+/*
+ * Copyright (C) Cyberus Technology GmbH.
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <https://www.gnu.org/licenses/>.
+ *
+ * SPDX-License-Identifier: GPL-3.0-or-later
+ */
+
+#pragma once
+
+#include <VBox/types.h>
+#include <VBox/vmm/pdmdev.h>
+#include <VBox/vmm/stam.h>
+
+#include <iprt/mem.h>
+#include <iprt/cpp/lock.h>
+
+#include "../VirtIO/VirtioCore.h"
+
+#include "DevVirtioGpuResource.hpp"
+#include "DevVirtioGpuDefinitions.hpp"
+
+#include <array>
+#include <functional>
+#include <memory>
+#include <optional>
+#include <tuple>
+#include <vector>
+
+class VirtioGpuCmdHandler
+{
+public:
+    /**
+     * A VirtioAdapter encapsulates functions to receive data from a virtq,
+     * put data into a virtq and signal to the guest that there is new data
+     * in a virtq.
+     */
+    class VirtioAdapter
+    {
+    public:
+        /* Drains cb bytes from the pVirtqBuf into pv. */
+        virtual void virtqBufDrain(PVIRTQBUF pVirtqBuf, void* pv, size_t cb) = 0;
+
+        /* Puts pv into the used ring and thus sends data to the guest. */
+        virtual void virtqBufPut(PVIRTQBUF pVirtqBuf, void* pv, size_t cb) = 0;
+
+        /* Informs the guest driver about new data in the virtq. */
+        virtual void virtqSyncRings(PVIRTQBUF pVirtqBuf) = 0;
+    };
+
+    /**
+     * The DisplayManager is the interface to the virtual displays provided by
+     * the hypervisor platform.
+     * It is responsible for updating the dimensions and the frames of the
+     * virtual displays according to the data in the scanouts.
+     */
+    class DisplayManager
+    {
+    public:
+        /**
+         * The Backing store information
+         */
+        using BackingStoreInfo = std::pair<void*, size_t>;
+        using Dimension = std::pair<uint32_t, uint32_t>;
+
+        /**
+         * Check whether the display index is managed by the Manager.
+         *
+         * \param displayIndex The display index.
+         *
+         * \return true if the display is managed, false otherwise
+         */
+        virtual bool isManaged(uint32_t displayIndex) = 0;
+
+        /**
+         * Obtain the dimensions of the given display.
+         *
+         * \param displayIndex The display index
+         *
+         * \return the dimension of the display or <0,0> if not managed
+         */
+        virtual Dimension displayDimension(uint32_t displayIndex) = 0;
+
+        /**
+         * Resize the given display to the given width and height.
+         *
+         * \param displayIndex The display index
+         * \param uWidth display width
+         * \param uHeigth display height
+         * \param i32OriginX The x position of the display to resize
+         * \param i32OriginY The y position of the display to resize
+         */
+        virtual void resize(uint32_t displayIndex, uint32_t uWidth, uint32_t uHeight,
+                            std::optional<int32_t> i32OriginX = std::nullopt,
+                            std::optional<int32_t> i32OriginY = std::nullopt) = 0;
+
+        /**
+         * Attaches the virtio-gpu to the given display.
+         *
+         * \param displayIndex The display index
+         */
+        virtual int attachDisplay(uint32_t displayIndex) = 0;
+
+        /**
+         * Detaches the virtio-gpu from the given display.
+         *
+         * \param displayIndex The display index
+         */
+        virtual void detachDisplay(uint32_t displayIndex) = 0;
+
+        /**
+         * Check attachment status of the given display.
+         *
+         * \param displayIndex The display index
+         *
+         * \return true if the display is attached, false otherwise.
+         */
+        virtual bool isAttached(uint32_t displayIndex) = 0;
+
+        /**
+         * Displays the framebuffer content on the display.
+         *
+         * \param displayIndex The display index
+         */
+        virtual void display(uint32_t displayIndex) = 0;
+
+        /**
+         * Obtain backing store information.
+         *
+         * \param displayIndex The display index
+         *
+         * \return Backing store information
+         */
+        virtual BackingStoreInfo acquireBackingStore(uint32_t displayIndex) = 0;
+
+        /**
+         * Releases the backing store, after an update of the frame buffer is done.
+         */
+        virtual void releaseBackingStore() = 0;
+    };
+
+    /**
+     * A memoryAdapter is used to map guest physical addresses into the host's
+     * address space and to also unmap these mappings.
+     */
+    class MemoryAdapter
+    {
+    protected:
+        struct VirtioGpuMapping
+        {
+            void* uAddr_;            // The host virtual address
+            const uint32_t uLength_; // The size of the mapping
+            void* pv_;               // A pointer to data the adapter may need to free this mapping later
+
+            VirtioGpuMapping() = delete;
+            VirtioGpuMapping(void* uAddr, const uint32_t uLength, void* pv) : uAddr_(uAddr), uLength_(uLength), pv_(pv)
+            {}
+        };
+
+        using VecMemEntries = std::vector<VirtioGpuResource::MemEntry>;
+        using VecMappings = std::vector<VirtioGpuMapping>;
+
+    public:
+        /**
+         * Translates the guest physical addresses given in vBacking into host
+         * virtual addresses.
+         */
+        virtual VecMappings mapGCPhys2HCVirt(const VecMemEntries& vBacking) = 0;
+
+        /**
+         * Returns the mappings to the adapter so the adapter can do whatever
+         * is necessary.
+         */
+        virtual void releaseMappings(const VecMappings& vMapping) = 0;
+    };
+
+private:
+    VirtioAdapter& virtioAdapter_;
+    DisplayManager& displayManager_;
+    MemoryAdapter& memoryAdapter_;
+    const uint32_t numScanouts_;
+    RTCLockMtx mutex_;
+
+    struct Scanout
+    {
+        uint32_t uScanoutId {0};
+        uint32_t uResourceId {0};
+        uint32_t uCurrentWidth {0};
+        uint32_t uCurrentHeight {0};
+        uint32_t uResizedWidth {0u};
+        uint32_t uResizedHeight {0u};
+        bool fActive {false};
+        bool fNeedsResize {true};
+        bool fResizeRequested {false};
+
+        DisplayManager& rDisplayManager;
+
+        Scanout() = delete;
+        Scanout(DisplayManager& dManager) : rDisplayManager(dManager) {}
+
+        bool hasDisplay() const { return rDisplayManager.isManaged(uScanoutId); }
+
+        bool isAttachedToDisplay() const { return hasDisplay() and rDisplayManager.isAttached(uScanoutId); }
+
+        void attachDisplay() const
+        {
+            if (hasDisplay() and not isAttachedToDisplay()) {
+                rDisplayManager.attachDisplay(uScanoutId);
+            }
+        }
+
+        void detachDisplay() const
+        {
+            if (isAttachedToDisplay()) {
+                rDisplayManager.detachDisplay(uScanoutId);
+            }
+        }
+
+        DisplayManager::Dimension displayDimensions() const { return rDisplayManager.displayDimension(uScanoutId); }
+
+        void resizeDisplay() { rDisplayManager.resize(uScanoutId, uCurrentWidth, uCurrentHeight); }
+
+        void flush() { rDisplayManager.display(uScanoutId); }
+    };
+
+    using ScanoutRef = std::reference_wrapper<Scanout>;
+    using ScanoutCRef = std::reference_wrapper<const Scanout>;
+
+    std::vector<std::unique_ptr<VirtioGpuResource>> vResources_;
+
+    /* Returns a pointer to the resource with the given ID, or a nullptr if there is no resource with the given ID. */
+    inline VirtioGpuResource* getResource(uint32_t uResourceId);
+
+    /* Creates a resource with the given ID. Returns false if the ID was already in use, true otherwise. */
+    inline bool createResource(uint32_t uResourceId);
+
+    /* Removes the resource with the given ID. */
+    inline void removeResource(uint32_t uResourceId);
+
+    std::vector<Scanout> activeScanouts;
+
+    /* Returns true if the given scanout is in the range of existing scanouts (0 to NUM_MAX_SCANOUTS-1), false otherwise
+     */
+    inline bool scanoutExists(uint32_t uScanout);
+
+    /* Returns a reference to a scanout if the given scanout exists, an empty optional otherwise. */
+    inline std::optional<ScanoutRef> getScanout(uint32_t uScanout);
+
+    /**
+     * Returns a vector filled with references to all scanouts with the given resourceId, or an empty optional if no
+     * scanout is assigned to the given resourceId.
+     */
+    inline std::vector<ScanoutRef> getScanoutsByResource(uint32_t uResourceId);
+
+    /* Returns a dummy size to initialize the scanouts in case we are a secondary graphics controller. */
+    inline std::tuple<uint32_t, uint32_t> getDummySize()
+    {
+        return std::make_tuple(virtioGpu::INITIAL_WIDTH, virtioGpu::INITIAL_HEIGHT);
+    }
+
+public:
+    VirtioGpuCmdHandler() = delete;
+    VirtioGpuCmdHandler(VirtioAdapter& vAdapter, DisplayManager& dManager, MemoryAdapter& mAdapter,
+                        uint32_t numScanouts, bool attachDisplayLater);
+
+    ~VirtioGpuCmdHandler() = default;
+
+    /* Destroys all existing resources. */
+    void clearResources() { vResources_.clear(); }
+
+    /**
+     * Returns a const reference to the scanout with the given ID if it exists.
+     * That way another class working with the cmdHandler can't modify the scanouts.
+     */
+    std::optional<ScanoutCRef> getCScanout(uint32_t uScanout);
+
+    /**
+     * Requests resizing of the monitor. Sets the uResizedWidth and uResizedHeight variables of the associated scanout
+     * and sets scanout.fResizeRequested to true. The next getDisplayInfo or getEdid will then use the new resolution.
+     */
+    void requestResize(uint32_t uScanout, bool enabled, uint32_t uWidth, uint32_t uHeight);
+
+    /** Updates the current width and height of the given scanout and resizes display if necessary. */
+    inline void resizeScanout(uint32_t uScanout, uint32_t uWidth, uint32_t uHeight);
+
+    /* Handles the given virtq buffer and returns a response to the driver. */
+    void handleBuffer(PVIRTQBUF pVirtqBuf);
+
+    /* Does some basic sanity checking and returns an appropriate error to the guest if something is broken. */
+    inline bool checkCtrlqCmd(const char* cmdName, PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr, size_t cbSend,
+                              size_t cbReturn);
+
+    /* Checks wether the given scanout id is valid and returns a ERR_INVALID_SCANOUT_ID header to the guest if it isn't.
+     */
+    inline bool checkScanoutId(const char* cmdName, PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr,
+                               uint32_t uScanoutId);
+
+    /* Checks wether the given resource id is valid and returns a ERR_INVALID_RESOURCE_ID header to the guest if it
+     * isn't. */
+    inline bool checkResourceId(const char* cmdName, PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr,
+                                uint32_t uResourceId);
+
+    /* Returns a CtrlType::Response::OK_NODATA if the FENCE-flag is not set */
+    inline void returnResponseOkEarly(PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr);
+
+    /* Returns a CtrlType::Response::OK_NODATA if the FENCE-flag is set */
+    inline void returnResponseOkLate(PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr);
+
+    /* Returns a header with the given resonseType to the driver. */
+    inline void returnResponseNoData(PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr,
+                                     virtioGpu::CtrlType::Response responseType);
+
+    /* Returns a response buffer to the driver. */
+    inline void returnResponseBuf(PVIRTQBUF pVirtqBuf, void* pv, size_t cb);
+
+    /* Returns the current output configureation to the driver. */
+    void cmdGetDisplayInfo(PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr);
+
+    /* Return the EDID data for a given scanout to the driver. */
+    void cmdGetEdid(PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr);
+
+    /* Creates a 2D resource on the host. */
+    void cmdResourceCreate2d(PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr);
+
+    /* Destroys a 2D resource. */
+    void cmdResourceUnref(PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr);
+
+    /* Sets the scanout parameters for a given output. */
+    void cmdSetScanout(PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr);
+
+    /* Flushes a resource to the screen. */
+    void cmdResourceFlush(PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr);
+
+    /* Transfers guest memory to host memory. */
+    void cmdTransferToHost2d(PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr);
+
+    /* Attaches backing pages to a resource. */
+    void cmdResourceAttachBacking(PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr);
+
+    /* Removes backing pages from a resource. */
+    void cmdResourceDetachBacking(PVIRTQBUF pVirtqBuf, virtioGpu::CtrlHdr* pCtrlHdr);
+};
diff --git a/src/VBox/Devices/Graphics/DevVirtioGpuDefinitions.hpp b/src/VBox/Devices/Graphics/DevVirtioGpuDefinitions.hpp
new file mode 100644
index 0000000..fbb2fa7
--- /dev/null
+++ b/src/VBox/Devices/Graphics/DevVirtioGpuDefinitions.hpp
@@ -0,0 +1,360 @@
+/*
+ * Copyright (C) Cyberus Technology GmbH.
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <https://www.gnu.org/licenses/>.
+ *
+ * SPDX-License-Identifier: GPL-3.0-or-later
+ */
+
+#pragma once
+
+#include <cstdint>
+
+namespace virtioGpu
+{
+
+constexpr uint32_t INITIAL_WIDTH {1920u};
+constexpr uint32_t INITIAL_HEIGHT {1080u};
+
+/**
+ * Virtio 1.2 - 4.1.2 PCI Device Discovery
+ * The PCI Device ID is calculated by adding 0x1040 to the Virtio Device ID.
+ */
+enum : uint16_t
+{
+    DEVICE_ID = 16,
+    PCI_DEVICE_ID = 0x1040 + DEVICE_ID,
+    PCI_CLASS_BASE = 0x03, ///< GPU
+    PCI_CLASS_SUB = 0x00,  ///< VGA compatible
+    PCI_CLASS_PROG = 0x00, ///< Unspecified
+    PCI_INTERRUPT_LINE = 0x00,
+    PCI_INTERRUPT_PIN = 0x01,
+};
+
+/**
+ * Virtio 1.2 - 5.7.1 GPU Device Feature bits
+ */
+enum Features : uint16_t
+{
+    VIRGIL = 1u << 0,        ///< virgl 3D mode is supported
+    EDID = 1u << 1,          ///< EDID (Extended Display Identification Data) is supported
+    RESOURCE_UUID = 1u << 2, ///< assigning resources UUIDs for export to other virtio devices is supported
+    RESOURCE_BLOB = 1u << 3, ///< creating and using size-based blob resources is supported
+    CONTEXT_INIT = 1u << 4,  ///< multiple context types and synchronization timelines supported
+};
+
+/**
+ * Virtio 1.2 - 5.7.2 GPU Device Virtqueues
+ */
+constexpr unsigned NUM_VIRTQUEUES {2u};
+
+enum VirtqIdx : uint16_t
+{
+    CONTROLQ = 0, ///< The index of the controlqueue
+    CURSORQ = 1,  ///< The index of the cursorqueue
+};
+
+/**
+ * Virtio 1.2 - 5.7.4 GPU Device configuration layout
+ * Virtio GPU device-specific configuration
+ */
+struct Config
+{
+    uint32_t uEventsRead {0u};  ///< Signals pending events to the driver
+    uint32_t uEventsClear {0u}; ///< Clears pending events in the device (write-to-clear)
+    uint32_t uNumScanouts {0u}; ///< Maximum number of scanouts supported (between 1 and 16 inclusive)
+    uint32_t uNumCapsets {0u};  ///< Maximum number of capability sets supported
+};
+
+static constexpr uint32_t EVENT_DISPLAY {
+    1u << 0}; ///< display configuration has changed and should be fetched by the driver
+
+/**
+ * Virtio 1.2 - 5.7.6.7 GPU Device Device Operation: Request header
+ */
+struct CtrlType
+{
+    enum Cmd : uint32_t
+    {
+        /* 2d commands */
+        GET_DISPLAY_INFO = 0x0100,
+        RESOURCE_CREATE_2D,
+        RESOURCE_UNREF,
+        SET_SCANOUT,
+        RESOURCE_FLUSH,
+        TRANSFER_TO_HOST_2D,
+        RESOURCE_ATTACH_BACKING,
+        RESOURCE_DETACH_BACKING,
+        GET_CAPSET_INFO,
+        GET_CAPSET,
+        GET_EDID,
+        RESOURCE_ASSIGN_UUID,
+        RESOURCE_ASSIGN_BLOB,
+        SET_SCANOUT_BLOB,
+
+        /* 3d commands */
+        CTX_CREATE = 0x0200,
+        CTX_DESTROY,
+        CTX_ATTACH_RESOURCE,
+        CTX_DETACH_RESOURCE,
+        RESOURCE_CREATE_3D,
+        TRANSFER_TO_HOST_3D,
+        TRANSFER_FROM_HOST_3D,
+        SUBMIT_3D,
+        RESOURCE_MAP_BLOB,
+        RESOURCE_UNMAP_BLOB,
+
+        /* cursor commands */
+        UPDATE_CURSOR = 0x0300,
+        MOVE_CURSOR,
+    };
+
+    enum Response : uint32_t
+    {
+        /* success responses */
+        OK_NODATA = 0x1100,
+        OK_DISPLAY_INFO,
+        OK_CAPSET_INFO,
+        OK_CAPSET,
+        OK_EDID,
+        OK_RESOURCE_UUID,
+        OK_MAP_INFO,
+
+        /* error responses */
+        ERR_UNSPEC = 0x1200,
+        ERR_OUT_OF_MEMORY,
+        ERR_INVALID_SCANOUT_ID,
+        ERR_INVALID_RESOURCE_ID,
+        ERR_INVALID_CONTEXT_ID,
+        ERR_INVALID_PARAMETER,
+    };
+};
+
+/**
+ * Virtio 1.2 - 5.7.6.8 GPU Device Operation: controlq
+ * VIRTIO_GPU_CMD_RESOURCE_CREATE_2D possible formats
+ */
+struct __attribute__((packed)) CtrlHdr
+{
+    uint32_t uType {0};    ///< type specifies the type of driver request or device response
+    uint32_t uFlags {0};   ///< flags request/response flags
+    uint64_t uFenceId {0}; ///< fence_id only important if FLAG_FENCE bit is set in flags
+    uint32_t uCtxId {0};   ///< ctx_id rendering context (3D mode only)
+    uint8_t uRingIdx {0};  ///< ring_idx
+    uint8_t uPadding[3];
+
+    CtrlHdr() = default;
+    CtrlHdr(uint32_t uCmd) : uType(uCmd) {}
+    CtrlHdr(CtrlType::Cmd uCmd) : uType(uCmd) {}
+
+    enum class Flags : uint32_t
+    {
+        FENCE = 1u << 0,
+        INFO_RING_IDX = 1u << 1,
+    };
+
+    /* Checks whether the given bit is set in uFlags */
+    inline bool has_flag(Flags flag) const { return (uFlags & static_cast<uint32_t>(flag)) != 0; };
+
+    /* Sets the given bit if fSet is true, otherwise clears it. */
+    inline void set_flag(Flags flag, bool fSet)
+    {
+        const uint32_t mask {static_cast<uint32_t>(flag)};
+        uFlags &= ~mask | fSet ? mask : 0u;
+    };
+
+    /* Transfers the fence-flag and uFenceId from other to this. */
+    inline void transfer_fence(const CtrlHdr* other)
+    {
+        if (other->has_flag(Flags::FENCE)) {
+            set_flag(Flags::FENCE, true);
+            uFenceId = other->uFenceId;
+        }
+    }
+};
+
+/*
+ * controlq command structure definitions
+ * See Virtio 1.2 - 5.7.6.8
+ */
+static void* removeHeader(void* pThis)
+{
+    return reinterpret_cast<void*>(reinterpret_cast<uintptr_t>(pThis) + sizeof(CtrlHdr));
+}
+
+struct __attribute__((packed)) Rect
+{
+    uint32_t x {0};
+    uint32_t y {0};
+    uint32_t width {0};
+    uint32_t height {0};
+
+    Rect() = default;
+    Rect(uint32_t w, uint32_t h) : width(w), height(h) {}
+
+    friend bool operator==(const Rect& lhs, const Rect& rhs)
+    {
+        return lhs.x == rhs.x and lhs.y == rhs.y and lhs.width == rhs.width and lhs.height == rhs.height;
+    }
+
+    friend bool operator!=(const Rect& lhs, const Rect& rhs) { return not(lhs == rhs); }
+};
+
+struct __attribute__((packed)) DisplayOne
+{
+    Rect r;
+    uint32_t enabled {0};
+    uint32_t flags {0};
+};
+
+struct __attribute__((packed)) ResponseDisplayInfo
+{
+private:
+    static constexpr uint32_t NUM_MAX_SCANOUTS {16u};
+
+public:
+    CtrlHdr hdr {CtrlType::Response::OK_DISPLAY_INFO};
+    DisplayOne pmodes[NUM_MAX_SCANOUTS];
+
+    static size_t size(uint32_t num_scanouts) { return sizeof(CtrlHdr) + num_scanouts * sizeof(DisplayOne); }
+};
+
+struct __attribute__((packed)) GetEdid
+{
+    CtrlHdr hdr {CtrlType::Cmd::GET_EDID};
+    uint32_t uScanout {0};
+    uint32_t uPadding;
+
+    void* payload() { return removeHeader(this); }
+};
+
+struct __attribute__((packed)) ResponseEdid
+{
+    CtrlHdr hdr {CtrlType::Response::OK_EDID};
+    uint32_t uSize {0};
+    uint32_t uPadding;
+    uint8_t aEdid[1024] {0};
+};
+
+enum Format : uint32_t
+{
+    B8G8R8A8_UNORM = 1,
+    B8G8R8X8_UNORM = 2,
+    A8R8G8B8_UNORM = 3,
+    X8R8G8B8_UNORM = 4,
+
+    R8G8B8A8_UNORM = 67,
+    X8B8G8R8_UNORM = 68,
+
+    A8B8G8R8_UNORM = 121,
+    R8G8B8X8_UNORM = 134,
+};
+
+struct __attribute__((packed)) ResourceCreate2d
+{
+    CtrlHdr hdr {CtrlType::Cmd::RESOURCE_CREATE_2D};
+    uint32_t uResourceId {0};
+    uint32_t uFormat {0};
+    uint32_t uWidth {0};
+    uint32_t uHeight {0};
+
+    ResourceCreate2d() = default;
+    ResourceCreate2d(uint32_t id) : uResourceId(id) {}
+    ResourceCreate2d(uint32_t id, uint32_t w, uint32_t h) : uResourceId(id), uWidth(w), uHeight(h) {}
+
+    void* payload() { return removeHeader(this); }
+};
+
+struct __attribute__((packed)) ResourceUnref
+{
+    CtrlHdr hdr {CtrlType::Cmd::RESOURCE_UNREF};
+    uint32_t uResourceId {0};
+    uint32_t uPadding;
+
+    ResourceUnref() = default;
+    ResourceUnref(uint32_t id) : uResourceId(id) {}
+
+    void* payload() { return removeHeader(this); }
+};
+
+struct __attribute__((packed)) SetScanout
+{
+    CtrlHdr hdr {CtrlType::Cmd::SET_SCANOUT};
+    Rect r;
+    uint32_t uScanoutId {0};
+    uint32_t uResourceId {0};
+
+    SetScanout() = default;
+    SetScanout(uint32_t scanoutId, uint32_t resId) : uScanoutId(scanoutId), uResourceId(resId) {}
+    SetScanout(uint32_t scanoutId, uint32_t resId, uint32_t w, uint32_t h)
+        : r(w, h), uScanoutId(scanoutId), uResourceId(resId)
+    {}
+
+    void* payload() { return removeHeader(this); }
+};
+
+struct __attribute__((packed)) ResourceFlush
+{
+    CtrlHdr hdr {CtrlType::Cmd::RESOURCE_FLUSH};
+    Rect r;
+    uint32_t uResourceId {0};
+    uint32_t uPadding;
+
+    void* payload() { return removeHeader(this); }
+};
+
+struct __attribute__((packed)) TransferToHost2d
+{
+    CtrlHdr hdr {CtrlType::Cmd::TRANSFER_TO_HOST_2D};
+    Rect r;
+    uint64_t uOffset {0};
+    uint32_t uResourceId {0};
+    uint32_t uPadding;
+
+    TransferToHost2d() = default;
+    TransferToHost2d(uint32_t resId) : uResourceId(resId) {}
+    TransferToHost2d(uint32_t resId, uint32_t w, uint32_t h) : r(w, h), uResourceId(resId) {}
+
+    void* payload() { return removeHeader(this); }
+};
+
+struct __attribute__((packed)) ResourceAttachBacking
+{
+    CtrlHdr hdr {CtrlType::Cmd::RESOURCE_ATTACH_BACKING};
+    uint32_t uResourceId {0};
+    uint32_t uNrEntries {0};
+
+    void* payload() { return removeHeader(this); }
+};
+
+struct __attribute__((packed)) ResourceMemEntry
+{
+    uint64_t uAddr {0};
+    uint32_t uLength {0};
+    uint32_t uPadding;
+};
+
+struct __attribute__((packed)) ResourceDetachBacking
+{
+    CtrlHdr hdr {CtrlType::Cmd::RESOURCE_DETACH_BACKING};
+    uint32_t uResourceId {0};
+    uint32_t uPadding;
+
+    ResourceDetachBacking() = default;
+    ResourceDetachBacking(uint32_t id) : uResourceId(id) {}
+
+    void* payload() { return removeHeader(this); }
+};
+
+} // namespace virtioGpu
diff --git a/src/VBox/Devices/Graphics/DevVirtioGpuDisplayManager.cpp b/src/VBox/Devices/Graphics/DevVirtioGpuDisplayManager.cpp
new file mode 100644
index 0000000..7a04ca9
--- /dev/null
+++ b/src/VBox/Devices/Graphics/DevVirtioGpuDisplayManager.cpp
@@ -0,0 +1,413 @@
+/*
+ * Copyright (C) Cyberus Technology GmbH.
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <https://www.gnu.org/licenses/>.
+ *
+ * SPDX-License-Identifier: GPL-3.0-or-later
+ */
+
+#define LOG_GROUP LOG_GROUP_DEV_VIRTIO_GPU
+#include "DevVirtioGpuDisplayManager.hpp"
+
+#include "DevVirtioGpuResource.hpp"
+#include <VBox/log.h>
+#include <VBox/types.h>
+#include <VBox/vmm/pdmapi.h>
+#include <VBox/vmm/vm.h>
+
+#include <cyberus/edid.hpp>
+
+#include <algorithm>
+
+VirtioGpuDisplayManager::VirtioGpuDisplayManager(PPDMDEVINS pDevIns_, unsigned iLUN_, PDMIBASE& iBase_,
+                                                 uint32_t u32VRamSize, uint32_t u32MonitorCount_)
+    : pDevIns(pDevIns_), iLUN(iLUN_), iBase(iBase_), u32MonitorCount(u32MonitorCount_)
+{
+    vram.resize(u32VRamSize);
+
+    uint32_t viewIndex {0ul};
+
+    auto generateDisplays = [&viewIndex, &u32VRamSize]() {
+        Display display;
+        display.view.u32ViewIndex = viewIndex;
+        display.view.u32ViewSize = u32VRamSize;
+        /*
+         * We allow the free use of the assigned VRAM, so it is irrelevant if
+         * there are multiple monitors of a mid size resolution or one single monitor with a huge resolution
+         */
+        display.view.u32MaxScreenSize = u32VRamSize;
+
+        display.screen.u32ViewIndex = viewIndex;
+        display.screen.u16BitsPerPixel = VirtioGpuResource::BYTES_PER_PIXEL * __CHAR_BIT__;
+        display.screen.u32Width = virtioGpu::INITIAL_WIDTH;
+        display.screen.u32Height = virtioGpu::INITIAL_HEIGHT;
+
+        display.screen.i32OriginX = viewIndex * virtioGpu::INITIAL_WIDTH;
+        display.screen.i32OriginY = 0;
+
+        display.screen.u16Flags = VBVA_SCREEN_F_DISABLED;
+
+        viewIndex++;
+
+        return display;
+    };
+
+    std::generate_n(std::back_insert_iterator<std::vector<Display>>(displays), u32MonitorCount, generateDisplays);
+    std::memset(vram.data(), 0, vram.size());
+}
+
+VirtioGpuDisplayManager::~VirtioGpuDisplayManager()
+{}
+
+void VirtioGpuDisplayManager::reset()
+{
+    DriverGuard _ {driverMtx};
+
+    if (not pDrv) {
+        return;
+    }
+
+    if (pDrv->pfnReset != nullptr) {
+        pDrv->pfnReset(pDrv);
+    }
+}
+
+bool VirtioGpuDisplayManager::isManaged(uint32_t displayIndex)
+{
+    return displayIndex < u32MonitorCount;
+}
+
+VirtioGpuDisplayManager::Dimension VirtioGpuDisplayManager::displayDimension(uint32_t displayIndex)
+{
+    if (not isManaged(displayIndex)) {
+        return {0, 0};
+    }
+
+    DriverGuard _ {driverMtx};
+
+    auto& display {displays.at(displayIndex)};
+
+    return {display.screen.u32Width, display.screen.u32Height};
+}
+
+void VirtioGpuDisplayManager::resize(uint32_t displayIndex, uint32_t uWidth, uint32_t uHeight,
+                                     std::optional<int32_t> i32OriginX, std::optional<int32_t> i32OriginY)
+{
+    if (not isAttached(displayIndex)) {
+        return;
+    }
+
+    DriverGuard _ {driverMtx};
+
+    auto& screen {displays.at(displayIndex).screen};
+
+    const uint32_t bytesPerPixel {screen.u16BitsPerPixel / static_cast<unsigned>(__CHAR_BIT__)};
+
+    int32_t newOriginX {i32OriginX.value_or(screen.i32OriginX)};
+    int32_t newOriginY {i32OriginY.value_or(screen.i32OriginY)};
+
+    screen.u32LineSize = uWidth * bytesPerPixel;
+    screen.u32Width = uWidth;
+    screen.u32Height = uHeight;
+    screen.i32OriginX = newOriginX;
+    screen.i32OriginY = newOriginY;
+
+    /*
+     * The Framebuffers of all displays are handled in a consecutive buffer of memory by VBox, which is called the VRAM
+     * During a Monitor resize, the portion of memory used for the desired monitor changes.
+     * Thus we need to adjust the start offset of the next monitor to avoid wrong graphics output.
+     */
+    for (uint32_t i {displayIndex + 1}; i < displays.size(); ++i) {
+        auto& currentScreen {displays.at(i).screen};
+        auto& previousScreen {displays.at(i - 1).screen};
+
+        auto calculateScreenSize = [](auto& screen_) -> uint32_t {
+            return screen_.u32Width * screen_.u32Height
+                   * (screen_.u16BitsPerPixel / static_cast<unsigned>(__CHAR_BIT__));
+        };
+
+        uint32_t previousScreenSize {calculateScreenSize(previousScreen)};
+        uint32_t newStartOffset {previousScreen.u32StartOffset + previousScreenSize};
+
+        currentScreen.u32StartOffset = newStartOffset;
+
+        int64_t xOffset {previousScreen.i32OriginX + previousScreen.u32Width};
+
+        currentScreen.i32OriginX = xOffset;
+        resizeVBVA(i, true);
+
+        uint32_t screenSize {calculateScreenSize(currentScreen)};
+        AssertLogRelMsg((currentScreen.u32StartOffset + screenSize) < vram.size(),
+                        ("VirtioGpuDisplayManager: The framebuffer for the displays starting with index %u does not "
+                         "fit into VRAM, monitorCount %u \n",
+                         i, displays.size()));
+    }
+
+    resizeVBVA(displayIndex, true);
+}
+
+int VirtioGpuDisplayManager::attachDisplay(uint32_t displayIndex)
+{
+    int rc {VINF_SUCCESS};
+    if (isAttached(displayIndex)) {
+        return VINF_SUCCESS;
+    }
+
+    if (not isManaged(displayIndex)) {
+        return VERR_NOT_AVAILABLE;
+    }
+
+    {
+        DriverGuard _ {driverMtx};
+
+        auto& display {displays.at(displayIndex)};
+
+        LogRel6(("VirtioGpuDisplayManager: attaching monitor %u .\n", display.view.u32ViewIndex));
+
+        display.screen.u16Flags = VBVA_SCREEN_F_ACTIVE;
+    }
+
+    if (not allDisplaysDetached() and not ownDisplay) {
+        PVM pVM {PDMDevHlpGetVM(pDevIns)};
+
+        rc = PDMR3DriverDetach(pVM->pUVM, "vga", 0, 0, NULL, 0, PDM_TACH_FLAGS_NOT_HOT_PLUG);
+        AssertLogRel(RT_SUCCESS(rc));
+
+        rc = PDMR3DriverAttach(pVM->pUVM, "vga", 0, 0, PDM_ATTACH_DUMMY_DRIVER, NULL);
+
+        if (not pDrv) {
+            rc = takeoverDriver();
+            AssertLogRel(RT_SUCCESS(rc));
+        }
+        ownDisplay = true;
+        return rc;
+    }
+
+    rc = enableVBVA(displayIndex);
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    rc = resizeVBVA(displayIndex, false);
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    return rc;
+}
+
+void VirtioGpuDisplayManager::detachDisplay(uint32_t displayIndex)
+{
+    if (not isAttached(displayIndex)) {
+        LogRel(("Display %d not attached. Not going to do anything\n", displayIndex));
+        return;
+    }
+
+    DriverGuard _ {driverMtx};
+
+    if (not isManaged(displayIndex)) {
+        LogRel(("Display %d not managed. Not going to do anything\n", displayIndex));
+        return;
+    }
+
+    auto& display {displays.at(displayIndex)};
+
+    LogRel6(("VirtioGpuDisplayManager: detaching monitor %u.\n", displayIndex));
+
+    display.screen.u16Flags = VBVA_SCREEN_F_DISABLED;
+
+    /**
+     * On display termination, the pDrv is handed back to VBox already. Thus
+     * the error code VERR_NOT_AVAILABLE is reported here.
+     */
+    resizeVBVA(displayIndex, false);
+
+    disableVBVA(displayIndex);
+}
+
+bool VirtioGpuDisplayManager::isAttached(uint32_t displayIndex)
+{
+    DriverGuard _ {driverMtx};
+
+    if (not isManaged(displayIndex)) {
+        return false;
+    }
+
+    auto& display {displays.at(displayIndex)};
+
+    return display.screen.u16Flags & VBVA_SCREEN_F_ACTIVE;
+}
+
+void VirtioGpuDisplayManager::display(uint32_t displayIndex)
+{
+    if (not isAttached(displayIndex)) {
+        return;
+    }
+
+    DriverGuard _ {driverMtx};
+    if (pDrv != nullptr) {
+        auto& screen {displays.at(displayIndex).screen};
+        VBVACMDHDR cmd;
+
+        cmd.x = screen.i32OriginX;
+        cmd.y = screen.i32OriginY;
+        cmd.w = screen.u32Width;
+        cmd.h = screen.u32Height;
+
+        pDrv->pfnVBVAUpdateBegin(pDrv, screen.u32ViewIndex);
+        pDrv->pfnVBVAUpdateProcess(pDrv, screen.u32ViewIndex, &cmd, sizeof(cmd));
+        pDrv->pfnVBVAUpdateEnd(pDrv, screen.u32ViewIndex, screen.i32OriginX, screen.i32OriginY, screen.u32Width,
+                               screen.u32Height);
+    }
+}
+
+VirtioGpuDisplayManager::BackingStoreInfo VirtioGpuDisplayManager::acquireBackingStore(uint32_t displayIndex)
+{
+    driverMtx.lock();
+
+    if (not isManaged(displayIndex) or pDrv == nullptr) {
+        return {nullptr, 0};
+    }
+
+    auto& screen {displays.at(displayIndex).screen};
+
+    uint8_t* pFramebuffer {vram.data() + screen.u32StartOffset};
+    size_t cbFramebuffer {screen.u32Width * screen.u32Height
+                          * (screen.u16BitsPerPixel / static_cast<unsigned>(__CHAR_BIT__))};
+
+    return {pFramebuffer, cbFramebuffer};
+}
+
+void VirtioGpuDisplayManager::releaseBackingStore()
+{
+    driverMtx.unlock();
+}
+
+bool VirtioGpuDisplayManager::allDisplaysDetached()
+{
+    auto attachementFn = [](Display& display) { return display.screen.u16Flags & VBVA_SCREEN_F_ACTIVE; };
+
+    return std::find_if(displays.begin(), displays.end(), attachementFn) == displays.end();
+}
+
+int VirtioGpuDisplayManager::takeoverDriver()
+{
+    int rc {VINF_SUCCESS};
+
+    if (pDrvBase == nullptr) {
+        rc = PDMDevHlpDriverAttach(pDevIns, iLUN, &iBase, &pDrvBase, "Display Port");
+    }
+
+    if (rc == VERR_PDM_NO_ATTACHED_DRIVER) {
+        AssertLogRelMsgFailed(("VirtioGpuDisplayManager: %s/%d: warning: no driver attached to LUN #0!\n",
+                               pDevIns->pReg->szName, pDevIns->iInstance));
+        return VINF_SUCCESS;
+    } else if (not RT_SUCCESS(rc)) {
+        AssertLogRelMsgFailed(("VirtioGpuDisplayManager: failed to attach LUN #0! rc=%Rrc\n", rc));
+        return rc;
+    }
+
+    /* rc == VINF_SUCCESS, i.e. pDrvBase is attached to iLUN */
+
+    pDrv = PDMIBASE_QUERY_INTERFACE(pDrvBase, PDMIDISPLAYCONNECTOR);
+    if (pDrv != nullptr) {
+        if (pDrv->pfnRefresh == nullptr or pDrv->pfnResize == nullptr or pDrv->pfnUpdateRect == nullptr) {
+            Assert(pDrv->pfnRefresh != nullptr);
+            Assert(pDrv->pfnResize != nullptr);
+            Assert(pDrv->pfnUpdateRect != nullptr);
+            pDrv = nullptr;
+            pDrvBase = nullptr;
+            rc = VERR_INTERNAL_ERROR;
+        }
+    } else {
+        AssertLogRelMsgFailed(
+            ("VirtioGpuDisplayManager: LUN #0 doesn't have a display connector interface! rc=%Rrc\n", rc));
+        pDrvBase = nullptr;
+        rc = VERR_PDM_MISSING_INTERFACE;
+    }
+
+    LogRel2(("VirtioGpuDisplayDriver: Display Port Driver attached\n"));
+
+    /*
+     * We deactivate the rendering of the mouse cursor by VBox, as the intel driver of the Windows
+     * VM renders the mouse cursor for the VM already.
+     */
+    pDrv->pfnVBVAMousePointerShape(pDrv, false, false, 0, 0, 0, 0, nullptr);
+    return rc;
+}
+
+void VirtioGpuDisplayManager::handoverDriver()
+{
+    PVM pVM {PDMDevHlpGetVM(pDevIns)};
+    PDMR3DriverDetach(pVM->pUVM, "virtio-gpu", 0, 0, NULL, 0, 0);
+    PDMR3DriverAttach(pVM->pUVM, "vga", 0, 0, PDM_TACH_FLAGS_NOT_HOT_PLUG, NULL);
+
+    pDrv = nullptr;
+    pDrvBase = nullptr;
+    ownDisplay = false;
+
+    LogRel2(("VirtioGpuDisplayDriver: Display Port Driver detached\n"));
+}
+
+void VirtioGpuDisplayManager::detachAllDisplays()
+{
+    for (auto i {0ul}; i < displays.size(); ++i) {
+        detachDisplay(i);
+    }
+}
+
+int VirtioGpuDisplayManager::resizeVBVA(uint32_t displayIndex, bool fResetInputMapping)
+{
+    AssertLogRelMsgReturn(isManaged(displayIndex),
+                          ("VirtioGpuDisplayManager: UpdateVBVA: The Display %u is not managed! \n", displayIndex),
+                          VERR_INVALID_PARAMETER);
+
+    int rc {VERR_NOT_AVAILABLE};
+
+    if (pDrv != nullptr and pDrv->pfnVBVAResize != nullptr) {
+        AssertRelease(isManaged(displayIndex));
+
+        auto& display {displays.at(displayIndex)};
+
+        return pDrv->pfnVBVAResize(pDrv, &display.view, &display.screen, vram.data(), fResetInputMapping);
+    }
+
+    LogRel6(("VirtioGpuDisplayManager: tried to update VBVA for display %u. Return Code: %Rrc.\n", displayIndex, rc));
+
+    return rc;
+}
+
+int VirtioGpuDisplayManager::enableVBVA(uint32_t displayIndex)
+{
+    AssertLogRelMsgReturn(isManaged(displayIndex),
+                          ("VirtioGpuDisplayManager: EnableVBVA: The display %u is not managed! \n", displayIndex),
+                          VERR_INVALID_PARAMETER);
+
+    int rc {VERR_NOT_AVAILABLE};
+
+    if (pDrv != nullptr and pDrv->pfnVBVAEnable != nullptr) {
+        rc = pDrv->pfnVBVAEnable(pDrv, displayIndex, 0);
+    }
+
+    LogRel6(("VirtioGpuDisplayManager: tried to enable VBVA for display %u. Return Code: %Rrc.\n", displayIndex, rc));
+
+    return rc;
+}
+
+void VirtioGpuDisplayManager::disableVBVA(uint32_t displayIndex)
+{
+    AssertReleaseMsg(isManaged(displayIndex),
+                     ("VirtioGpuDisplayManager: disableVBVA: The display %u is not managed! \n", displayIndex));
+
+    if (pDrv != nullptr and pDrv->pfnVBVADisable != nullptr) {
+        pDrv->pfnVBVADisable(pDrv, displayIndex);
+        LogRel6(("VirtioGpuDisplayManager: disabled VBVA for display %u.\n", displayIndex));
+    }
+}
diff --git a/src/VBox/Devices/Graphics/DevVirtioGpuDisplayManager.hpp b/src/VBox/Devices/Graphics/DevVirtioGpuDisplayManager.hpp
new file mode 100644
index 0000000..838a236
--- /dev/null
+++ b/src/VBox/Devices/Graphics/DevVirtioGpuDisplayManager.hpp
@@ -0,0 +1,213 @@
+/*
+ * Copyright (C) Cyberus Technology GmbH.
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <https://www.gnu.org/licenses/>.
+ *
+ * SPDX-License-Identifier: GPL-3.0-or-later
+ */
+
+#pragma once
+
+#include <VBox/vmm/pdmdev.h>
+#include <VBox/vmm/pdmifs.h>
+#include <VBox/vmm/pgm.h>
+
+#include "DevVirtioGpuCmdHandler.hpp"
+#include <VBox/Graphics/VBoxVideo.h>
+
+#include <mutex>
+
+/**
+ * The Virtio Display Manager implementation.
+ *
+ */
+class VirtioGpuDisplayManager final : public VirtioGpuCmdHandler::DisplayManager
+{
+public:
+    VirtioGpuDisplayManager() = delete;
+
+    /**
+     * The Virtio GPU Display Manager.
+     *
+     * \param pDevINs_ The VBox PDM Device Instance Data
+     * \param iLUN_ The device LUN of the GPU
+     * \param iBase_ The Virtio GPU Interface Base
+     * \param u32VRamSize The assigned VRAM
+     * \param u32MonitorCount The maximum active monitor count
+     */
+    VirtioGpuDisplayManager(PPDMDEVINS pDevIns_, unsigned iLUN_, PDMIBASE& iBase_, uint32_t u32VRamSize,
+                            uint32_t u32MonitorCount);
+
+    ~VirtioGpuDisplayManager();
+
+    /**
+     * Reset the Display infrastructure
+     */
+    void reset();
+
+    /**
+     * Check whether the display index is managed by the Manager.
+     *
+     * \param displayIndex The display index.
+     *
+     * \return true if the display is managed, false otherwise
+     */
+    virtual bool isManaged(uint32_t displayIndex) final;
+
+    /**
+     * Obtain the dimensions of the given display.
+     *
+     * \param displayIndex The display index
+     *
+     * \return the dimension of the display or <0,0> if not managed
+     */
+    virtual Dimension displayDimension(uint32_t displayIndex) final;
+
+    /**
+     * Resize the given display to the given width and height.
+     *
+     * \param displayIndex The display index
+     * \param uWidth display width
+     * \param uHeigth display height
+     * \param u32OriginX (Optional) The display x position
+     * \param u32OriginY (Optional) The display y position
+     */
+    virtual void resize(uint32_t displayIndex, uint32_t uWidth, uint32_t uHeight, std::optional<int32_t> i32OriginX,
+                        std::optional<int32_t> i32OriginY) final;
+
+    /**
+     * Attaches the virtio-gpu to the given display.
+     *
+     * \param displayIndex The display index
+     */
+    virtual int attachDisplay(uint32_t displayIndex) final;
+
+    /**
+     * Detaches the virtio-gpu from the given display.
+     *
+     * \param displayIndex The display index
+     */
+    virtual void detachDisplay(uint32_t displayIndex) final;
+
+    /**
+     * Check attachment status of the given display.
+     *
+     * \param displayIndex The display index
+     *
+     * \return true if the display is attached, false otherwise.
+     */
+    virtual bool isAttached(uint32_t displayIndex) final;
+    /**
+     * Displays the framebuffer content on the display.
+     *
+     * \param displayIndex The display index
+     */
+    virtual void display(uint32_t displayIndex) final;
+
+    /**
+     * Obtain backing store.
+     *
+     * The function activates the pDrv lock, to ensure consistency.
+     *
+     * \param displayIndex The display index
+     *
+     * \return Backing store information
+     */
+    virtual BackingStoreInfo acquireBackingStore(uint32_t displayIndex) final;
+
+    /**
+     * Release the backing store lock.
+     */
+    virtual void releaseBackingStore() final;
+
+    /**
+     * Take over the display driver from the default Graphics Adapter.
+     *
+     * \return VBox Status Code
+     */
+    int takeoverDriver();
+
+    /**
+     * Hand back the display driver to the default Graphics Adapter.
+     */
+    void handoverDriver();
+
+    /**
+     * Detach all attached displays.
+     */
+    void detachAllDisplays();
+
+private:
+    /**
+     * Update the screen data at the VBox Video Acceleration infrastructure for
+     * the desired display, including a resize, if necessary.
+     *
+     * \param displayIndex The desired display index
+     * \param fResetInputMapping Whether to reset the input mapping or not.
+     *
+     * \return VBox Status Code
+     */
+    int resizeVBVA(uint32_t displayIndex, bool fResetInputMapping);
+
+    /**
+     * Enable the VirtualBox Video Acceleration for the desired display.
+     *
+     * \param displayIndex The desired display index
+     *
+     *
+     * \return VBox Status Code
+     */
+    int enableVBVA(uint32_t displayIndex);
+
+    /**
+     * Disable the VirtualBox Video Acceleration for the desired display.
+     *
+     * \param displayIndex The desired display index
+     */
+    void disableVBVA(uint32_t displayIndex);
+
+    /**
+     * Check that all displays are detached.
+     *
+     * \return true if all displays are detached, false otherwise.
+     */
+    bool allDisplaysDetached();
+
+    /**
+     * The display internal management data structure
+     */
+    struct Display
+    {
+        VBVAINFOVIEW view;
+        VBVAINFOSCREEN screen;
+    };
+
+    PPDMDEVINS pDevIns;
+    unsigned iLUN;
+    PDMIBASE& iBase;
+    const uint32_t u32MonitorCount;
+
+    PPDMIDISPLAYCONNECTOR pDrv {nullptr};
+    PPDMIBASE pDrvBase {nullptr};
+
+    // Once we have taken over the display this get's true and stays true
+    // until guest reset or reboot.
+    bool ownDisplay {false};
+
+    std::vector<uint8_t> vram;
+    std::vector<Display> displays;
+
+    std::mutex driverMtx;
+    using DriverGuard = std::lock_guard<std::mutex>;
+};
diff --git a/src/VBox/Devices/Graphics/DevVirtioGpuResource.hpp b/src/VBox/Devices/Graphics/DevVirtioGpuResource.hpp
new file mode 100644
index 0000000..f27d576
--- /dev/null
+++ b/src/VBox/Devices/Graphics/DevVirtioGpuResource.hpp
@@ -0,0 +1,80 @@
+/*
+ * Copyright (C) Cyberus Technology GmbH.
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <https://www.gnu.org/licenses/>.
+ *
+ * SPDX-License-Identifier: GPL-3.0-or-later
+ */
+
+#pragma once
+
+#include <cstdint>
+#include <vector>
+
+class VirtioGpuResource
+{
+    const uint32_t uResourceId_;
+    uint32_t uFormat_ {0};
+    uint32_t uWidth_ {0};
+    uint32_t uHeight_ {0};
+
+    uint32_t uScanoutId_ {0};
+
+public:
+    struct MemEntry
+    {
+        const uint64_t uAddr_; // guest physical address
+        const uint32_t uLength_;
+
+        MemEntry() = delete;
+        MemEntry(uint64_t uAddr, uint32_t uLength) : uAddr_(uAddr), uLength_(uLength) {}
+    };
+
+    static constexpr unsigned BYTES_PER_PIXEL {4u};
+
+private:
+    std::vector<MemEntry> vBacking_ {};
+
+public:
+    VirtioGpuResource() = delete;
+    VirtioGpuResource(uint32_t uResourceId) : uResourceId_(uResourceId) {}
+
+    ~VirtioGpuResource() = default;
+
+    uint32_t resourceId() const { return uResourceId_; }
+
+    void format(uint32_t uFormat) { uFormat_ = uFormat; }
+    uint32_t format() const { return uFormat_; }
+
+    void size(uint32_t uWidth, uint32_t uHeight)
+    {
+        uWidth_ = uWidth;
+        uHeight_ = uHeight;
+    }
+
+    uint32_t width() const { return uWidth_; }
+    uint32_t height() const { return uHeight_; }
+
+    void scanoutId(uint32_t uScanoutId) { uScanoutId_ = uScanoutId; }
+    uint32_t scanoutId() { return uScanoutId_; }
+
+    size_t memNeeded() const { return uWidth_ * uHeight_ * BYTES_PER_PIXEL; }
+
+    void reserveBacking(size_t sz) { vBacking_.reserve(sz); }
+    void clearBacking() { vBacking_.clear(); }
+    void addBacking(uint64_t uAddr, uint32_t uLenght) { vBacking_.emplace_back(uAddr, uLenght); }
+
+    MemEntry* getBacking(uint32_t idx) { return &vBacking_.at(idx); }
+    const std::vector<MemEntry>& getBacking() { return vBacking_; }
+};
diff --git a/src/VBox/Devices/Graphics/DevVirtioGpuVBoxStubs.cpp b/src/VBox/Devices/Graphics/DevVirtioGpuVBoxStubs.cpp
new file mode 100644
index 0000000..5a5d18c
--- /dev/null
+++ b/src/VBox/Devices/Graphics/DevVirtioGpuVBoxStubs.cpp
@@ -0,0 +1,342 @@
+/*
+ * Copyright (C) Cyberus Technology GmbH.
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <https://www.gnu.org/licenses/>.
+ *
+ * SPDX-License-Identifier: GPL-3.0-or-later
+ */
+
+#define LOG_GROUP LOG_GROUP_DEV_VIRTIO_GPU
+#include "DevVirtioGpuVBoxStubs.hpp"
+#include "DevVirtioGpu.hpp"
+
+#include <VBox/log.h>
+#include <VBox/msi.h>
+#include <VBox/vmm/mm.h>
+#include <VBox/vmm/pdmdev.h>
+
+#ifdef IN_RING3
+#    include <iprt/uuid.h>
+#endif
+
+static DECLCALLBACK(int) devVirtioGpuConstruct(PPDMDEVINS pDevIns, int iInstance, PCFGMNODE pCfg)
+{
+    // Check that the device instance and device helper structures are compatible.
+    PDMDEV_CHECK_VERSIONS_RETURN(pDevIns);
+
+    PVIRTIOGPUDEV pThis {PDMDEVINS_2_DATA(pDevIns, PVIRTIOGPUDEV)};
+
+    int rc {VINF_SUCCESS};
+    bool secondaryController {false};
+    unsigned cMonitorCount {0};
+    uint32_t u32VRamSize {0};
+
+    constexpr char validation[] = "secondaryController"
+                                  "|MonitorCount"
+                                  "|VRamSize";
+
+    PDMDEV_VALIDATE_CONFIG_RETURN(pDevIns, validation, "Invalid Configuration");
+
+    rc = pDevIns->pHlpR3->pfnCFGMQueryBoolDef(pCfg, "secondaryController", &secondaryController, false);
+    if (RT_FAILURE(rc)) {
+        return PDMDEV_SET_ERROR(pDevIns, rc,
+                                N_("Condfiguration error: Querying secondaryController asa a bool failed"));
+    }
+
+    rc = pDevIns->pHlpR3->pfnCFGMQueryU32Def(pCfg, "MonitorCount", &cMonitorCount, 1);
+    if (RT_FAILURE(rc)) {
+        return PDMDEV_SET_ERROR(pDevIns, rc, N_("Configuration error: Querying MonitorCount as uint32_t failed"));
+    }
+
+    rc = pDevIns->pHlpR3->pfnCFGMQueryU32Def(pCfg, "VRamSize", &u32VRamSize, 32 * _1M);
+    if (RT_FAILURE(rc)) {
+        return PDMDEV_SET_ERROR(pDevIns, rc, N_("Configuration error: Querying VRAM Size as uin32_t failed"));
+    }
+
+    rc = pThis->init(pDevIns, iInstance, u32VRamSize, cMonitorCount, secondaryController);
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    return VINF_SUCCESS;
+}
+
+static DECLCALLBACK(int) devVirtioGpuDestruct(PPDMDEVINS pDevIns)
+{
+    // Check that the device instance and device helper structures are compatible again.
+    PDMDEV_CHECK_VERSIONS_RETURN(pDevIns);
+
+    PVIRTIOGPUDEV pThis {PDMDEVINS_2_DATA(pDevIns, PVIRTIOGPUDEV)};
+
+    int rc {pThis->terminate(pDevIns)};
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    return VINF_SUCCESS;
+}
+
+static DECLCALLBACK(void) devVirtioGpuReset(PPDMDEVINS pDevIns)
+{
+    PVIRTIOGPUDEV pThis {PDMDEVINS_2_DATA(pDevIns, PVIRTIOGPUDEV)};
+    pThis->pDisplayManager->reset();
+    pThis->pDisplayManager->handoverDriver();
+}
+
+static DECLCALLBACK(int) devVirtioGpuAttach(PPDMDEVINS pDevIns, unsigned iLUN, uint32_t)
+{
+    PVIRTIOGPUDEV pThis {PDMDEVINS_2_DATA(pDevIns, PVIRTIOGPUDEV)};
+
+    /* we only support iLUN == 0 at the moment */
+    if (iLUN != 0) {
+        AssertLogRelMsgFailed(("Invalid LUN #%d\n", iLUN));
+        return VERR_PDM_NO_SUCH_LUN;
+    }
+
+    int rc {pThis->pDisplayManager->takeoverDriver()};
+    AssertLogRelReturn(RT_SUCCESS(rc), rc);
+
+    return VINF_SUCCESS;
+}
+
+static DECLCALLBACK(void) devVirtioGpuDetach(PPDMDEVINS pDevIns, unsigned, uint32_t)
+{
+    PVIRTIOGPUDEV pThis {PDMDEVINS_2_DATA(pDevIns, PVIRTIOGPUDEV)};
+    pThis->pDisplayManager->detachAllDisplays();
+}
+
+/**
+ * Device registration structure.
+ */
+extern "C" const PDMDEVREG g_DeviceVirtioGpuDev = {
+    /* .u32Version = */ PDM_DEVREG_VERSION,
+    /* .uReserved0 = */ 0,
+    /* .szName = */ "virtio-gpu",
+    /* .fFlags = */ PDM_DEVREG_FLAGS_DEFAULT_BITS | PDM_DEVREG_FLAGS_NEW_STYLE,
+    /* .fClass = */ PDM_DEVREG_CLASS_GRAPHICS,
+    /* .cMaxInstances = */ 1u,
+    /* .uSharedVersion = */ 42,
+    /* .cbInstanceShared = */ sizeof(VIRTIOGPUDEV),
+    /* .cbInstanceR0 = */ sizeof(VIRTIOGPUDEVCC),
+    /* .cbInstanceRC = */ 0,
+    /* .cMaxPciDevices = */ 1,
+    /* .cMaxMsixVectors = */ VBOX_MSIX_MAX_ENTRIES,
+    /* .pszDescription = */ "Virtio Host GPU.\n",
+    /* .pszRCMod = */ "",
+    /* .pszR0Mod = */ "",
+    /* .pfnConstruct = */ devVirtioGpuConstruct,
+    /* .pfnDestruct = */ devVirtioGpuDestruct,
+    /* .pfnRelocate = */ NULL,
+    /* .pfnMemSetup = */ NULL,
+    /* .pfnPowerOn = */ NULL,
+    /* .pfnReset = */ devVirtioGpuReset,
+    /* .pfnSuspend = */ NULL,
+    /* .pfnResume = */ NULL,
+    /* .pfnAttach = */ devVirtioGpuAttach,
+    /* .pfnDetach = */ devVirtioGpuDetach,
+    /* .pfnQueryInterface. = */ NULL,
+    /* .pfnInitComplete = */ NULL,
+    /* .pfnPowerOff = */ NULL,
+    /* .pfnSoftReset = */ NULL,
+    /* .pfnReserved0 = */ NULL,
+    /* .pfnReserved1 = */ NULL,
+    /* .pfnReserved2 = */ NULL,
+    /* .pfnReserved3 = */ NULL,
+    /* .pfnReserved4 = */ NULL,
+    /* .pfnReserved5 = */ NULL,
+    /* .pfnReserved6 = */ NULL,
+    /* .pfnReserved7 = */ NULL,
+    /* .u32VersionEnd = */ PDM_DEVREG_VERSION};
+
+DECLCALLBACK(void) virtioGpuStatusChanged(PVIRTIOCORE pVirtio, PVIRTIOCORECC, uint32_t fDriverOk)
+{
+    PVIRTIOGPUDEV pThis {RT_FROM_MEMBER(pVirtio, VIRTIOGPUDEV, virtio)};
+
+    if (fDriverOk != 0) {
+        int rc = pThis->start();
+        AssertLogRel(RT_SUCCESS(rc));
+    } else {
+        int rc = pThis->stop();
+        AssertLogRel(RT_SUCCESS(rc));
+    }
+}
+
+DECLCALLBACK(int) virtioGpuDevCapRead(PPDMDEVINS pDevIns, uint32_t uOffset, void* pvBuf, uint32_t cbToRead)
+{
+    PVIRTIOGPUDEV pThis {PDMDEVINS_2_DATA(pDevIns, PVIRTIOGPUDEV)};
+    return pThis->readCap(uOffset, pvBuf, cbToRead);
+}
+
+DECLCALLBACK(int) virtioGpuDevCapWrite(PPDMDEVINS pDevIns, uint32_t uOffset, const void* pvBuf, uint32_t cbToWrite)
+{
+    PVIRTIOGPUDEV pThis {PDMDEVINS_2_DATA(pDevIns, PVIRTIOGPUDEV)};
+    return pThis->writeCap(uOffset, pvBuf, cbToWrite);
+}
+
+DECLCALLBACK(void) virtioGpuVirtqNotified(PPDMDEVINS pDevIns, PVIRTIOCORE, uint16_t uVirtqNbr)
+{
+    PVIRTIOGPUDEV pThis {PDMDEVINS_2_DATA(pDevIns, PVIRTIOGPUDEV)};
+    pThis->wakeupWorker(uVirtqNbr);
+}
+
+DECLCALLBACK(void)
+virtioGpuDisplayChanged(PPDMDEVINS pDevIns, uint32_t numDisplays, VMMDevDisplayDef* displayDefs)
+{
+    PVIRTIOGPUDEV pThis {PDMDEVINS_2_DATA(pDevIns, PVIRTIOGPUDEV)};
+    pThis->displayChanged(numDisplays, displayDefs);
+}
+
+DECLCALLBACK(void*) virtioGpuQueryInterface(PPDMIBASE pInterface, const char* pszIID)
+{
+    PPDMDEVINS pDevIns {PDMIBASE_2_PDMDEV(pInterface)};
+    PVIRTIOGPUDEV pThis {PDMDEVINS_2_DATA(pDevIns, PVIRTIOGPUDEV)};
+    LogRel8(("%s: virtioGpuQueryInterface.\n", pThis->szInst.c_str()));
+    PDMIBASE_RETURN_INTERFACE(pszIID, PDMIVIRTIOGPUPORT, &pThis->IVirtioGpuPort);
+    return nullptr;
+}
+
+DECLCALLBACK(void*) virtioGpuPortQueryInterface(PPDMIBASE pInterface, const char* pszIID)
+{
+    PVIRTIOGPUDEV pThis {RT_FROM_MEMBER(pInterface, VIRTIOGPUDEV, IBase)};
+    LogRel8(("%s: virtioGpuPortQueryInterface.\n", pThis->szInst.c_str()));
+    PDMIBASE_RETURN_INTERFACE(pszIID, PDMIBASE, &pThis->IBase);
+    PDMIBASE_RETURN_INTERFACE(pszIID, PDMIDISPLAYPORT, &pThis->IPort);
+    PDMIBASE_RETURN_INTERFACE(pszIID, PDMIDISPLAYVBVACALLBACKS, &pThis->IVBVACallbacks);
+    return nullptr;
+}
+
+static PVIRTIOGPUDEV virtioGpuFromPPDMIDISPLAYPORT(PPDMIDISPLAYPORT pInterface)
+{
+    return reinterpret_cast<PVIRTIOGPUDEV>(reinterpret_cast<uintptr_t>(pInterface) - RT_OFFSETOF(VIRTIOGPUDEV, IPort));
+}
+
+DECLCALLBACK(void) virtioGpuPortSetRenderVRAM(PPDMIDISPLAYPORT pInterface, bool)
+{
+    [[maybe_unused]] auto pThis {virtioGpuFromPPDMIDISPLAYPORT(pInterface)};
+    LogRel8(("%s: virtioGpuPortSetRenderVRAM.\n", pThis->szInst.c_str()));
+}
+
+DECLCALLBACK(int) virtioGpuUpdateDisplay(PPDMIDISPLAYPORT pInterface)
+{
+    [[maybe_unused]] auto pThis {virtioGpuFromPPDMIDISPLAYPORT(pInterface)};
+    LogRel8(("%s: virtioGpuUpdateDisplay.\n", pThis->szInst.c_str()));
+    return VINF_SUCCESS;
+}
+
+DECLCALLBACK(int) virtioGpuPortUpdateDisplayAll(PPDMIDISPLAYPORT pInterface, bool)
+{
+    [[maybe_unused]] auto pThis {virtioGpuFromPPDMIDISPLAYPORT(pInterface)};
+    LogRel8(("%s: virtioGpuPortUpdateDisplayAll.\n", pThis->szInst.c_str()));
+    return VINF_SUCCESS;
+}
+
+DECLCALLBACK(int)
+virtioGpuPortQueryVideoMode(PPDMIDISPLAYPORT pInterface, uint32_t* pcBits, uint32_t* pcx, uint32_t* pcy)
+{
+    PVIRTIOGPUDEV pThis {virtioGpuFromPPDMIDISPLAYPORT(pInterface)};
+    LogRel8(("%s: virtioGpuPortQueryVideoMode. pcBits: %u, pcx: %u, pcy: %u.\n", pThis->szInst.c_str(), *pcBits, *pcx,
+             *pcy));
+
+    if (!pcBits) {
+        return VERR_INVALID_PARAMETER;
+    }
+
+    *pcBits = 0;
+
+    // CYBER-TODO: This should not always be scanout 0
+    // When we have figured out how to handle multiple VBox-Windows, we have to
+    // figure out how to get the index of the scanout here.
+    auto maybeScanout {pThis->pCmdHandler->getCScanout(0)};
+    if (not maybeScanout.has_value()) {
+        return VINF_SUCCESS;
+    }
+
+    const auto currentScanout {maybeScanout->get()};
+    if (pcx) {
+        *pcx = currentScanout.uCurrentWidth;
+    }
+
+    if (pcy) {
+        *pcy = currentScanout.uCurrentHeight;
+    }
+
+    return VINF_SUCCESS;
+}
+
+DECLCALLBACK(int) virtioGpuPortSetRefreshRate(PPDMIDISPLAYPORT pInterface, uint32_t)
+{
+    [[maybe_unused]] auto pThis {virtioGpuFromPPDMIDISPLAYPORT(pInterface)};
+    LogRel8(("%s: virtioGpuPortSetRefreshRate.\n", pThis->szInst.c_str()));
+    return VINF_SUCCESS;
+}
+
+DECLCALLBACK(int) virtioGpuPortTakeScreenshot(PPDMIDISPLAYPORT pInterface, uint8_t**, size_t*, uint32_t*, uint32_t*)
+{
+    [[maybe_unused]] auto pThis {virtioGpuFromPPDMIDISPLAYPORT(pInterface)};
+    LogRel8(("%s: virtioGpuPortTakeScreenshot.\n", pThis->szInst.c_str()));
+    return VINF_SUCCESS;
+}
+
+DECLCALLBACK(void) virtioGpuPortFreeScreenshot(PPDMIDISPLAYPORT pInterface, uint8_t*)
+{
+    [[maybe_unused]] auto pThis {virtioGpuFromPPDMIDISPLAYPORT(pInterface)};
+    LogRel8(("%s: virtioGpuPortFreeScreenshot.\n", pThis->szInst.c_str()));
+}
+
+DECLCALLBACK(void) virtioGpuPortUpdateDisplayRect(PPDMIDISPLAYPORT pInterface, int32_t, int32_t, uint32_t, uint32_t)
+{
+    [[maybe_unused]] auto pThis {virtioGpuFromPPDMIDISPLAYPORT(pInterface)};
+    LogRel8(("%s: virtioGpuPortUpdateDisplayRect.\n", pThis->szInst.c_str()));
+}
+
+DECLCALLBACK(int)
+virtioGpuPortDisplayBlt(PPDMIDISPLAYPORT pInterface, const void*, uint32_t, uint32_t, uint32_t, uint32_t)
+{
+    [[maybe_unused]] auto pThis {virtioGpuFromPPDMIDISPLAYPORT(pInterface)};
+    LogRel8(("%s: virtioGpuPortDisplayBlt.\n", pThis->szInst.c_str()));
+    return VINF_SUCCESS;
+}
+
+DECLCALLBACK(int)
+virtioGpuPortCopyRect(PPDMIDISPLAYPORT pInterface, uint32_t, uint32_t, const uint8_t*, int32_t, int32_t, uint32_t,
+                      uint32_t, uint32_t, uint32_t, uint8_t*, int32_t, int32_t, uint32_t, uint32_t, uint32_t, uint32_t)
+{
+    [[maybe_unused]] auto pThis {virtioGpuFromPPDMIDISPLAYPORT(pInterface)};
+    LogRel8(("%s: virtioGpuPortCopyRect.\n", pThis->szInst.c_str()));
+    return VINF_SUCCESS;
+}
+
+DECLCALLBACK(void)
+vmsvgavirtioGpuPortSetViewport(PPDMIDISPLAYPORT pInterface, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t)
+{
+    [[maybe_unused]] auto pThis {virtioGpuFromPPDMIDISPLAYPORT(pInterface)};
+    LogRel8(("%s: SetViewport\n\n\n\n\n", pThis->szInst.c_str()));
+}
+
+DECLCALLBACK(int)
+vbvavirtioGpuPortSendModeHint(PPDMIDISPLAYPORT pInterface, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t,
+                              uint32_t, uint32_t)
+{
+    [[maybe_unused]] auto pThis {virtioGpuFromPPDMIDISPLAYPORT(pInterface)};
+    LogRel8(("%s: vbvavirtioGpuPortSendModeHint.\n", pThis->szInst.c_str()));
+    return VINF_SUCCESS;
+}
+
+DECLCALLBACK(void) vbvavirtioGpuPortReportHostCursorCapabilities(PPDMIDISPLAYPORT pInterface, bool, bool)
+{
+    [[maybe_unused]] auto pThis {virtioGpuFromPPDMIDISPLAYPORT(pInterface)};
+    LogRel8(("%s: vbvavirtioGpuPortReportHostCursorCapabilities.\n", pThis->szInst.c_str()));
+}
+
+DECLCALLBACK(void) vbvavirtioGpuPortReportHostCursorPosition(PPDMIDISPLAYPORT pInterface, uint32_t, uint32_t, bool)
+{
+    [[maybe_unused]] auto pThis {virtioGpuFromPPDMIDISPLAYPORT(pInterface)};
+    LogRel8(("%s: vbvavirtioGpuPortReportHostCursorPosition.\n", pThis->szInst.c_str()));
+}
diff --git a/src/VBox/Devices/Graphics/DevVirtioGpuVBoxStubs.hpp b/src/VBox/Devices/Graphics/DevVirtioGpuVBoxStubs.hpp
new file mode 100644
index 0000000..fd6a562
--- /dev/null
+++ b/src/VBox/Devices/Graphics/DevVirtioGpuVBoxStubs.hpp
@@ -0,0 +1,71 @@
+/*
+ * Copyright (C) Cyberus Technology GmbH.
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <https://www.gnu.org/licenses/>.
+ *
+ * SPDX-License-Identifier: GPL-3.0-or-later
+ */
+
+#pragma once
+
+#include <VBox/VMMDev.h>
+#include <VBox/vmm/pdmdev.h>
+
+#include "../VirtIO/VirtioCore.h"
+
+#include <cstdint>
+
+/*
+ * VIRTIOCORER3
+ */
+
+/** VIRTIOCORER3::pfnStatusChanged */
+DECLCALLBACK(void) virtioGpuStatusChanged(PVIRTIOCORE pVirtio, PVIRTIOCORECC, uint32_t fDriverOk);
+
+/** VIRTIOCORER3::pfnDevCapRead */
+DECLCALLBACK(int) virtioGpuDevCapRead(PPDMDEVINS pDevIns, uint32_t uOffset, void* pvBuf, uint32_t cbToRead);
+
+/** VIRTIOCORER3::pfnDevCapWrite */
+DECLCALLBACK(int) virtioGpuDevCapWrite(PPDMDEVINS pDevIns, uint32_t uOffset, const void* pvBuf, uint32_t cbToWrite);
+
+/** VIRTIOCORER3::pfnVirtqNotified */
+DECLCALLBACK(void) virtioGpuVirtqNotified(PPDMDEVINS pDevIns, PVIRTIOCORE, uint16_t uVirtqNbr);
+
+DECLCALLBACK(void)
+virtioGpuDisplayChanged(PPDMDEVINS pDevIns, uint32_t numDisplays, VMMDevDisplayDef* displayDefs);
+
+DECLCALLBACK(void*) virtioGpuQueryInterface(PPDMIBASE pInterface, const char* pszIID);
+
+DECLCALLBACK(void) virtioGpuReset(PPDMDEVINS);
+DECLCALLBACK(int) virtioGpuAttach(PPDMDEVINS, unsigned, uint32_t);
+DECLCALLBACK(void) virtioGpuDetach(PPDMDEVINS, unsigned, uint32_t);
+DECLCALLBACK(void*) virtioGpuPortQueryInterface(PPDMIBASE, const char*);
+DECLCALLBACK(void) virtioGpuPortSetRenderVRAM(PPDMIDISPLAYPORT, bool);
+DECLCALLBACK(int) virtioGpuUpdateDisplay(PPDMIDISPLAYPORT);
+DECLCALLBACK(int) virtioGpuPortUpdateDisplayAll(PPDMIDISPLAYPORT, bool);
+DECLCALLBACK(int) virtioGpuPortQueryVideoMode(PPDMIDISPLAYPORT, uint32_t*, uint32_t*, uint32_t*);
+DECLCALLBACK(int) virtioGpuPortSetRefreshRate(PPDMIDISPLAYPORT, uint32_t);
+DECLCALLBACK(int) virtioGpuPortTakeScreenshot(PPDMIDISPLAYPORT, uint8_t**, size_t*, uint32_t*, uint32_t*);
+DECLCALLBACK(void) virtioGpuPortFreeScreenshot(PPDMIDISPLAYPORT, uint8_t*);
+DECLCALLBACK(void) virtioGpuPortUpdateDisplayRect(PPDMIDISPLAYPORT, int32_t, int32_t, uint32_t, uint32_t);
+DECLCALLBACK(int) virtioGpuPortDisplayBlt(PPDMIDISPLAYPORT, const void*, uint32_t, uint32_t, uint32_t, uint32_t);
+DECLCALLBACK(int)
+virtioGpuPortCopyRect(PPDMIDISPLAYPORT, uint32_t, uint32_t, const uint8_t*, int32_t, int32_t, uint32_t, uint32_t,
+                      uint32_t, uint32_t, uint8_t*, int32_t, int32_t, uint32_t, uint32_t, uint32_t, uint32_t);
+DECLCALLBACK(void) vmsvgavirtioGpuPortSetViewport(PPDMIDISPLAYPORT, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t);
+DECLCALLBACK(int)
+vbvavirtioGpuPortSendModeHint(PPDMIDISPLAYPORT, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t,
+                              uint32_t);
+DECLCALLBACK(void) vbvavirtioGpuPortReportHostCursorCapabilities(PPDMIDISPLAYPORT, bool, bool);
+DECLCALLBACK(void) vbvavirtioGpuPortReportHostCursorPosition(PPDMIDISPLAYPORT, uint32_t, uint32_t, bool);
diff --git a/src/VBox/Devices/Makefile.kmk b/src/VBox/Devices/Makefile.kmk
index a17e655..a4caa91 100644
--- a/src/VBox/Devices/Makefile.kmk
+++ b/src/VBox/Devices/Makefile.kmk
@@ -187,6 +187,8 @@ if !defined(VBOX_ONLY_EXTPACKS) && "$(intersects $(KBUILD_TARGET_ARCH),$(VBOX_SU
  	Input/UsbMouse.cpp \
  	Bus/DevPCI.cpp \
  	Bus/DevPciIch9.cpp \
+	Bus/DevVfio.cpp \
+	Bus/VfioDevice.cpp \
  	Bus/MsiCommon.cpp \
  	Bus/MsixCommon.cpp \
  	$(if $(VBOX_WITH_IOMMU_AMD),Bus/DevIommuAmd.cpp,) \
@@ -195,6 +197,10 @@ if !defined(VBOX_ONLY_EXTPACKS) && "$(intersects $(KBUILD_TARGET_ARCH),$(VBOX_SU
  	EFI/DevFlash.cpp \
  	EFI/FlashCore.cpp \
  	Graphics/DevVGA.cpp \
+	Graphics/DevVirtioGpuCmdHandler.cpp \
+	Graphics/DevVirtioGpu.cpp \
+	Graphics/DevVirtioGpuDisplayManager.cpp \
+	Graphics/DevVirtioGpuVBoxStubs.cpp \
  	Storage/DevATA.cpp \
  	PC/DevPit-i8254.cpp \
  	PC/DevPIC.cpp \
@@ -252,6 +258,16 @@ if !defined(VBOX_ONLY_EXTPACKS) && "$(intersects $(KBUILD_TARGET_ARCH),$(VBOX_SU
   VBoxDD_SOURCES += Storage/DrvHostFloppy.cpp
  endif
 
+ # VFIO
+ VBoxDD_LIBS.linux += $(LIB_VMM)
+ Bus/DevVfio.cpp_CXXFLAGS.linux += $(CYBERUS_CXX_FLAGS)
+ Bus/VfioDevice.cpp_CXXFLAGS.linux += $(CYBERUS_CXX_FLAGS)
+
+ # VirtioGPU
+ VBoxDD_DEFS += $(VMM_COMMON_DEFS)
+ Graphics/DevVirtioGpuCmdHandler.cpp_CXXFLAGS.linux += $(CYBERUS_CXX_FLAGS)
+ Graphics/DevVirtioGpu.cpp_CXXFLAGS.linux += $(CYBERUS_CXX_FLAGS)
+ Graphics/DevVirtioGpuVBoxStubs.cpp_CXXFLAGS.linux += $(CYBERUS_CXX_FLAGS)
 
  ifn1of ($(KBUILD_TARGET), darwin)
   VBoxDD_SOURCES += Storage/HBDMgmt-generic.cpp
diff --git a/src/VBox/Devices/PC/DevACPI.cpp b/src/VBox/Devices/PC/DevACPI.cpp
index abf2ba5..672b9af 100644
--- a/src/VBox/Devices/PC/DevACPI.cpp
+++ b/src/VBox/Devices/PC/DevACPI.cpp
@@ -812,7 +812,11 @@ struct ACPITBLISO
     uint16_t            u16Flags;               /**< MPS INTI flags Global */
 };
 AssertCompileSize(ACPITBLISO, 10);
-#define NUMBER_OF_IRQ_SOURCE_OVERRIDES 2
+#ifdef VBOX_WITH_KVM_IRQCHIP_FULL
+#define NUMBER_OF_IRQ_SOURCE_OVERRIDES (10)
+#else
+#define NUMBER_OF_IRQ_SOURCE_OVERRIDES (2)
+#endif
 
 /** HPET Descriptor Structure */
 struct ACPITBLHPET
@@ -3295,8 +3299,73 @@ static void acpiR3SetupMadt(PPDMDEVINS pDevIns, PACPISTATE pThis, RTGCPHYS32 add
     isos[1].u8Bus      = 0; /* Must be 0 */
     isos[1].u8Source   = 9; /* IRQ9 */
     isos[1].u32GSI     = 9; /* connected to pin 9 */
+#ifdef VBOX_WITH_KVM_IRQCHIP_FULL
+    isos[1].u16Flags   = 0xd; /* active high, level triggered */
+#else
     isos[1].u16Flags   = 0xf; /* active low, level triggered */
+#endif
+
+#ifdef VBOX_WITH_KVM_IRQCHIP_FULL
+    isos[2].u8Type     = 2;
+    isos[2].u8Length   = sizeof(ACPITBLISO);
+    isos[2].u8Bus      = 0; /* Must be 0 */
+    isos[2].u8Source   = 16; /* IRQ16 */
+    isos[2].u32GSI     = 16; /* connected to pin 16 */
+    isos[2].u16Flags   = 0xd; /* active high, level triggered */
+
+    isos[3].u8Type     = 2;
+    isos[3].u8Length   = sizeof(ACPITBLISO);
+    isos[3].u8Bus      = 0; /* Must be 0 */
+    isos[3].u8Source   = 17; /* IRQ17 */
+    isos[3].u32GSI     = 17; /* connected to pin 17 */
+    isos[3].u16Flags   = 0xd; /* active high, level triggered */
+
+    isos[4].u8Type     = 2;
+    isos[4].u8Length   = sizeof(ACPITBLISO);
+    isos[4].u8Bus      = 0; /* Must be 0 */
+    isos[4].u8Source   = 18; /* IRQ18 */
+    isos[4].u32GSI     = 18; /* connected to pin 18 */
+    isos[4].u16Flags   = 0xd; /* active high, level triggered */
+
+    isos[5].u8Type     = 2;
+    isos[5].u8Length   = sizeof(ACPITBLISO);
+    isos[5].u8Bus      = 0; /* Must be 0 */
+    isos[5].u8Source   = 19; /* IRQ19 */
+    isos[5].u32GSI     = 19; /* connected to pin 19 */
+    isos[5].u16Flags   = 0xd; /* active high, level triggered */
+
+    isos[6].u8Type     = 2;
+    isos[6].u8Length   = sizeof(ACPITBLISO);
+    isos[6].u8Bus      = 0; /* Must be 0 */
+    isos[6].u8Source   = 20; /* IRQ20 */
+    isos[6].u32GSI     = 20; /* connected to pin 20 */
+    isos[6].u16Flags   = 0xd; /* active high, level triggered */
+
+    isos[7].u8Type     = 2;
+    isos[7].u8Length   = sizeof(ACPITBLISO);
+    isos[7].u8Bus      = 0; /* Must be 0 */
+    isos[7].u8Source   = 21; /* IRQ21 */
+    isos[7].u32GSI     = 21; /* connected to pin 21 */
+    isos[7].u16Flags   = 0xd; /* active high, level triggered */
+
+    isos[8].u8Type     = 2;
+    isos[8].u8Length   = sizeof(ACPITBLISO);
+    isos[8].u8Bus      = 0; /* Must be 0 */
+    isos[8].u8Source   = 22; /* IRQ22 */
+    isos[8].u32GSI     = 22; /* connected to pin 22 */
+    isos[8].u16Flags   = 0xd; /* active high, level triggered */
+
+    isos[9].u8Type     = 2;
+    isos[9].u8Length   = sizeof(ACPITBLISO);
+    isos[9].u8Bus      = 0; /* Must be 0 */
+    isos[9].u8Source   = 23; /* IRQ23 */
+    isos[9].u32GSI     = 23; /* connected to pin 23 */
+    isos[9].u16Flags   = 0xd; /* active high, level triggered */
+
+    Assert(NUMBER_OF_IRQ_SOURCE_OVERRIDES == 10);
+#else
     Assert(NUMBER_OF_IRQ_SOURCE_OVERRIDES == 2);
+#endif
 
     madt.header_addr()->u8Checksum = acpiR3Checksum(madt.data(), madt.size());
     acpiR3PhysCopy(pDevIns, addr, madt.data(), madt.size());
diff --git a/src/VBox/Devices/PC/DevIoApic.cpp b/src/VBox/Devices/PC/DevIoApic.cpp
index a69d8e3..f56c667 100644
--- a/src/VBox/Devices/PC/DevIoApic.cpp
+++ b/src/VBox/Devices/PC/DevIoApic.cpp
@@ -32,6 +32,14 @@
 #define LOG_GROUP LOG_GROUP_DEV_IOAPIC
 #include <VBox/log.h>
 #include <VBox/vmm/hm.h>
+
+#ifdef VBOX_WITH_KVM
+#include <VBox/vmm/nem.h>
+#ifdef IN_RING3
+#include <vector>
+#endif
+#endif
+
 #include <VBox/msi.h>
 #include <VBox/pci.h>
 #include <VBox/vmm/pdmdev.h>
@@ -40,7 +48,6 @@
 #include <iprt/x86.h>
 #include <iprt/string.h>
 
-
 /*********************************************************************************************************************************
 *   Defined Constants And Macros                                                                                                 *
 *********************************************************************************************************************************/
@@ -68,6 +75,10 @@ Controller" */
 
 /** The number of interrupt input pins. */
 #define IOAPIC_NUM_INTR_PINS                    24
+
+#if defined(IN_RING3) && defined(VBOX_WITH_KVM)
+AssertCompile(IOAPIC_NUM_INTR_PINS == KVM_IRQCHIP_NUM_IOAPIC_INTR_PINS);
+#endif
 /** Maximum redirection entires. */
 #define IOAPIC_MAX_RTE_INDEX                    (IOAPIC_NUM_INTR_PINS - 1)
 /** Reduced RTEs used by SIO.A (82379AB). */
@@ -340,6 +351,19 @@ typedef struct IOAPIC
 #endif
     /** Per-vector stats. */
     STAMCOUNTER             aStatVectors[256];
+
+#if defined(VBOX_WITH_KVM) && !defined(VBOX_WITH_KVM_IRQCHIP_FULL) && defined(IN_RING3)
+    /** Handle to the timer that is used for delayed IRQ injection */
+    TMTIMERHANDLE           hIoapicDelayedInjectionHandler;
+
+    /** List of PINs that need delayed injection handling, protected by IOAPIC_LOCK */
+    std::vector<uint8_t> delayed_interrupt_list;
+
+    /** A per-GSI counter that is increased whenever a level triggered interrupt is
+        instantly pending following an EOI. The counter is reset to zero when no
+        interrupt is pending following an EOI. */
+    uint64_t gsi_counter[IOAPIC_NUM_INTR_PINS] {};
+#endif
 } IOAPIC;
 AssertCompileMemberAlignment(IOAPIC, au64RedirTable, 8);
 /** Pointer to shared IOAPIC data. */
@@ -572,6 +596,35 @@ DECLINLINE(void) ioapicGetMsiFromRte(uint64_t u64Rte, IOAPICTYPE enmType, PMSIMS
 #endif
 
 
+static bool handlePossibleInterruptStorm(PPDMDEVINS pDevIns, PIOAPIC pThis, unsigned idxRte)
+{
+#if defined(VBOX_WITH_KVM) && !defined(VBOX_WITH_KVM_IRQCHIP_FULL) && defined(IN_RING3)
+
+    /** There are buggy drivers that do not clear all interrupt conditions before sending an EOI to the IOAPIC.
+        On real HW, such drivers make slow foward progress because the IOAPIC needs a few cycles the next interrupt
+        is injected after an EOI. If we detect this situation, delay the interrupt and give the guest driver the
+        opportunity to fix this mess. */
+
+    static constexpr uint64_t NUM_EXCESSIVE_INTERRUPTS {10000};
+    if (++pThis->gsi_counter[idxRte] == NUM_EXCESSIVE_INTERRUPTS) {
+        LogRel(("Interrupt storm on GSI %d, delaying injection\n", idxRte));
+
+        // Reset our counter so the next injection of this GSI succeeds.
+        pThis->gsi_counter[idxRte] = 0;
+
+        // Remember which GSI we have to raise after our delay.
+        pThis->delayed_interrupt_list.push_back(idxRte);
+
+        // Arm the delayed injection handler.
+        PDMDevHlpTimerSetMillies(pDevIns, pThis->hIoapicDelayedInjectionHandler, 100 /* ms */);
+        return true;
+    }
+#else
+    NOREF(pDevIns); NOREF(pThis); NOREF(idxRte);
+#endif
+
+    return false;
+}
 /**
  * Signals the next pending interrupt for the specified Redirection Table Entry
  * (RTE).
@@ -608,6 +661,10 @@ static void ioapicSignalIntrForRte(PPDMDEVINS pDevIns, PIOAPIC pThis, PIOAPICCC
             STAM_COUNTER_INC(&pThis->StatSuppressedLevelIntr);
             return;
         }
+
+        if (handlePossibleInterruptStorm(pDevIns, pThis, idxRte)) {
+            return;
+        }
     }
 
     XAPICINTR ApicIntr;
@@ -655,6 +712,11 @@ static void ioapicSignalIntrForRte(PPDMDEVINS pDevIns, PIOAPIC pThis, PIOAPICCC
     }
 #endif
 
+#if defined(IN_RING3) && defined(VBOX_WITH_KVM) && !defined(VBOX_WITH_KVM_IRQCHIP_FULL)
+    AssertReleaseMsg(rcRemap == VERR_IOMMU_NOT_PRESENT || rcRemap == VERR_IOMMU_CANNOT_CALL_SELF,
+                     ("Interrupt remapping not supported yet."));
+    int rc = pThisCC->pIoApicHlp->pfnKvmSplitIrqchipDeliverMsi(pDevIns, &MsiIn);
+#else
     uint32_t const u32TagSrc = pThis->au32TagSrc[idxRte];
     Log2(("IOAPIC: Signaling %s-triggered interrupt. Dest=%#x DestMode=%s Vector=%#x (%u)\n",
           ApicIntr.u8TriggerMode == IOAPIC_RTE_TRIGGER_MODE_EDGE ? "edge" : "level", ApicIntr.u8Dest,
@@ -672,6 +734,7 @@ static void ioapicSignalIntrForRte(PPDMDEVINS pDevIns, PIOAPIC pThis, PIOAPICCC
                                                     ApicIntr.u8Polarity,
                                                     ApicIntr.u8TriggerMode,
                                                     u32TagSrc);
+#endif
     /* Can't reschedule to R3. */
     Assert(rc == VINF_SUCCESS || rc == VERR_APIC_INTR_DISCARDED);
 #ifdef DEBUG_ramshankar
@@ -781,6 +844,16 @@ static VBOXSTRICTRC ioapicSetRedirTableEntry(PPDMDEVINS pDevIns, PIOAPIC pThis,
 
         LogFlow(("IOAPIC: ioapicSetRedirTableEntry: uIndex=%#RX32 idxRte=%u uValue=%#RX32\n", uIndex, idxRte, uValue));
 
+#if defined(VBOX_WITH_KVM) && defined(IN_RING3) && !defined(VBOX_WITH_KVM_IRQCHIP_FULL)
+        const uint64_t u64RteNew { pThis->au64RedirTable[idxRte] };
+        if (not IOAPIC_RTE_IS_MASKED(u64RteNew)) {
+            MSIMSG msi;
+            RT_ZERO(msi);
+            ioapicGetMsiFromRte(u64RteNew, pThis->enmType, &msi);
+            rc = pThisCC->pIoApicHlp->pfnKvmSplitIrqchipAddUpdateRTE(pDevIns, idxRte, &msi);
+        }
+#endif
+
         /*
          * Signal the next pending interrupt for this RTE.
          */
@@ -790,7 +863,6 @@ static VBOXSTRICTRC ioapicSetRedirTableEntry(PPDMDEVINS pDevIns, PIOAPIC pThis,
             LogFlow(("IOAPIC: ioapicSetRedirTableEntry: Signalling pending interrupt. idxRte=%u\n", idxRte));
             ioapicSignalIntrForRte(pDevIns, pThis, pThisCC, idxRte);
         }
-
         IOAPIC_UNLOCK(pDevIns, pThis, pThisCC);
     }
     else
@@ -940,6 +1012,15 @@ static DECLCALLBACK(void) ioapicSetIrq(PPDMDEVINS pDevIns, PCIBDF uBusDevFn, int
     PIOAPIC   pThis   = PDMDEVINS_2_DATA(pDevIns, PIOAPIC);
     PIOAPICCC pThisCC = PDMDEVINS_2_DATA_CC(pDevIns, PIOAPICCC);
     LogFlow(("IOAPIC: ioapicSetIrq: iIrq=%d iLevel=%d uTagSrc=%#x\n", iIrq, iLevel, uTagSrc));
+#if defined(IN_RING3) && defined(VBOX_WITH_KVM_IRQCHIP_FULL)
+    pThisCC->pIoApicHlp->pfnKvmSetIrqLine(pDevIns, iIrq, iLevel & PDM_IRQ_LEVEL_HIGH);
+
+    if ((iLevel & PDM_IRQ_LEVEL_FLIP_FLOP) == PDM_IRQ_LEVEL_FLIP_FLOP) {
+        pThisCC->pIoApicHlp->pfnKvmSetIrqLine(pDevIns, iIrq, PDM_IRQ_LEVEL_LOW);
+    }
+
+    return;
+#endif
 
     STAM_COUNTER_INC(&pThis->CTX_SUFF_Z(StatSetIrq));
 
@@ -962,6 +1043,9 @@ static DECLCALLBACK(void) ioapicSetIrq(PPDMDEVINS pDevIns, PCIBDF uBusDevFn, int
 #endif
         if (!fActive)
         {
+#if defined(VBOX_WITH_KVM) && !defined(VBOX_WITH_KVM_IRQCHIP_FULL) && defined(IN_RING3)
+            pThis->gsi_counter[idxRte] = 0;
+#endif
             pThis->uIrr &= ~uPinMask;
             pThis->au32TagSrc[idxRte] = 0;
             IOAPIC_UNLOCK(pDevIns, pThis, pThisCC);
@@ -1080,7 +1164,11 @@ static DECLCALLBACK(void) ioapicSendMsi(PPDMDEVINS pDevIns, PCIBDF uBusDevFn, PC
 #else
     NOREF(uBusDevFn);
 #endif
+#if defined(IN_RING3) && defined(VBOX_WITH_KVM)
+    int rc = pThisCC->pIoApicHlp->pfnKvmSplitIrqchipDeliverMsi(pDevIns, pMsi);
 
+    AssertReleaseMsg(rc == VINF_SUCCESS || rc == VERR_APIC_INTR_DISCARDED, ("ioapicSendMsi: Could not deliver MSI! error %d\n", rc));
+#else
     ioapicGetApicIntrFromMsi(pMsi, &ApicIntr);
 
     /*
@@ -1098,6 +1186,7 @@ static DECLCALLBACK(void) ioapicSendMsi(PPDMDEVINS pDevIns, PCIBDF uBusDevFn, PC
                                                     uTagSrc);
     /* Can't reschedule to R3. */
     Assert(rc == VINF_SUCCESS || rc == VERR_APIC_INTR_DISCARDED); NOREF(rc);
+#endif
 }
 
 
@@ -1444,10 +1533,33 @@ static DECLCALLBACK(void) ioapicR3DbgInfo(PPDMDEVINS pDevIns, PCDBGFINFOHLP pHlp
  */
 static DECLCALLBACK(int) ioapicR3SaveExec(PPDMDEVINS pDevIns, PSSMHANDLE pSSM)
 {
-    PCIOAPIC        pThis = PDMDEVINS_2_DATA(pDevIns, PCIOAPIC);
+    PIOAPIC         pThis = PDMDEVINS_2_DATA(pDevIns, PIOAPIC);
     PCPDMDEVHLPR3   pHlp  = pDevIns->pHlpR3;
     LogFlow(("IOAPIC: ioapicR3SaveExec\n"));
 
+#ifdef VBOX_WITH_KVM_IRQCHIP_FULL
+    PIOAPICCC pThisCC = PDMDEVINS_2_DATA_CC(pDevIns, PIOAPICCC);
+    KVMIOAPICSTATE kvm_ioapic_state;
+
+    for (unsigned pic = 0; pic < 2; ++pic) {
+        int rc = pThisCC->pIoApicHlp->pfnKvmGetIoApicState(pDevIns, &kvm_ioapic_state);
+        AssertLogRelMsg(RT_SUCCESS(rc), ("Unable to retrieve IOPIC state from KVM"));
+
+        /**
+         * There's no need to look at kvm_ioapic_state.base_address because
+         * VBox does not support IOAPIC relocation, thus, it will always be
+         * at IOAPIC_MMIO_BASE_PHYSADDR.
+         */
+        pThis->uIrr = kvm_ioapic_state.irr;
+        pThis->u8Id = kvm_ioapic_state.id;
+        pThis->u8Index = kvm_ioapic_state.ioregsel;
+
+        for (uint8_t idxRte = 0; idxRte < RT_ELEMENTS(pThis->au64RedirTable); idxRte++) {
+            pThis->au64RedirTable[idxRte] = kvm_ioapic_state.redirtbl[idxRte];
+        }
+    }
+#endif
+
     pHlp->pfnSSMPutU32(pSSM, pThis->uIrr);
     pHlp->pfnSSMPutU8(pSSM,  pThis->u8Id);
     pHlp->pfnSSMPutU8(pSSM,  pThis->u8Index);
@@ -1490,6 +1602,39 @@ static DECLCALLBACK(int) ioapicR3LoadExec(PPDMDEVINS pDevIns, PSSMHANDLE pSSM, u
     for (uint8_t idxRte = 0; idxRte < RT_ELEMENTS(pThis->au64RedirTable); idxRte++)
         pHlp->pfnSSMGetU64(pSSM, &pThis->au64RedirTable[idxRte]);
 
+#if defined(VBOX_WITH_KVM) && !defined(VBOX_WITH_KVM_IRQCHIP_FULL)
+    PIOAPICCC pThisCC = PDMDEVINS_2_DATA_CC(pDevIns, PIOAPICCC);
+    for (uint8_t idxRte = 0; idxRte < RT_ELEMENTS(pThis->au64RedirTable); idxRte++) {
+        const uint64_t u64RteNew { pThis->au64RedirTable[idxRte] };
+        if (not IOAPIC_RTE_IS_MASKED(u64RteNew) and (IOAPIC_RTE_GET_TRIGGER_MODE(u64RteNew) != IOAPIC_RTE_TRIGGER_MODE_EDGE)) {
+            MSIMSG msi;
+            RT_ZERO(msi);
+            ioapicGetMsiFromRte(u64RteNew, pThis->enmType, &msi);
+            int rc = pThisCC->pIoApicHlp->pfnKvmSplitIrqchipAddUpdateRTE(pDevIns, idxRte, &msi);
+            AssertLogRelMsg(RT_SUCCESS(rc), ("Adding redirection table entry failed."));
+        }
+    }
+#endif
+
+#ifdef VBOX_WITH_KVM_IRQCHIP_FULL
+    PIOAPICCC pThisCC = PDMDEVINS_2_DATA_CC(pDevIns, PIOAPICCC);
+    KVMIOAPICSTATE kvm_ioapic_state;
+
+    for (unsigned pic = 0; pic < 2; ++pic) {
+        kvm_ioapic_state.base_address = IOAPIC_MMIO_BASE_PHYSADDR;
+        kvm_ioapic_state.irr = pThis->uIrr;
+        kvm_ioapic_state.id = pThis->u8Id;
+        kvm_ioapic_state.ioregsel = pThis->u8Index;
+
+        for (uint8_t idxRte = 0; idxRte < RT_ELEMENTS(pThis->au64RedirTable); idxRte++) {
+            kvm_ioapic_state.redirtbl[idxRte] = pThis->au64RedirTable[idxRte];
+        }
+
+        int rc = pThisCC->pIoApicHlp->pfnKvmSetIoApicState(pDevIns, &kvm_ioapic_state);
+        AssertLogRelMsg(RT_SUCCESS(rc), ("Unable to retrieve IOPIC state from KVM"));
+    }
+#endif
+
     if (uVersion > IOAPIC_SAVED_STATE_VERSION_NO_FLIPFLOP_MAP)
         for (uint8_t idx = 0; idx < RT_ELEMENTS(pThis->bmFlipFlop); idx++)
             pHlp->pfnSSMGetU64(pSSM, &pThis->bmFlipFlop[idx]);
@@ -1518,6 +1663,10 @@ static DECLCALLBACK(void) ioapicR3Reset(PPDMDEVINS pDevIns)
     {
         pThis->au64RedirTable[idxRte] = IOAPIC_RTE_MASK;
         pThis->au32TagSrc[idxRte] = 0;
+#if defined(VBOX_WITH_KVM) && !defined(VBOX_WITH_KVM_IRQCHIP_FULL)
+        int rc = pThisCC->pIoApicHlp->pfnKvmSplitIrqchipRemoveRTE(pDevIns, idxRte);
+        AssertLogRelMsg(RT_SUCCESS(rc), ("Removing redirection table entry failed."));
+#endif
     }
 
     IOAPIC_UNLOCK(pDevIns, pThis, pThisCC);
@@ -1545,6 +1694,10 @@ static DECLCALLBACK(int) ioapicR3Destruct(PPDMDEVINS pDevIns)
     PIOAPIC pThis = PDMDEVINS_2_DATA(pDevIns, PIOAPIC);
     LogFlow(("IOAPIC: ioapicR3Destruct: pThis=%p\n", pThis));
 
+#if defined(VBOX_WITH_KVM) && !defined(VBOX_WITH_KVM_IRQCHIP_FULL) && defined(IN_RING3)
+    PDMDevHlpTimerDestroy(pDevIns, pThis->hIoapicDelayedInjectionHandler);
+#endif
+
 # ifndef IOAPIC_WITH_PDM_CRITSECT
     /*
      * Destroy the RTE critical section.
@@ -1558,6 +1711,26 @@ static DECLCALLBACK(int) ioapicR3Destruct(PPDMDEVINS pDevIns)
     return VINF_SUCCESS;
 }
 
+static DECLCALLBACK(void) ioapicDelayedInjectionHandler(PPDMDEVINS pDevIns, TMTIMERHANDLE hTimer, void *pvUser)
+{
+    NOREF(hTimer); NOREF(pvUser);
+#if defined(VBOX_WITH_KVM) && !defined(VBOX_WITH_KVM_IRQCHIP_FULL) && defined(IN_RING3)
+    PIOAPIC         pThis   = PDMDEVINS_2_DATA(pDevIns, PIOAPIC);
+    PIOAPICCC       pThisCC = PDMDEVINS_2_DATA_CC(pDevIns, PIOAPICCC);
+
+    IOAPIC_LOCK(pDevIns, pThis, pThisCC, VERR_IGNORED);
+
+    for(auto iPin : pThis->delayed_interrupt_list) {
+        ioapicSignalIntrForRte(pDevIns, pThis, pThisCC, iPin);
+    }
+
+    pThis->delayed_interrupt_list.clear();
+
+    IOAPIC_UNLOCK(pDevIns, pThis, pThisCC);
+#else
+    NOREF(pDevIns);
+#endif
+}
 
 /**
  * @interface_method_impl{PDMDEVREG,pfnConstruct}
@@ -1571,6 +1744,12 @@ static DECLCALLBACK(int) ioapicR3Construct(PPDMDEVINS pDevIns, int iInstance, PC
     LogFlow(("IOAPIC: ioapicR3Construct: pThis=%p iInstance=%d\n", pThis, iInstance));
     Assert(iInstance == 0); RT_NOREF(iInstance);
 
+#if defined(VBOX_WITH_KVM) && !defined(VBOX_WITH_KVM_IRQCHIP_FULL) && defined(IN_RING3)
+    int rc_timer = PDMDevHlpTimerCreate(pDevIns, TMCLOCK_VIRTUAL, ioapicDelayedInjectionHandler, pThis,
+            TMTIMER_FLAGS_NO_CRIT_SECT | TMTIMER_FLAGS_NO_RING0, "IOAPIC Delayed IRQ", &pThis->hIoapicDelayedInjectionHandler);
+    AssertRCReturn(rc_timer, rc_timer);
+#endif
+
     /*
      * Validate and read the configuration.
      */
diff --git a/src/VBox/Devices/PC/DevPIC.cpp b/src/VBox/Devices/PC/DevPIC.cpp
index b4e1959..f44e2c6 100644
--- a/src/VBox/Devices/PC/DevPIC.cpp
+++ b/src/VBox/Devices/PC/DevPIC.cpp
@@ -366,6 +366,16 @@ static DECLCALLBACK(void) picSetIrq(PPDMDEVINS pDevIns, int iIrq, int iLevel, ui
 {
     PDEVPIC     pThis   = PDMDEVINS_2_DATA(pDevIns, PDEVPIC);
     PDEVPICCC   pThisCC = PDMDEVINS_2_DATA_CC(pDevIns, PDEVPICCC);
+
+#if defined(IN_RING3) && defined(VBOX_WITH_KVM_IRQCHIP_FULL)
+    pThisCC->pPicHlp->pfnKvmSetIrqLine(pDevIns, iIrq, iLevel & PDM_IRQ_LEVEL_HIGH);
+
+    if ((iLevel & PDM_IRQ_LEVEL_FLIP_FLOP) == PDM_IRQ_LEVEL_FLIP_FLOP) {
+        pThisCC->pPicHlp->pfnKvmSetIrqLine(pDevIns, iIrq, PDM_IRQ_LEVEL_LOW);
+    }
+
+    return;
+#else
     AssertMsgReturnVoid(iIrq < 16, ("iIrq=%d\n", iIrq));
 
     Log(("picSetIrq %d %d\n", iIrq, iLevel));
@@ -383,6 +393,7 @@ static DECLCALLBACK(void) picSetIrq(PPDMDEVINS pDevIns, int iIrq, int iLevel, ui
     }
     pic_set_irq1(&RT_SAFE_SUBSCRIPT(pThis->aPics, iIrq >> 3), iIrq & 7, iLevel & PDM_IRQ_LEVEL_HIGH, uTagSrc);
     pic_update_irq(pDevIns, pThis, pThisCC);
+#endif
 }
 
 
@@ -830,6 +841,33 @@ static DECLCALLBACK(int) picR3SaveExec(PPDMDEVINS pDevIns, PSSMHANDLE pSSM)
     PDEVPIC         pThis = PDMDEVINS_2_DATA(pDevIns, PDEVPIC);
     PCPDMDEVHLPR3   pHlp  = pDevIns->pHlpR3;
 
+#ifdef VBOX_WITH_KVM_IRQCHIP_FULL
+    PDEVPICCC   pThisCC = PDMDEVINS_2_DATA_CC(pDevIns, PDEVPICCC);
+    KVMPICSTATE kvm_pic_state;
+
+    for (unsigned pic = 0; pic < 2; ++pic) {
+        int rc = pThisCC->pPicHlp->pfnKvmGetPicState(pDevIns, pic == 0 ? KVMIRQCHIP::PIC_MASTER : KVMIRQCHIP::PIC_SLAVE, &kvm_pic_state);
+        AssertLogRelMsg(RT_SUCCESS(rc), ("Unable to retrieve PIC state from KVM"));
+
+        pThis->aPics[pic].last_irr = kvm_pic_state.last_irr;
+        pThis->aPics[pic].irr = kvm_pic_state.irr;
+        pThis->aPics[pic].imr = kvm_pic_state.imr;
+        pThis->aPics[pic].isr = kvm_pic_state.isr;
+        pThis->aPics[pic].priority_add = kvm_pic_state.priority_add;
+        pThis->aPics[pic].irq_base = kvm_pic_state.irq_base;
+        pThis->aPics[pic].read_reg_select = kvm_pic_state.read_reg_select;
+        pThis->aPics[pic].poll = kvm_pic_state.poll;
+        pThis->aPics[pic].special_mask = kvm_pic_state.special_mask;
+        pThis->aPics[pic].init_state = kvm_pic_state.init_state;
+        pThis->aPics[pic].auto_eoi = kvm_pic_state.auto_eoi;
+        pThis->aPics[pic].rotate_on_auto_eoi = kvm_pic_state.rotate_on_auto_eoi;
+        pThis->aPics[pic].special_fully_nested_mode = kvm_pic_state.special_fully_nested_mode;
+        pThis->aPics[pic].init4 = kvm_pic_state.init4;
+        pThis->aPics[pic].elcr = kvm_pic_state.elcr;
+        pThis->aPics[pic].elcr_mask = kvm_pic_state.elcr_mask;
+    }
+#endif
+
     for (unsigned i = 0; i < RT_ELEMENTS(pThis->aPics); i++)
     {
         pHlp->pfnSSMPutU8(pSSM, pThis->aPics[i].last_irr);
@@ -883,6 +921,33 @@ static DECLCALLBACK(int) picR3LoadExec(PPDMDEVINS pDevIns, PSSMHANDLE pSSM, uint
         pHlp->pfnSSMGetU8(pSSM, &pThis->aPics[i].elcr);
     }
 
+#ifdef VBOX_WITH_KVM_IRQCHIP_FULL
+    PDEVPICCC   pThisCC = PDMDEVINS_2_DATA_CC(pDevIns, PDEVPICCC);
+    KVMPICSTATE kvm_pic_state;
+
+    for (unsigned pic = 0; pic < 2; ++pic) {
+        kvm_pic_state.last_irr = pThis->aPics[pic].last_irr;
+        kvm_pic_state.irr = pThis->aPics[pic].irr;
+        kvm_pic_state.imr = pThis->aPics[pic].imr;
+        kvm_pic_state.isr = pThis->aPics[pic].isr;
+        kvm_pic_state.priority_add = pThis->aPics[pic].priority_add;
+        kvm_pic_state.irq_base = pThis->aPics[pic].irq_base;
+        kvm_pic_state.read_reg_select = pThis->aPics[pic].read_reg_select;
+        kvm_pic_state.poll = pThis->aPics[pic].poll;
+        kvm_pic_state.special_mask = pThis->aPics[pic].special_mask;
+        kvm_pic_state.init_state = pThis->aPics[pic].init_state;
+        kvm_pic_state.auto_eoi = pThis->aPics[pic].auto_eoi;
+        kvm_pic_state.rotate_on_auto_eoi = pThis->aPics[pic].rotate_on_auto_eoi;
+        kvm_pic_state.special_fully_nested_mode = pThis->aPics[pic].special_fully_nested_mode;
+        kvm_pic_state.init4 = pThis->aPics[pic].init4;
+        kvm_pic_state.elcr = pThis->aPics[pic].elcr;
+        kvm_pic_state.elcr_mask = pThis->aPics[pic].elcr_mask;
+
+        int rc = pThisCC->pPicHlp->pfnKvmSetPicState(pDevIns, pic == 0 ? KVMIRQCHIP::PIC_MASTER : KVMIRQCHIP::PIC_SLAVE, &kvm_pic_state);
+        AssertLogRelMsg(RT_SUCCESS(rc), ("Unable to push PIC state to KVM"));
+    }
+#endif
+
     /* Note! PDM will restore the VMCPU_FF_INTERRUPT_PIC state. */
     return VINF_SUCCESS;
 }
diff --git a/src/VBox/Devices/VirtIO/VirtioCore.cpp b/src/VBox/Devices/VirtIO/VirtioCore.cpp
index f0ed6e4..6e33955 100644
--- a/src/VBox/Devices/VirtIO/VirtioCore.cpp
+++ b/src/VBox/Devices/VirtIO/VirtioCore.cpp
@@ -1446,7 +1446,7 @@ static int virtioNudgeGuest(PPDMDEVINS pDevIns, PVIRTIOCORE pVirtio, uint8_t uCa
 
     if (!pVirtio->fMsiSupport)
     {
-        pVirtio->uISR |= uCause;
+        pVirtio->uISR = (VIRTIO_ISR_DEVICE_CONFIG == uCause) ? 0x3 : uCause;
         PDMDevHlpPCISetIrq(pDevIns, 0, PDM_IRQ_LEVEL_HIGH);
     }
     else if (uMsixVector != VIRTIO_MSI_NO_VECTOR)
diff --git a/src/VBox/Devices/build/VBoxDD.cpp b/src/VBox/Devices/build/VBoxDD.cpp
index 36b12c6..e7497c6 100644
--- a/src/VBox/Devices/build/VBoxDD.cpp
+++ b/src/VBox/Devices/build/VBoxDD.cpp
@@ -218,6 +218,9 @@ extern "C" DECLEXPORT(int) VBoxDevicesRegister(PPDMDEVREGCB pCallbacks, uint32_t
     if (RT_FAILURE(rc))
         return rc;
 #endif
+    rc = pCallbacks->pfnRegister(pCallbacks, &g_DeviceVfioDev);
+    if (RT_FAILURE(rc))
+        return rc;
     rc = pCallbacks->pfnRegister(pCallbacks, &g_DeviceGIMDev);
     if (RT_FAILURE(rc))
         return rc;
@@ -247,6 +250,9 @@ extern "C" DECLEXPORT(int) VBoxDevicesRegister(PPDMDEVREGCB pCallbacks, uint32_t
     if (RT_FAILURE(rc))
         return rc;
 #endif
+    rc = pCallbacks->pfnRegister(pCallbacks, &g_DeviceVirtioGpuDev);
+    if (RT_FAILURE(rc))
+        return rc;
 
     return VINF_SUCCESS;
 }
diff --git a/src/VBox/Devices/build/VBoxDD.h b/src/VBox/Devices/build/VBoxDD.h
index 9350f42..63dedfa 100644
--- a/src/VBox/Devices/build/VBoxDD.h
+++ b/src/VBox/Devices/build/VBoxDD.h
@@ -107,7 +107,9 @@ extern const PDMDEVREG g_DeviceEFI;
 #ifdef VBOX_WITH_PCI_PASSTHROUGH_IMPL
 extern const PDMDEVREG g_DevicePciRaw;
 #endif
+extern const PDMDEVREG g_DeviceVfioDev;
 extern const PDMDEVREG g_DeviceGIMDev;
+extern const PDMDEVREG g_DeviceVirtioGpuDev;
 extern const PDMDEVREG g_DeviceLPC;
 #ifdef VBOX_WITH_VIRTUALKD
 extern const PDMDEVREG g_DeviceVirtualKD;
diff --git a/src/VBox/Devices/testcase/Makefile.kmk b/src/VBox/Devices/testcase/Makefile.kmk
index a65768b..288199e 100644
--- a/src/VBox/Devices/testcase/Makefile.kmk
+++ b/src/VBox/Devices/testcase/Makefile.kmk
@@ -70,12 +70,18 @@ ifeq ($(KBUILD_TARGET),$(KBUILD_HOST))
  ifeq ($(filter-out x86.x86 amd64.amd64 x86.amd64, $(KBUILD_TARGET_ARCH).$(KBUILD_HOST_ARCH)),)
   OTHERS += \
   	$(VBOX_DEVICES_TEST_OUT_DIR)/tstDeviceStructSize.run
+  if defined(VBOX_WITH_SUPERNOVA_UNITTESTS)
+	OTHERS += $(VBOX_DEVICES_TEST_OUT_DIR)/tstVirtioGpuCmdHandling.run
+  endif
  endif
 endif
 
 # The normal testing pass.
-TESTING += \
-	$(VBOX_DEVICES_TEST_OUT_DIR)/tstDeviceStructSize.run
+TESTING += $(VBOX_DEVICES_TEST_OUT_DIR)/tstDeviceStructSize.run
+
+if defined(VBOX_WITH_SUPERNOVA_UNITTESTS)
+	TESTING += $(VBOX_DEVICES_TEST_OUT_DIR)/tstVirtioGpuCmdHandling.run
+endif
 
 ifdef VBOX_WITH_RAW_MODE
  #
@@ -128,6 +134,27 @@ ifdef VBOX_WITH_RAW_MODE
 endif
 tstDeviceStructSize_INCS      += $(VBOX_PATH_VMM_DEVICES_SRC)
 
+if defined(VBOX_WITH_SUPERNOVA_UNITTESTS)
+PROGRAMS += tstVirtioGpuCmdHandling
+endif
+
+tstVirtioGpuCmdHandling_TEMPLATE = VBOXR3AUTOTST
+tstVirtioGpuCmdHandling_DEFS     = $(VBOX_DEVICES_TESTS_FEATURES)
+tstVirtioGpuCmdHandling_INCS     = \
+	$(VBOX_PATH_DEVICES_SRC)/build \
+	$(VBOX_PATH_DEVICES_SRC)/Bus \
+	$(VBOX_DEVICES_TEST_OUT_DIR) \
+	$(VBOX_GRAPHICS_INCS) \
+	$(VBoxDD_INCS)
+tstVirtioGpuCmdHandling_SOURCES  = \
+	../Graphics/DevVirtioGpuCmdHandler.cpp \
+	tstVirtioGpuCmdHandling.cpp
+tstVirtioGpuCmdHandling_LIBS    = \
+	$(VBOX_LIB_RUNTIME_STATIC)
+tstVirtioGpuCmdHandling_CLEAN    = \
+	$(VBOX_DEVICES_TEST_OUT_DIR)/tstVirtioGpuCmdHandling.run
+tstVirtioGpuCmdHandling_INCS     += $(VBOX_PATH_VMM_DEVICES_SRC)
+
 #
 # Run rule for tstDeviceStructSize.
 #
@@ -149,8 +176,14 @@ $(VBOX_DEVICES_TEST_OUT_DIR)/tstDeviceStructSize.run: $$(tstDeviceStructSize_1_S
 	$^
 	$(QUIET)$(APPEND) "$@" "done"
 
+$(VBOX_DEVICES_TEST_OUT_DIR)/tstVirtioGpuCmdHandling.run: $$(tstVirtioGpuCmdHandling_1_STAGE_TARGET) | $$(dir $$@)
+	$(QUIET)$(RM) -f $@
+	$^
+	$(QUIET)$(APPEND) "$@" "done"
+
 # alias for the struct test.
 run-struct-tests: $(VBOX_DEVICES_TEST_OUT_DIR)/tstDeviceStructSize.run
+run-supernova-tests: $(VBOX_DEVICES_TEST_OUT_DIR)/tstVirtioGpuCmdHandling.run
 
 
 include $(FILE_KBUILD_SUB_FOOTER)
diff --git a/src/VBox/Devices/testcase/tstVirtioGpuAdapter.hpp b/src/VBox/Devices/testcase/tstVirtioGpuAdapter.hpp
new file mode 100644
index 0000000..9e23a73
--- /dev/null
+++ b/src/VBox/Devices/testcase/tstVirtioGpuAdapter.hpp
@@ -0,0 +1,181 @@
+/*
+ * Copyright (C) Cyberus Technology GmbH.
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <https://www.gnu.org/licenses/>.
+ *
+ * SPDX-License-Identifier: GPL-3.0-or-later
+ */
+
+#include "../Graphics/DevVirtioGpuCmdHandler.hpp"
+
+#include <catch2/catch.hpp>
+
+#include <array>
+#include <cstdlib>
+#include <numeric>
+#include <tuple>
+#include <vector>
+
+static constexpr uint32_t TST_VIOGPU_MAX_SCANOUTS {2u};
+
+class tstVirtioAdapter final : public VirtioGpuCmdHandler::VirtioAdapter
+{
+public:
+    uint8_t* sendBuf_ {nullptr}; // During each virtqBufDrain, we will read from this pointer into pv
+    uint8_t* recvBuf_ {nullptr}; // During each virtqBufPut, we will write to this pointer
+
+    template <typename SendType, typename ReceiveType>
+    void prepareCommand(SendType* send, ReceiveType* recv, uint16_t uVirtq, PVIRTQBUF pVirtqBuf)
+    {
+        prepareCommand(send, sizeof(SendType), recv, sizeof(ReceiveType), uVirtq, pVirtqBuf);
+    }
+
+    void prepareCommand(void* sendBuf, size_t sendSz, void* recvBuf, size_t recvSz, uint16_t uVirtq, PVIRTQBUF pVirtqBuf)
+    {
+        sendBuf_ = reinterpret_cast<uint8_t*>(sendBuf);
+        pVirtqBuf->cbPhysSend = sendSz;
+        recvBuf_ = reinterpret_cast<uint8_t*>(recvBuf);
+        pVirtqBuf->cbPhysReturn = recvSz;
+        pVirtqBuf->uVirtq = uVirtq;
+    }
+
+    void virtqBufDrain(PVIRTQBUF pVirtqBuf, void *pv, size_t cb) final
+    {
+        REQUIRE(pVirtqBuf != nullptr);
+        REQUIRE(pv != nullptr);
+        REQUIRE(cb != 0);
+
+        // The cmdHandler has to check wether the size of the src buffer is sufficient for the drain-request
+        REQUIRE(pVirtqBuf->cbPhysSend >= cb);
+        std::memcpy(pv, sendBuf_, cb);
+        pVirtqBuf->cbPhysSend -= cb;
+        sendBuf_ += cb;
+    }
+
+    void virtqBufPut(PVIRTQBUF pVirtqBuf, void *pv, size_t cb) final
+    {
+        REQUIRE(pVirtqBuf != nullptr);
+        REQUIRE(pv != nullptr);
+        REQUIRE(cb != 0);
+
+        // The cmdHandler has to check wether the size of the dst buffer is sufficient for the put-request
+        REQUIRE(pVirtqBuf->cbPhysReturn >= cb);
+        std::memcpy(recvBuf_, pv, cb);
+        pVirtqBuf->cbPhysReturn -= cb;
+        recvBuf_ += cb;
+    }
+
+    void virtqSyncRings(PVIRTQBUF pVirtqBuf) final
+    {
+        REQUIRE(pVirtqBuf != 0);
+    }
+};
+
+class tstDisplayAdapter final : public VirtioGpuCmdHandler::displayAdapter
+{
+public:
+    std::vector<uint8_t> framebuf;
+    uint32_t displayIdx {0};
+    bool fAttached {false};
+    bool fFlushed  {false};
+    uint32_t uCurrentWidth {virtioGpu::INITIAL_WIDTH};
+    uint32_t uCurrentHeight {virtioGpu::INITIAL_HEIGHT};
+
+    tstDisplayAdapter() = default;
+
+    void reset()
+    {
+        framebuf.clear();
+        fAttached = false;
+        fFlushed = false;
+        uCurrentWidth = virtioGpu::INITIAL_WIDTH;
+        uCurrentHeight = virtioGpu::INITIAL_HEIGHT;
+    }
+
+    void resize(uint32_t uWidth, uint32_t uHeight) final
+    {
+        uCurrentWidth = uWidth;
+        uCurrentHeight = uHeight;
+
+        framebuf.resize(cbFrameBuffer());
+    }
+
+    std::tuple<uint32_t, uint32_t> size() final
+    {
+        return std::make_tuple(uCurrentWidth, uCurrentHeight);
+    }
+
+    void attachDisplay(unsigned iLUN) final
+    {
+        REQUIRE(iLUN == displayIdx);
+        fAttached = true;
+    }
+
+    void detachDisplay(unsigned iLUN) final
+    {
+        REQUIRE(iLUN == displayIdx);
+        fAttached = false;
+    }
+
+    bool isAttachedToDisplay() final
+    {
+        return fAttached;
+    }
+
+    void flush(uint32_t /*uWidth*/, uint32_t /*uHeight*/) final
+    {
+        fFlushed = true;
+    }
+
+    void* pFrameBuffer() final { return framebuf.data(); }
+    size_t cbFrameBuffer() final { return uCurrentWidth * uCurrentHeight * virtioGpuResource::BYTES_PER_PIXEL; }
+};
+
+class tstDisplayManager final : public VirtioGpuCmdHandler::DisplayManager
+{
+    std::array<tstDisplayAdapter, TST_VIOGPU_MAX_SCANOUTS> displayAdapters;
+public:
+    tstDisplayManager()
+    {
+        uint32_t displayIdx {0u};
+        for (auto& displayAdapterOne : displayAdapters) {
+            displayAdapterOne.displayIdx = displayIdx;
+            displayIdx++;
+        }
+    }
+
+    tstDisplayAdapter* display(uint32_t idx) final
+    {
+        if (idx > TST_VIOGPU_MAX_SCANOUTS-1) {
+            return nullptr;
+        }
+        return &displayAdapters.at(idx);
+    }
+};
+
+class tstMemoryAdapter final : public VirtioGpuCmdHandler::MemoryAdapter
+{
+public:
+    VecMappings mapGCPhys2HCVirt(const vecMemEntries& vBacking) final
+    {
+        vecMappings vMapping;
+        for (const auto& backing : vBacking) {
+            void* uAddr {reinterpret_cast<void*>(backing.uAddr_)};
+            vMapping.emplace_back(uAddr, backing.uLength_, nullptr);
+        }
+        return vMapping;
+    }
+
+    void releaseMappings(const vecMappings& /*vMapping*/) final { return ; }
+};
diff --git a/src/VBox/Devices/testcase/tstVirtioGpuCmdHandling.cpp b/src/VBox/Devices/testcase/tstVirtioGpuCmdHandling.cpp
new file mode 100644
index 0000000..a10d4e1
--- /dev/null
+++ b/src/VBox/Devices/testcase/tstVirtioGpuCmdHandling.cpp
@@ -0,0 +1,450 @@
+/*
+ * Copyright (C) Cyberus Technology GmbH.
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <https://www.gnu.org/licenses/>.
+ *
+ * SPDX-License-Identifier: GPL-3.0-or-later
+ */
+
+#include <VBox/types.h>
+#include <VBox/vmm/pdmdev.h>
+#include <VBox/vmm/stam.h>
+
+#define CATCH_CONFIG_MAIN
+#include <catch2/catch.hpp>
+
+#undef LOG_GROUP
+#include "../Graphics/DevVirtioGpuDefinitions.hpp"
+#include "../Graphics/DevVirtioGpuCmdHandler.hpp"
+#include "tstVirtioGpuAdapter.hpp"
+
+#include <algorithm>
+
+// virtioAdapter and memoryAdapter both have no state, thus we can reuse them
+static tstVirtioAdapter virtioAdapter;
+static tstMemoryAdapter memoryAdapter;
+
+static VIRTQBUF virtqBuf;
+
+static constexpr uint32_t RESOURCE_ID_ONE {1u};
+static constexpr uint32_t RESOURCE_ID_TWO {2u};
+
+static constexpr uint32_t SCANOUT_ID_ONE {0u};
+static constexpr uint32_t SCANOUT_ID_TWO {1u};
+
+static constexpr uint32_t RESOURCE_WIDTH {1920u};
+static constexpr uint32_t RESOURCE_HEIGHT {1080u};
+static constexpr uint32_t RESIZED_WIDTH {800u};
+static constexpr uint32_t RESIZED_HEIGHT {600u};
+
+static constexpr uint32_t NUM_BACKINGS {4u};
+static constexpr size_t BACKING_SIZE {X86_PAGE_SIZE};
+static constexpr size_t SIZE_FRAMEBUFFER {NUM_BACKINGS * BACKING_SIZE};
+
+static constexpr size_t ATTACH_BACKING_STRUCT_SIZE {sizeof(virtioGpu::resourceAttachBacking) + NUM_BACKINGS * sizeof(virtioGpu::resourceMemEntry)};
+
+TEST_CASE("handler returns out-of-memory error if request-buffer is too small")
+{
+    tstDisplayManager displayManager;
+    VirtioGpuCmdHandler handler(virtioAdapter, displayManager, memoryAdapter, TST_VIOGPU_MAX_SCANOUTS, false);
+    virtioGpu::ctrlHdr recvHdr;
+
+    virtqBuf.cbPhysReturn = sizeof(recvHdr);
+    virtqBuf.uVirtq = virtioGpu::virtqIdx::CONTROLQ;
+    virtioAdapter.recvBuf_ = reinterpret_cast<uint8_t *>(&recvHdr);
+
+    handler.handleBuffer(&virtqBuf);
+    REQUIRE(recvHdr.uType == virtioGpu::ctrlType::resp::ERR_OUT_OF_MEMORY);
+}
+
+TEST_CASE("handler returns unspec error if the ctrl-type is unknown")
+{
+    tstDisplayManager displayManager;
+    VirtioGpuCmdHandler handler(virtioAdapter, displayManager, memoryAdapter, TST_VIOGPU_MAX_SCANOUTS, false);
+    virtioGpu::ctrlHdr recvHdr;
+
+    // GET_DISPLAY_INFO is the command with the lowest value, thus GET_DISPLAY_INFO is an invalid command.
+    virtioGpu::ctrlHdr sendHdr {virtioGpu::ctrlType::cmd::GET_DISPLAY_INFO - 1};
+
+    virtioAdapter.prepareCommand(&sendHdr, &recvHdr, virtioGpu::virtqIdx::CONTROLQ, &virtqBuf);
+    handler.handleBuffer(&virtqBuf);
+    REQUIRE(recvHdr.uType == virtioGpu::ctrlType::resp::ERR_UNSPEC);
+}
+
+TEST_CASE("handler returns unspec error if a command is in the wrong queue")
+{
+    tstDisplayManager displayManager;
+    VirtioGpuCmdHandler handler(virtioAdapter, displayManager, memoryAdapter, TST_VIOGPU_MAX_SCANOUTS, false);
+
+    for (uint32_t cmd {virtioGpu::ctrlType::cmd::GET_DISPLAY_INFO}; cmd < virtioGpu::ctrlType::cmd::RESOURCE_DETACH_BACKING; cmd++) {
+        virtioGpu::ctrlHdr sendHdr {cmd};
+        virtioGpu::ctrlHdr recvHdr;
+        virtioAdapter.prepareCommand(&sendHdr, &recvHdr, virtioGpu::virtqIdx::CURSORQ, &virtqBuf);
+        handler.handleBuffer(&virtqBuf);
+        REQUIRE(recvHdr.uType == virtioGpu::ctrlType::resp::ERR_UNSPEC);
+    }
+
+    {
+        virtioGpu::ctrlHdr sendHdr {virtioGpu::ctrlType::cmd::GET_EDID};
+        virtioGpu::ctrlHdr recvHdr;
+        virtioAdapter.prepareCommand(&sendHdr, &recvHdr, virtioGpu::virtqIdx::CURSORQ, &virtqBuf);
+        handler.handleBuffer(&virtqBuf);
+        REQUIRE(recvHdr.uType == virtioGpu::ctrlType::resp::ERR_UNSPEC);
+    }
+
+    for (uint32_t cmd {virtioGpu::ctrlType::cmd::UPDATE_CURSOR}; cmd < virtioGpu::ctrlType::cmd::MOVE_CURSOR; cmd++) {
+        virtioGpu::ctrlHdr sendHdr {cmd};
+        virtioGpu::ctrlHdr recvHdr;
+        virtioAdapter.prepareCommand(&sendHdr, &recvHdr, virtioGpu::virtqIdx::CONTROLQ, &virtqBuf);
+        handler.handleBuffer(&virtqBuf);
+        REQUIRE(recvHdr.uType == virtioGpu::ctrlType::resp::ERR_UNSPEC);
+    }
+}
+
+SCENARIO("The command handler respects the attachDisplayLater flag")
+{
+    GIVEN("A display adapter and a GET_DISPLAY_INFO command") {
+        tstDisplayManager displayManager;
+        virtioGpu::ctrlHdr sendHdr {virtioGpu::ctrlType::cmd::GET_DISPLAY_INFO};
+        virtioGpu::respDisplayInfo displayInfo;
+        virtioAdapter.prepareCommand(&sendHdr, sizeof(sendHdr), &displayInfo, virtioGpu::respDisplayInfo::size(TST_VIOGPU_MAX_SCANOUTS), virtioGpu::virtqIdx::CONTROLQ, &virtqBuf);
+
+        WHEN("The command handler is created with attachDisplayLater set to false and GET_DISPLAY_INFO is called") {
+            VirtioGpuCmdHandler handler(virtioAdapter, displayManager, memoryAdapter, TST_VIOGPU_MAX_SCANOUTS, false);
+            handler.handleBuffer(&virtqBuf);
+
+            THEN("Display 0 is enabled, has the initial resolution and is attached") {
+                REQUIRE(displayInfo.hdr.uType == virtioGpu::ctrlType::resp::OK_DISPLAY_INFO);
+                REQUIRE(displayInfo.pmodes[0].enabled != 0);
+                REQUIRE(displayInfo.pmodes[0].r.width == virtioGpu::INITIAL_WIDTH);
+                REQUIRE(displayInfo.pmodes[0].r.height == virtioGpu::INITIAL_HEIGHT);
+                REQUIRE(displayManager.display(0)->fAttached == true);
+            }
+        }
+
+        WHEN("The command handler is created with attachDisplayLater set to true and GET_DISPLAY_INFO is called") {
+            VirtioGpuCmdHandler handler(virtioAdapter, displayManager, memoryAdapter, TST_VIOGPU_MAX_SCANOUTS, true);
+            handler.handleBuffer(&virtqBuf);
+
+            THEN("Display 0 is enabled and has the initial resolution, but the display is not attached") {
+                // We do this because if a driver attaches later to the virtio-gpu but immerdiately asks for the display info,
+                // the driver should still see all available scanouts.
+                REQUIRE(displayInfo.hdr.uType == virtioGpu::ctrlType::resp::OK_DISPLAY_INFO);
+                REQUIRE(displayInfo.pmodes[0].enabled != 0);
+                REQUIRE(displayInfo.pmodes[0].r.width == virtioGpu::INITIAL_WIDTH);
+                REQUIRE(displayInfo.pmodes[0].r.height == virtioGpu::INITIAL_HEIGHT);
+                REQUIRE(displayManager.display(0)->fAttached == false);
+            }
+        }
+    }
+}
+
+SCENARIO("Creation and deletion of resources is handled correctly") {
+    GIVEN("A fresh command handler") {
+        tstDisplayManager displayManager;
+        VirtioGpuCmdHandler handler(virtioAdapter, displayManager, memoryAdapter, TST_VIOGPU_MAX_SCANOUTS, false);
+
+        WHEN("A resource with ID 0 should be allocated") {
+            virtioGpu::ctrlHdr recvHdr;
+            virtioGpu::resourceCreate2d createResource {0u};
+
+            virtioAdapter.prepareCommand(&createResource, &recvHdr, virtioGpu::virtqIdx::CONTROLQ, &virtqBuf);
+            handler.handleBuffer(&virtqBuf);
+
+            THEN("ERR_INVALID_RESOURCE_ID is returned.") {
+                // The driver disables a scanout be using the resource ID 0 in SET_SCANOUT.
+                // Thus the cmd handler should not allocate resources with ID 0.
+                REQUIRE(recvHdr.uType == virtioGpu::ctrlType::resp::ERR_INVALID_RESOURCE_ID);
+            }
+        }
+
+        WHEN("A resource with a valid ID is allocated") {
+            virtioGpu::ctrlHdr recvHdr;
+            virtioGpu::resourceCreate2d createResource {RESOURCE_ID_ONE, RESOURCE_WIDTH, RESOURCE_HEIGHT};
+
+            virtioAdapter.prepareCommand(&createResource, &recvHdr, virtioGpu::virtqIdx::CONTROLQ, &virtqBuf);
+            handler.handleBuffer(&virtqBuf);
+
+            THEN("OK_NODATA is returned.") {
+                REQUIRE(recvHdr.uType == virtioGpu::ctrlType::resp::OK_NODATA);
+            }
+
+            AND_WHEN("A resource with the same ID is allocated") {
+                recvHdr.uType = 0;
+
+                virtioAdapter.prepareCommand(&createResource, &recvHdr, virtioGpu::virtqIdx::CONTROLQ, &virtqBuf);
+                handler.handleBuffer(&virtqBuf);
+
+                THEN("ERR_INVALID_RESOURCE_ID is returned.") {
+                    REQUIRE(recvHdr.uType == virtioGpu::ctrlType::resp::ERR_INVALID_RESOURCE_ID);
+                }
+            }
+
+            AND_WHEN("The resource is deleted") {
+                recvHdr.uType = 0;
+                virtioGpu::resourceUnref unrefResource {RESOURCE_ID_ONE};
+
+                virtioAdapter.prepareCommand(&unrefResource, &recvHdr, virtioGpu::virtqIdx::CONTROLQ, &virtqBuf);
+                handler.handleBuffer(&virtqBuf);
+
+                THEN("OK_NODATA is returned.") {
+                    REQUIRE(recvHdr.uType == virtioGpu::ctrlType::resp::OK_NODATA);
+                }
+
+                AND_WHEN("The resource is deleted again") {
+                    recvHdr.uType = 0;
+
+                    virtioAdapter.prepareCommand(&unrefResource, &recvHdr, virtioGpu::virtqIdx::CONTROLQ, &virtqBuf);
+                    handler.handleBuffer(&virtqBuf);
+
+                    THEN("ERR_INVALID_RESOURCE_ID is returned") {
+                        REQUIRE(recvHdr.uType == virtioGpu::ctrlType::resp::ERR_INVALID_RESOURCE_ID);
+                    }
+                }
+            }
+        }
+    }
+}
+
+SCENARIO("Complex tests") {
+    GIVEN("A command handler with two resources with IDs 1 and 2 and attached backings to both resources") {
+        tstDisplayManager displayManager;
+        VirtioGpuCmdHandler handler(virtioAdapter, displayManager, memoryAdapter, TST_VIOGPU_MAX_SCANOUTS, false);
+
+        // 'Simple', because I just put in the two pointers
+        auto runSimpleCommand = [&handler](auto* pSend, auto* pRecv) -> void {
+            pRecv->hdr.uType = 0;
+            virtioAdapter.prepareCommand(pSend, pRecv, virtioGpu::virtqIdx::CONTROLQ, &virtqBuf);
+            handler.handleBuffer(&virtqBuf);
+        };
+
+        auto runSimpleCommandAndCheck = [&handler, &runSimpleCommand](auto* pSend, auto* pRecv,
+                    virtioGpu::ctrlType::resp response = virtioGpu::ctrlType::resp::OK_NODATA) -> void {
+            runSimpleCommand(pSend, pRecv);
+            REQUIRE(pRecv->hdr.uType == response);
+        };
+
+        // 'Complex', because I have to provide the size
+        auto runComplexCommand = [&handler](void* pSend, size_t cbSend, auto* pRecv) -> void {
+            pRecv->hdr.uType = 0;
+            virtioAdapter.prepareCommand(pSend, cbSend, pRecv, sizeof(*pRecv), virtioGpu::virtqIdx::CONTROLQ, &virtqBuf);
+            handler.handleBuffer(&virtqBuf);
+        };
+
+        auto runComplexCommandAndCheck = [&handler, &runComplexCommand](void* pSend, size_t cbSend, auto* pRecv,
+                    virtioGpu::ctrlType::resp response = virtioGpu::ctrlType::resp::OK_NODATA) -> void {
+            runComplexCommand(pSend, cbSend, pRecv);
+            REQUIRE(pRecv->hdr.uType == response);
+        };
+
+        struct { virtioGpu::ctrlHdr hdr; } recvHdr;
+        virtioGpu::respDisplayInfo recvDisplayInfo;
+
+        virtioGpu::ctrlHdr getDisplayInfo {virtioGpu::ctrlType::cmd::GET_DISPLAY_INFO};
+
+        virtioGpu::resourceCreate2d createResourceOne {RESOURCE_ID_ONE, RESOURCE_WIDTH, RESOURCE_HEIGHT};
+        virtioGpu::setScanout setScanoutOne {SCANOUT_ID_ONE, RESOURCE_ID_ONE, RESOURCE_WIDTH, RESOURCE_HEIGHT};
+        virtioGpu::setScanout disableScanoutOne {SCANOUT_ID_ONE, 0u};
+        virtioGpu::transferToHost2d transfer2HostOne {RESOURCE_ID_ONE, RESOURCE_WIDTH, RESOURCE_HEIGHT};
+        virtioGpu::resourceDetachBacking detachBackingOne {RESOURCE_ID_ONE};
+
+        virtioGpu::resourceCreate2d createResourceTwo {RESOURCE_ID_TWO, RESOURCE_WIDTH, RESOURCE_HEIGHT};
+        virtioGpu::setScanout setScanoutTwo {SCANOUT_ID_TWO, RESOURCE_ID_TWO, RESOURCE_WIDTH, RESOURCE_HEIGHT};
+        virtioGpu::transferToHost2d transfer2HostTwo {RESOURCE_ID_TWO, RESOURCE_WIDTH, RESOURCE_HEIGHT};
+
+        std::vector<void*> backingPagesOne;
+        std::vector<uint8_t> attachBackingMemOne;
+        virtioGpu::resourceAttachBacking* pAttachBackingOne;
+        virtioGpu::resourceMemEntry* pMemEntriesOne;
+
+        std::vector<void*> backingPagesTwo;
+        std::vector<uint8_t> attachBackingMemTwo;
+        virtioGpu::resourceAttachBacking* pAttachBackingTwo;
+        virtioGpu::resourceMemEntry* pMemEntriesTwo;
+
+        const uint8_t FRAME_BYTE_ONE {0x55};
+        const uint8_t FRAME_BYTE_TWO {0xaa};
+        auto initializeBacking = [](std::vector<uint8_t>& attachBackingMem,
+                                    std::vector<void*>& backingPages,
+                                    virtioGpu::resourceAttachBacking*& pAttachBacking,
+                                    virtioGpu::resourceMemEntry*& pMemEntries,
+                                    uint32_t uResourceId, uint8_t frame_byte) {
+            attachBackingMem.resize(ATTACH_BACKING_STRUCT_SIZE);
+            pAttachBacking = reinterpret_cast<virtioGpu::resourceAttachBacking*>(attachBackingMem.data());
+            pMemEntries = reinterpret_cast<virtioGpu::resourceMemEntry*>(attachBackingMem.data()+sizeof(virtioGpu::resourceAttachBacking));
+            pAttachBacking->hdr.uType = virtioGpu::ctrlType::cmd::RESOURCE_ATTACH_BACKING;
+            pAttachBacking->uResourceId = uResourceId;
+            pAttachBacking->uNrEntries = NUM_BACKINGS;
+
+            for (auto idx {0u}; idx < NUM_BACKINGS; idx++) {
+                void* backingPtr {RTMemAlloc(BACKING_SIZE)};
+                backingPages.emplace_back(backingPtr);
+
+                pMemEntries[idx].uAddr = reinterpret_cast<uint64_t>(backingPtr);
+                pMemEntries[idx].uLength = BACKING_SIZE;
+
+                std::memset(backingPages.at(idx), frame_byte, BACKING_SIZE);
+            }
+        };
+
+        initializeBacking(attachBackingMemOne, backingPagesOne, pAttachBackingOne, pMemEntriesOne, RESOURCE_ID_ONE, FRAME_BYTE_ONE);
+        initializeBacking(attachBackingMemTwo, backingPagesTwo, pAttachBackingTwo, pMemEntriesTwo, RESOURCE_ID_TWO, FRAME_BYTE_TWO);
+
+        auto frameBufPage = [&displayManager](int32_t displayIdx, size_t idx) -> void* {
+            if (displayManager.display(displayIdx)->pFrameBuffer() == nullptr) {
+                return nullptr;
+            }
+            return reinterpret_cast<uint8_t*>(displayManager.display(displayIdx)->pFrameBuffer())+idx*BACKING_SIZE;
+        };
+
+        // Returns true if the framebuffer and the backing have the same values in them
+        auto compareFramebufBacking = [&frameBufPage](std::vector<void*> backingPages, uint32_t displayIdx) -> bool {
+            if (frameBufPage(displayIdx, 0) == nullptr) {
+                return false;
+            }
+
+            std::vector<int> results;
+            for (auto idx {0u}; idx < NUM_BACKINGS; idx++) {
+                results.emplace_back(std::memcmp(backingPages.at(idx), frameBufPage(displayIdx, idx), BACKING_SIZE));
+            }
+            return std::all_of(std::begin(results), std::end(results), [](int res) { return res == 0; });
+        };
+
+        runSimpleCommandAndCheck(&createResourceOne, &recvHdr);
+        runComplexCommandAndCheck(pAttachBackingOne, ATTACH_BACKING_STRUCT_SIZE, &recvHdr);
+
+        runSimpleCommandAndCheck(&createResourceTwo, &recvHdr);
+        runComplexCommandAndCheck(pAttachBackingTwo, ATTACH_BACKING_STRUCT_SIZE, &recvHdr);
+
+        /*
+         * TESTING - SINGLE MONITOR
+         */
+
+        WHEN("TRANSFER_2_HOST is called") {
+            runSimpleCommand(&transfer2HostOne, &recvHdr);
+
+            THEN("The scanout is enabled and has its initial width and height") {
+                REQUIRE(displayManager.display(0)->fAttached == true);
+                REQUIRE(displayManager.display(0)->uCurrentWidth == virtioGpu::INITIAL_WIDTH);
+                REQUIRE(displayManager.display(0)->uCurrentHeight == virtioGpu::INITIAL_HEIGHT);
+            }
+
+            AND_THEN("The transferring fails because no scanout is assigned to the resource") {
+                REQUIRE(recvHdr.hdr.uType == virtioGpu::ctrlType::resp::ERR_INVALID_RESOURCE_ID);
+                REQUIRE(not compareFramebufBacking(backingPagesOne, SCANOUT_ID_ONE));
+            }
+        }
+
+        WHEN("SET_SCANOUT is called with the resource Id of an existing resource") {
+            runSimpleCommandAndCheck(&setScanoutOne, &recvHdr);
+
+            THEN("The scanout is enabled and has the given dimension") {
+                REQUIRE(displayManager.display(0)->fAttached == true);
+                REQUIRE(displayManager.display(0)->uCurrentWidth == RESOURCE_WIDTH);
+                REQUIRE(displayManager.display(0)->uCurrentHeight == RESOURCE_HEIGHT);
+            }
+
+            AND_WHEN("SET_SCANOUT is called with a resource Id of 0") {
+                runSimpleCommand(&disableScanoutOne, &recvHdr);
+
+                THEN("The scanout is disabled") {
+                    REQUIRE(displayManager.display(0)->fAttached == false);
+                }
+            }
+
+            AND_WHEN("TRANSFER_2_HOST ist called") {
+                runSimpleCommandAndCheck(&transfer2HostOne, &recvHdr);
+
+                THEN("The transferring is successful") {
+                    REQUIRE(compareFramebufBacking(backingPagesOne, SCANOUT_ID_ONE));
+                }
+            }
+
+            AND_WHEN("DETACH_BACKING and TRANSFER_2_HOST are called") {
+                // we again want to compare the framebuffer and the backing, thus we have to clear the framebuffer
+                std::memset(displayManager.display(0)->pFrameBuffer(), 0, displayManager.display(0)->cbFrameBuffer());
+
+                runSimpleCommandAndCheck(&detachBackingOne, &recvHdr);
+                runSimpleCommandAndCheck(&transfer2HostOne, &recvHdr);
+
+                THEN("No data is transferred") {
+                    REQUIRE(not compareFramebufBacking(backingPagesOne, SCANOUT_ID_ONE));
+                }
+            }
+
+            AND_THEN("GET_DISPLAY_INFO also reports the given resolution") {
+                virtioAdapter.prepareCommand(&getDisplayInfo, sizeof(getDisplayInfo), &recvDisplayInfo, virtioGpu::respDisplayInfo::size(TST_VIOGPU_MAX_SCANOUTS), virtioGpu::virtqIdx::CONTROLQ, &virtqBuf);
+                handler.handleBuffer(&virtqBuf);
+                REQUIRE(recvDisplayInfo.hdr.uType == virtioGpu::ctrlType::resp::OK_DISPLAY_INFO);
+
+                REQUIRE(recvDisplayInfo.pmodes[0].enabled != 0);
+                REQUIRE(recvDisplayInfo.pmodes[0].r.width == RESOURCE_WIDTH);
+                REQUIRE(recvDisplayInfo.pmodes[0].r.height == RESOURCE_HEIGHT);
+            }
+
+            AND_WHEN("requestResize is called because the screen has changed") {
+                handler.requestResize(0, RESIZED_WIDTH, RESIZED_HEIGHT);
+
+                THEN("the display reports still the same size") {
+                    REQUIRE(displayManager.display(0)->uCurrentWidth == RESOURCE_WIDTH);
+                    REQUIRE(displayManager.display(0)->uCurrentHeight == RESOURCE_HEIGHT);
+                }
+
+                AND_WHEN("GET_DISPLAY_INFO is used to receive the new resolution") {
+                    runSimpleCommandAndCheck(&getDisplayInfo, &recvDisplayInfo, virtioGpu::ctrlType::resp::OK_DISPLAY_INFO);
+
+                    THEN("the driver receives the new resolution and the display reports the new size") {
+                        REQUIRE(recvDisplayInfo.pmodes[0].enabled != 0);
+                        REQUIRE(recvDisplayInfo.pmodes[0].r.width == RESIZED_WIDTH);
+                        REQUIRE(recvDisplayInfo.pmodes[0].r.height == RESIZED_HEIGHT);
+                        REQUIRE(displayManager.display(0)->uCurrentWidth == RESIZED_WIDTH);
+                        REQUIRE(displayManager.display(0)->uCurrentHeight == RESIZED_HEIGHT);
+                    }
+                }
+            }
+        }
+
+        /*
+         * TESTING - MULTI MONITOR
+         */
+
+        // Mirroring
+        WHEN("A single framebuffer is linked to two monitors and TRANSFER_TO_HOST is called") {
+            virtioGpu::setScanout setScanoutTwo2One {SCANOUT_ID_TWO, RESOURCE_ID_ONE, RESOURCE_WIDTH, RESOURCE_HEIGHT};
+            runSimpleCommandAndCheck(&setScanoutOne, &recvDisplayInfo);
+            runSimpleCommandAndCheck(&setScanoutTwo2One, &recvDisplayInfo);
+
+            runSimpleCommandAndCheck(&transfer2HostOne, &recvHdr);
+
+            THEN("Both scanouts have the same data in their framebuffers") {
+                REQUIRE(compareFramebufBacking(backingPagesOne, SCANOUT_ID_ONE));
+                REQUIRE(compareFramebufBacking(backingPagesOne, SCANOUT_ID_TWO));
+            }
+        }
+
+        // Join Displays 1
+        WHEN("Different framebuffers are linked to two monitors and TRANSFER_TO_HOST is called") {
+            runSimpleCommandAndCheck(&setScanoutOne, &recvDisplayInfo);
+            runSimpleCommandAndCheck(&setScanoutTwo, &recvDisplayInfo);
+
+            runSimpleCommandAndCheck(&transfer2HostOne, &recvHdr);
+            runSimpleCommandAndCheck(&transfer2HostTwo, &recvHdr);
+
+            THEN("Both scanouts have the expected data in their framebuffers") {
+                REQUIRE(compareFramebufBacking(backingPagesOne, SCANOUT_ID_ONE));
+                REQUIRE(compareFramebufBacking(backingPagesTwo, SCANOUT_ID_TWO));
+            }
+        }
+    }
+}
diff --git a/src/VBox/Frontends/VBoxManage/VBoxManageInfo.cpp b/src/VBox/Frontends/VBoxManage/VBoxManageInfo.cpp
index 05bed8b..b0796c3 100644
--- a/src/VBox/Frontends/VBoxManage/VBoxManageInfo.cpp
+++ b/src/VBox/Frontends/VBoxManage/VBoxManageInfo.cpp
@@ -1457,6 +1457,18 @@ HRESULT showVMInfo(ComPtr<IVirtualBox> pVirtualBox,
                 else
                     pszCtrl = "VBoxSVGA";
                 break;
+            case GraphicsControllerType_VGAWithVirtioGpu:
+                if (details == VMINFO_MACHINEREADABLE)
+                    pszCtrl = "vga-virtiogpu";
+                else
+                    pszCtrl = "VGAWithVirtioGPU";
+                break;
+            case GraphicsControllerType_VirtioGpu:
+                if (details == VMINFO_MACHINEREADABLE)
+                    pszCtrl = "virtiogpu";
+                else
+                    pszCtrl = "VirtioGPU";
+                break;
             default:
                 if (details == VMINFO_MACHINEREADABLE)
                     pszCtrl = "unknown";
@@ -2685,6 +2697,30 @@ HRESULT showVMInfo(ComPtr<IVirtualBox> pVirtualBox,
     /* Host PCI passthrough devices */
 #endif
 
+    SafeArray<BSTR> vfioDevices;
+    hrc = machine->COMGETTER(VFIODeviceAssignments)(ComSafeArrayAsOutParam(vfioDevices));
+    if (SUCCEEDED(hrc))
+    {
+        if (vfioDevices.size() > 0 && (details != VMINFO_MACHINEREADABLE))
+        {
+            RTPrintf("\n Attached VFIO Devices: \n\n");
+        }
+
+        for (size_t i {0}; i < vfioDevices.size(); ++i)
+        {
+            Utf8Str devicePath {vfioDevices[i]};
+
+            if (details == VMINFO_MACHINEREADABLE)
+            {
+                RTPrintf("AttachedVFIO%d=%s\n", i, devicePath.c_str());
+            }
+            else
+            {
+                RTPrintf("   VFIO Device %s is attached\n", devicePath.c_str());
+            }
+        }
+    }
+
     /*
      * Bandwidth groups
      */
diff --git a/src/VBox/Frontends/VBoxManage/VBoxManageModifyVM.cpp b/src/VBox/Frontends/VBoxManage/VBoxManageModifyVM.cpp
index 4a36072..ce922b0 100644
--- a/src/VBox/Frontends/VBoxManage/VBoxManageModifyVM.cpp
+++ b/src/VBox/Frontends/VBoxManage/VBoxManageModifyVM.cpp
@@ -234,6 +234,8 @@ enum
     MODIFYVM_ATTACH_PCI,
     MODIFYVM_DETACH_PCI,
 #endif
+    MODIFYVM_ATTACH_VFIO,
+    MODIFYVM_DETACH_VFIO,
 #ifdef VBOX_WITH_USB_CARDREADER
     MODIFYVM_USBCARDREADER,
 #endif
@@ -470,6 +472,8 @@ static const RTGETOPTDEF g_aModifyVMOptions[] =
     OPT2("--pci-attach",                    "--pciattach",              MODIFYVM_ATTACH_PCI,                RTGETOPT_REQ_STRING),
     OPT2("--pci-detach",                    "--pcidetach",              MODIFYVM_DETACH_PCI,                RTGETOPT_REQ_STRING),
 #endif
+    { "--attachvfio",               MODIFYVM_ATTACH_VFIO,               RTGETOPT_REQ_STRING },
+    { "--detachvfio",               MODIFYVM_DETACH_VFIO,               RTGETOPT_REQ_STRING },
 #ifdef VBOX_WITH_USB_CARDREADER
     OPT2("--usb-card-reader",               "--usbcardreader",          MODIFYVM_USBCARDREADER,             RTGETOPT_REQ_BOOL_ONOFF),
 #endif
@@ -1001,6 +1005,12 @@ RTEXITCODE handleModifyVM(HandlerArg *a)
                          || !RTStrICmp(ValueUnion.psz, "svga"))
                     CHECK_ERROR(pGraphicsAdapter, COMSETTER(GraphicsControllerType)(GraphicsControllerType_VBoxSVGA));
 #endif
+                else if (   !RTStrICmp(ValueUnion.psz, "vga-virtiogpu")) {
+                    CHECK_ERROR(pGraphicsAdapter, COMSETTER(GraphicsControllerType)(GraphicsControllerType_VGAWithVirtioGpu));
+                }
+                else if (   !RTStrICmp(ValueUnion.psz, "virtiogpu")) {
+                    CHECK_ERROR(pGraphicsAdapter, COMSETTER(GraphicsControllerType)(GraphicsControllerType_VirtioGpu));
+                }
                 else
                 {
                     errorArgument(ModifyVM::tr("Invalid --graphicscontroller argument '%s'"), ValueUnion.psz);
@@ -3500,6 +3510,17 @@ RTEXITCODE handleModifyVM(HandlerArg *a)
                 break;
             }
 #endif
+            case MODIFYVM_ATTACH_VFIO:
+            {
+                CHECK_ERROR(sessionMachine, AttachVFIODevice(Bstr(ValueUnion.psz).raw()));
+                break;
+            }
+
+            case MODIFYVM_DETACH_VFIO:
+            {
+                CHECK_ERROR(sessionMachine, DetachVFIODevice(Bstr(ValueUnion.psz).raw()));
+                break;
+            }
 
 #ifdef VBOX_WITH_USB_CARDREADER
             case MODIFYVM_USBCARDREADER:
diff --git a/src/VBox/Frontends/VirtualBox/src/converter/UIConverterBackendCOM.cpp b/src/VBox/Frontends/VirtualBox/src/converter/UIConverterBackendCOM.cpp
index 3799bca..f5da2c8 100644
--- a/src/VBox/Frontends/VirtualBox/src/converter/UIConverterBackendCOM.cpp
+++ b/src/VBox/Frontends/VirtualBox/src/converter/UIConverterBackendCOM.cpp
@@ -316,6 +316,8 @@ template<> QString toString(const KGraphicsControllerType &type)
         case KGraphicsControllerType_VBoxVGA:  return QApplication::translate("UICommon", "VBoxVGA",  "GraphicsControllerType");
         case KGraphicsControllerType_VMSVGA:   return QApplication::translate("UICommon", "VMSVGA",   "GraphicsControllerType");
         case KGraphicsControllerType_VBoxSVGA: return QApplication::translate("UICommon", "VBoxSVGA", "GraphicsControllerType");
+        case KGraphicsControllerType_VGAWithVirtioGpu: return QApplication::translate("UICommon", "VGAWithVirtioGPU", "GraphicsControllerType");
+        case KGraphicsControllerType_VirtioGpu: return QApplication::translate("UICommon", "VirtioGPU", "GraphicsControllerType");
         default: AssertMsgFailed(("No text for %d", type)); break;
     }
     return QString();
@@ -329,6 +331,8 @@ template<> KGraphicsControllerType fromString<KGraphicsControllerType>(const QSt
     list.insert(QApplication::translate("UICommon", "VBoxVGA",  "GraphicsControllerType"), KGraphicsControllerType_VBoxVGA);
     list.insert(QApplication::translate("UICommon", "VMSVGA",   "GraphicsControllerType"), KGraphicsControllerType_VMSVGA);
     list.insert(QApplication::translate("UICommon", "VBoxSVGA", "GraphicsControllerType"), KGraphicsControllerType_VBoxSVGA);
+    list.insert(QApplication::translate("UICommon", "VGAWithVirtioGPU", "GraphicsControllerType"), KGraphicsControllerType_VGAWithVirtioGpu);
+    list.insert(QApplication::translate("UICommon", "VirtioGPU", "GraphicsControllerType"), KGraphicsControllerType_VirtioGpu);
     if (!list.contains(strType))
     {
         AssertMsgFailed(("No value for '%s'", strType.toUtf8().constData()));
diff --git a/src/VBox/HostDrivers/Support/Makefile.kmk b/src/VBox/HostDrivers/Support/Makefile.kmk
index 46c2784..9f9ad3c 100644
--- a/src/VBox/HostDrivers/Support/Makefile.kmk
+++ b/src/VBox/HostDrivers/Support/Makefile.kmk
@@ -191,6 +191,7 @@ SUPR3_DEFS          = \
 	$(if $(VBOX_WITH_MAIN),VBOX_WITH_MAIN,) \
 	$(if $(VBOX_WITH_RAW_MODE),VBOX_WITH_RAW_MODE,) \
 	$(if $(VBOX_WITH_DRIVERLESS_NEM_FALLBACK),VBOX_WITH_DRIVERLESS_NEM_FALLBACK,) \
+        $(if $(VBOX_WITH_PREALLOC_RAM_BY_DEFAULT),VBOX_WITH_PREALLOC_RAM_BY_DEFAULT,) \
 	VBOX_PERMIT_MORE \
 	VBOX_PERMIT_EVEN_MORE
 SUPR3_INCS         := $(PATH_SUB_CURRENT)
diff --git a/src/VBox/HostDrivers/Support/linux/SUPLib-linux.cpp b/src/VBox/HostDrivers/Support/linux/SUPLib-linux.cpp
index 5bdcda6..61ffb90 100644
--- a/src/VBox/HostDrivers/Support/linux/SUPLib-linux.cpp
+++ b/src/VBox/HostDrivers/Support/linux/SUPLib-linux.cpp
@@ -255,6 +255,10 @@ DECLHIDDEN(int) suplibOsPageAlloc(PSUPLIBDATA pThis, size_t cPages, uint32_t fFl
         fMmap |= MAP_HUGETLB;
 #endif
 
+#ifdef VBOX_WITH_PREALLOC_RAM_BY_DEFAULT
+    fMmap |= MAP_POPULATE;
+#endif
+
     size_t cbMmap = cPages << PAGE_SHIFT;
     if (   !pThis->fSysMadviseWorks
         && (fFlags & (SUP_PAGE_ALLOC_F_FOR_LOCKING | SUP_PAGE_ALLOC_F_LARGE_PAGES)) == SUP_PAGE_ALLOC_F_FOR_LOCKING)
diff --git a/src/VBox/Main/Makefile.kmk b/src/VBox/Main/Makefile.kmk
index 5711816..6f5d1a7 100644
--- a/src/VBox/Main/Makefile.kmk
+++ b/src/VBox/Main/Makefile.kmk
@@ -1088,7 +1088,9 @@ if !defined(VBOX_ONLY_SDK) && !defined(VBOX_ONLY_EXTPACKS) # Note this goes on f
 
 
  VBoxC_LIBS += \
- 	$(PATH_STAGE_LIB)/VBoxAPIWrap$(VBOX_SUFF_LIB)
+	$(PATH_STAGE_LIB)/VBoxAPIWrap$(VBOX_SUFF_LIB) \
+	$(PATH_STAGE_LIB)/VMMR3Imp.so
+
  VBoxC_LIBS.win += \
  	$(PATH_SDK_$(VBOX_WINPSDK)_LIB)/psapi.lib \
  	$(PATH_TOOL_$(VBOX_VCC_TOOL)_LIB)/delayimp.lib
diff --git a/src/VBox/Main/idl/VirtualBox.xidl b/src/VBox/Main/idl/VirtualBox.xidl
index 8654afe..ad6b2dd 100644
--- a/src/VBox/Main/idl/VirtualBox.xidl
+++ b/src/VBox/Main/idl/VirtualBox.xidl
@@ -6536,6 +6536,12 @@
     <const name="VBoxSVGA"  value="3">
       <desc>VirtualBox VGA device with VMware SVGA II extensions.</desc>
     </const>
+    <const name="VGAWithVirtioGpu" value="7">
+      <desc>Virtualbox VGA device for the boot screen switching to Intel HD Graphics.</desc>
+    </const>
+    <const name="VirtioGpu" value="8">
+      <desc>Intel HD Graphics with hardware acceleration.</desc>
+    </const>
   </enum>
 
   <enum
@@ -7336,6 +7342,12 @@
       </desc>
     </attribute>
 
+    <attribute name="VFIODeviceAssignments" type="wstring" readonly="yes" safearray="yes">
+      <desc>
+        Array of VFIO Device paths, assigned to this machine.
+      </desc>
+    </attribute>
+
     <attribute name="bandwidthControl" type="IBandwidthControl" readonly="yes">
       <desc>
         Bandwidth control manager.
@@ -8478,6 +8490,24 @@
       </param>
     </method>
 
+    <method name="attachVFIODevice">
+      <desc>
+        Attach a host VFIO device from the virtual machine.
+      </desc>
+      <param name="hostFileName" type="wstring" dir="in">
+        <desc> Absolute path to the device file in sysfs.</desc>
+      </param>
+    </method>
+
+    <method name="detachVFIODevice">
+      <desc>
+        Detach a host VFIO device from the virtual machine.
+      </desc>
+      <param name="hostFileName" type="wstring" dir="in">
+        <desc> Absolute path to the device file in sysfs.</desc>
+      </param>
+    </method>
+
     <method name="getNetworkAdapter" const="yes">
       <rest request="get" path="/vms/{vmid}/configuration/"/>
       <desc>
diff --git a/src/VBox/Main/include/ConsoleImpl.h b/src/VBox/Main/include/ConsoleImpl.h
index fdea838..6c35170 100644
--- a/src/VBox/Main/include/ConsoleImpl.h
+++ b/src/VBox/Main/include/ConsoleImpl.h
@@ -729,7 +729,8 @@ private:
                                    const ComPtr<IMachine> &ptrMachine,
                                    const ComPtr<IGraphicsAdapter> &ptrGraphicsAdapter,
                                    const ComPtr<IBIOSSettings> &ptrBiosSettings,
-                                   bool fHMEnabled);
+                                   bool fHMEnabled,
+                                   bool fHideMultipleMonitors = false);
     int i_checkMediumLocation(IMedium *pMedium, bool *pfUseHostIOCache);
     int i_unmountMediumFromGuest(PUVM pUVM, PCVMMR3VTABLE pVMM, StorageBus_T enmBus, DeviceType_T enmDevType,
                                  const char *pcszDevice, unsigned uInstance, unsigned uLUN,
@@ -807,6 +808,11 @@ private:
                                                      bool fForce);
 
     HRESULT i_attachRawPCIDevices(PUVM pUVM, BusAssignmentManager *BusMgr, PCFGMNODE pDevices);
+    HRESULT i_attachVfioDevices(BusAssignmentManager *BusMgr, PCFGMNODE pDevices, PCVMMR3VTABLE pVMM);
+    HRESULT i_attachVirtioGpuDevice(BusAssignmentManager *BusMgr,
+                                    PCFGMNODE pDevices,
+                                    const ComPtr<IGraphicsAdapter> &ptrGraphicsAdapter,
+                                    bool secondaryController);
     struct LEDSET;
     typedef struct LEDSET *PLEDSET;
     PPDMLED volatile *i_getLedSet(uint32_t iLedSet);
diff --git a/src/VBox/Main/include/MachineImpl.h b/src/VBox/Main/include/MachineImpl.h
index 311a80b..5a90896 100644
--- a/src/VBox/Main/include/MachineImpl.h
+++ b/src/VBox/Main/include/MachineImpl.h
@@ -364,6 +364,8 @@ public:
         typedef std::list<ComObjPtr<PCIDeviceAttachment> > PCIDeviceAssignmentList;
         PCIDeviceAssignmentList mPCIDeviceAssignments;
 
+        std::vector<Utf8Str> mVFIODeviceAssignments;
+
         settings::Debugging mDebugging;
         settings::Autostart mAutostart;
 
@@ -1017,6 +1019,7 @@ private:
     HRESULT getIOCacheSize(ULONG *aIOCacheSize);
     HRESULT setIOCacheSize(ULONG aIOCacheSize);
     HRESULT getPCIDeviceAssignments(std::vector<ComPtr<IPCIDeviceAttachment> > &aPCIDeviceAssignments);
+    HRESULT getVFIODeviceAssignments(std::vector<com::Utf8Str> &aVFIODeviceAssignments);
     HRESULT getBandwidthControl(ComPtr<IBandwidthControl> &aBandwidthControl);
     HRESULT getTracingEnabled(BOOL *aTracingEnabled);
     HRESULT setTracingEnabled(BOOL aTracingEnabled);
@@ -1114,6 +1117,8 @@ private:
                                 LONG aDesiredGuestAddress,
                                 BOOL aTryToUnbind);
     HRESULT detachHostPCIDevice(LONG aHostAddress);
+    HRESULT attachVFIODevice(const com::Utf8Str &aDevicePath);
+    HRESULT detachVFIODevice(const com::Utf8Str &aDevicePath);
     HRESULT getNetworkAdapter(ULONG aSlot,
                               ComPtr<INetworkAdapter> &aAdapter);
     HRESULT addStorageController(const com::Utf8Str &aName,
diff --git a/src/VBox/Main/src-client/BusAssignmentManager.cpp b/src/VBox/Main/src-client/BusAssignmentManager.cpp
index a8d36d0..1085b52 100644
--- a/src/VBox/Main/src-client/BusAssignmentManager.cpp
+++ b/src/VBox/Main/src-client/BusAssignmentManager.cpp
@@ -109,17 +109,20 @@ static const DeviceAssignmentRule g_aGenericRules[] =
 #endif
 
     /* Network controllers */
-    /* the first network card gets the PCI ID 3, the next 3 gets 8..10,
-     * next 4 get 16..19. In "VMWare compatibility" mode the IDs 3 and 17
-     * swap places, i.e. the first card goes to ID 17=0x11. */
+    /* the first network card gets the PCI ID 3, the next 3 gets 8..10 */
+
     {"nic",           0,  3,  0, 1},
     {"nic",           0,  8,  0, 1},
     {"nic",           0,  9,  0, 1},
     {"nic",           0, 10,  0, 1},
-    {"nic",           0, 16,  0, 1},
-    {"nic",           0, 17,  0, 1},
-    {"nic",           0, 18,  0, 1},
-    {"nic",           0, 19,  0, 1},
+
+    /* Vfio Devices */
+    {"vfio",           0, 16,  0, 1},
+    {"vfio",           0, 17,  0, 1},
+    {"vfio",           0, 18,  0, 1},
+
+    /* Virtio-Gpu */
+    {"virtio-gpu",     0, 19,  0, 1},
 
     /* ISA/LPC controller */
     {"lpc",           0, 31,  0, 0},
diff --git a/src/VBox/Main/src-client/ConsoleImpl2.cpp b/src/VBox/Main/src-client/ConsoleImpl2.cpp
index 3576c49..b571253 100644
--- a/src/VBox/Main/src-client/ConsoleImpl2.cpp
+++ b/src/VBox/Main/src-client/ConsoleImpl2.cpp
@@ -674,6 +674,99 @@ HRESULT Console::i_attachRawPCIDevices(PUVM pUVM, BusAssignmentManager *pBusMgr,
 #endif
 
 
+HRESULT Console::i_attachVfioDevices(BusAssignmentManager *pBusMgr, PCFGMNODE pDevices, PCVMMR3VTABLE /*pVMM*/)
+{
+    HRESULT hrc {S_OK};
+    PCFGMNODE pInst{NULL};
+    PCFGMNODE pCfg{NULL};
+    PCFGMNODE pVfioDevs {NULL};
+
+    ComPtr<IMachine> aMachine {i_machine()};
+
+    SafeArray<BSTR> vfioDevices;
+    hrc = aMachine->COMGETTER(VFIODeviceAssignments)(ComSafeArrayAsOutParam(vfioDevices));
+
+    if (hrc != S_OK || vfioDevices.size() == 0)
+    {
+        return hrc;
+    }
+
+    if (vfioDevices.size() > 0)
+    {
+        InsertConfigNode(pDevices, "VfioDev", &pVfioDevs);
+
+        /*
+         * As an IOMMU is needed for VFIO devices we need to force RAM preallocation
+         */
+
+        //PCFGMNODE pRoot = pVMM->pfnCFGMR3GetParent(pDevices); Assert(pRoot);
+        //pVMM->pfnCFGMR3RemoveValue(pRoot, "RamPreAlloc");
+        //InsertConfigInteger(pRoot, "RamPreAlloc", 1);
+    }
+
+    for (size_t iDev{0}; iDev < vfioDevices.size(); ++iDev)
+    {
+        Utf8Str devicePath {vfioDevices[iDev]};
+
+        InsertConfigNode(pVfioDevs, Utf8StrFmt("%d", iDev).c_str(), &pInst);
+        InsertConfigInteger(pInst, "Trusted", 1);
+        InsertConfigNode(pInst, "Config", &pCfg);
+        InsertConfigString(pCfg, "sysfsPath", devicePath);
+
+        PCIBusAddress guestAddress;
+        bool fGuestAddressRequired{false};
+        /*
+         * The fGuestAddressRequired flag of the assignPCIDevice call can ask for a certain BDF in the guest.
+         * If a guestAddress is required for a certain device guestAddress has to be set to the certain BDF.
+         * The call will fail, if the address is already in use.
+         */
+        hrc = pBusMgr->assignPCIDevice("vfio", pInst, guestAddress, fGuestAddressRequired);
+        if (hrc != S_OK)
+        {
+            return hrc;
+        }
+
+        InsertConfigInteger(pCfg,      "GuestPCIBusNo",      guestAddress.miBus);
+        InsertConfigInteger(pCfg,      "GuestPCIDeviceNo",   guestAddress.miDevice);
+        InsertConfigInteger(pCfg,      "GuestPCIFunctionNo", guestAddress.miFn);
+    }
+
+    return hrc;
+}
+
+HRESULT Console::i_attachVirtioGpuDevice(BusAssignmentManager *pBusMgr,
+                                         PCFGMNODE pDevices,
+                                         const ComPtr<IGraphicsAdapter> &ptrGraphicsAdapter,
+                                         bool secondaryController)
+{
+    PCFGMNODE pInst {NULL};
+    PCFGMNODE pVirtioGpuDev {NULL};
+
+    InsertConfigNode(pDevices, "virtio-gpu", &pVirtioGpuDev);
+    InsertConfigNode(pVirtioGpuDev, "0", &pInst);
+    InsertConfigInteger(pInst, "Trusted", 1);
+
+    PCFGMNODE pCfg {NULL};
+    PCFGMNODE pLunL0 {NULL};
+
+    InsertConfigNode(pInst,    "Config", &pCfg);
+    InsertConfigInteger(pCfg, "secondaryController", secondaryController);
+
+    unsigned cMonitorCount {0};
+    auto hrc = ptrGraphicsAdapter->COMGETTER(MonitorCount)(&cMonitorCount); H();
+    InsertConfigInteger(pCfg, "MonitorCount", cMonitorCount);
+
+    unsigned cVRamMBs;
+    hrc = ptrGraphicsAdapter->COMGETTER(VRAMSize)(&cVRamMBs);               H();
+    InsertConfigInteger(pCfg,  "VRamSize", cVRamMBs * _1M);
+
+    InsertConfigNode(pInst, "LUN#0", &pLunL0);
+    InsertConfigString(pLunL0, "Driver", "MainDisplay");
+    InsertConfigNode(pLunL0, "Config", &pCfg);
+
+    return pBusMgr->assignPCIDevice("virtio-gpu", pInst);
+}
+
 /**
  * Updates the device type for a LED.
  *
@@ -1422,6 +1515,26 @@ int Console::i_configConstructorInner(PUVM pUVM, PVM pVM, PCVMMR3VTABLE pVMM, Au
         bool         fGimDebug          = false;
         com::Utf8Str strGimDebugAddress = "127.0.0.1";
         uint32_t     uGimDebugPort      = 50000;
+
+        PCFGMNODE pHvNode;
+        InsertConfigNode(pParavirtNode, "HyperV", &pHvNode);
+
+        {
+            ComPtr<IGraphicsAdapter> pGraphicsAdapter;
+            hrc = pMachine->COMGETTER(GraphicsAdapter)(pGraphicsAdapter.asOutParam());           H();
+            GraphicsControllerType_T enmGraphicsController;
+            hrc = pGraphicsAdapter->COMGETTER(GraphicsControllerType)(&enmGraphicsController);          H();
+
+            switch (enmGraphicsController) {
+            case GraphicsControllerType_VirtioGpu:
+            case GraphicsControllerType_VGAWithVirtioGpu:
+                InsertConfigInteger(pHvNode, "VirtioGPU", true);
+                break;
+            default:
+                break;
+            }
+        }
+
         if (strParavirtDebug.isNotEmpty())
         {
             /* Hyper-V debug options. */
@@ -1474,8 +1587,6 @@ int Console::i_configConstructorInner(PUVM pUVM, PVM pVM, PCVMMR3VTABLE pVMM, Au
                 /* Update HyperV CFGM node with active debug options. */
                 if (fGimHvDebug)
                 {
-                    PCFGMNODE pHvNode;
-                    InsertConfigNode(pParavirtNode, "HyperV", &pHvNode);
                     InsertConfigString(pHvNode,  "VendorID", strGimHvVendor);
                     InsertConfigInteger(pHvNode, "VSInterface", fGimHvVsIf ? 1 : 0);
                     InsertConfigInteger(pHvNode, "HypercallDebugInterface", fGimHvHypercallIf ? 1 : 0);
@@ -1734,6 +1845,8 @@ int Console::i_configConstructorInner(PUVM pUVM, PVM pVM, PCVMMR3VTABLE pVMM, Au
             }
         }
 
+        hrc = i_attachVfioDevices(pBusMgr, pDevices, pVMM);                                       H();
+
         /*
          * Enable the following devices: HPET, SMC and LPC on MacOS X guests or on ICH9 chipset
          */
@@ -1922,6 +2035,23 @@ int Console::i_configConstructorInner(PUVM pUVM, PVM pVM, PCVMMR3VTABLE pVMM, Au
                 if (FAILED(vrc))
                     return vrc;
                 break;
+            case GraphicsControllerType_VGAWithVirtioGpu:
+                hrc = i_attachVirtioGpuDevice(pBusMgr, pDevices, pGraphicsAdapter, true);
+                if (FAILED(hrc)) {
+                    return hrc;
+                }
+                // See case GraphicsControllerType_VGAWithIntelGVT
+                hrc = i_configGraphicsController(pDevices, GraphicsControllerType_VBoxSVGA, pBusMgr, pMachine, pGraphicsAdapter, biosSettings,
+                                                RT_BOOL(fHMEnabled), true);
+                if (FAILED(hrc))
+                    return hrc;
+                break;
+            case GraphicsControllerType_VirtioGpu:
+                hrc = i_attachVirtioGpuDevice(pBusMgr, pDevices, pGraphicsAdapter, false);
+                if (FAILED(hrc)) {
+                    return hrc;
+                }
+                break;
             default:
                 AssertMsgFailed(("Invalid graphicsController=%d\n", enmGraphicsController));
                 return pVMM->pfnVMR3SetError(pUVM, VERR_INVALID_PARAMETER, RT_SRC_POS,
@@ -4312,7 +4442,8 @@ int Console::i_configGraphicsController(PCFGMNODE pDevices,
                                         const ComPtr<IMachine> &ptrMachine,
                                         const ComPtr<IGraphicsAdapter> &ptrGraphicsAdapter,
                                         const ComPtr<IBIOSSettings> &ptrBiosSettings,
-                                        bool fHMEnabled)
+                                        bool fHMEnabled,
+                                        bool fHideMultipleMonitors)
 {
     // InsertConfig* throws
     try
@@ -4329,11 +4460,24 @@ int Console::i_configGraphicsController(PCFGMNODE pDevices,
 
         hrc = pBusMgr->assignPCIDevice(pcszDevice, pInst);                                  H();
         InsertConfigNode(pInst,    "Config", &pCfg);
-        ULONG cVRamMBs;
-        hrc = ptrGraphicsAdapter->COMGETTER(VRAMSize)(&cVRamMBs);                           H();
-        InsertConfigInteger(pCfg,  "VRamSize",             cVRamMBs * _1M);
+        ULONG cVRam;
+        hrc = ptrGraphicsAdapter->COMGETTER(VRAMSize)(&cVRam);                              H();
+        InsertConfigInteger(pCfg,  "VRamSize",             cVRam * _1M);
         ULONG cMonitorCount;
-        hrc = ptrGraphicsAdapter->COMGETTER(MonitorCount)(&cMonitorCount);                  H();
+
+        /**
+         * If the Virtio GPU is used with multiple monitors we hide additional
+         * monitors for the VirtualBox VGA adapter that is used for the legacy
+         * output, as the legacy output does not require multiple monitors.
+         * This leads to the multiple monitors appearing when we switch to the
+         * Virtio GPU.
+         */
+        if (not fHideMultipleMonitors)
+        {
+            hrc = ptrGraphicsAdapter->COMGETTER(MonitorCount)(&cMonitorCount);              H();
+        } else {
+            cMonitorCount = 1;
+        }
         InsertConfigInteger(pCfg,  "MonitorCount",         cMonitorCount);
 #ifdef VBOX_WITH_2X_4GB_ADDR_SPACE
         InsertConfigInteger(pCfg,  "R0Enabled",            fHMEnabled);
diff --git a/src/VBox/Main/src-client/DisplayImpl.cpp b/src/VBox/Main/src-client/DisplayImpl.cpp
index 5a4beef..1f236d9 100644
--- a/src/VBox/Main/src-client/DisplayImpl.cpp
+++ b/src/VBox/Main/src-client/DisplayImpl.cpp
@@ -65,6 +65,9 @@
 # include <VBox/vmm/pdmaudioifs.h>
 #endif
 
+#include <VBox/vmm/pdmdev.h>
+#include <VBox/com/errorprint.h>
+
 /**
  * Display driver instance data.
  *
@@ -2330,7 +2333,12 @@ HRESULT Display::drawToScreen(ULONG aScreenId, BYTE *aAddress, ULONG aX, ULONG a
 
         if (   !pFBInfo->fVBVAEnabled
             && uScreenId == VBOX_VIDEO_PRIMARY_SCREEN)
+        {
+            if (not pDisplay->mpDrv) {
+                return VINF_SUCCESS;
+            }
             pDisplay->mpDrv->pUpPort->pfnUpdateDisplayAll(pDisplay->mpDrv->pUpPort, /* fFailOnResize = */ true);
+        }
         else
         {
             if (!pFBInfo->fDisabled)
@@ -2664,6 +2672,39 @@ HRESULT Display::setScreenLayout(ScreenLayoutMode_T aScreenLayoutMode,
                         p->fDisplayFlags |= VMMDEV_DISPLAY_PRIMARY;
                 }
 
+                auto virtioGpuEnabled = [this]() -> bool {
+                    ComPtr<IGraphicsAdapter> pGraphicsAdapter;
+                    HRESULT hrc = mParent->i_machine()->COMGETTER(GraphicsAdapter)(pGraphicsAdapter.asOutParam());
+                    AssertComRCReturnRC(hrc);
+
+                    GraphicsControllerType_T adapterType;
+                    CHECK_ERROR(pGraphicsAdapter, COMGETTER(GraphicsControllerType)(&adapterType));
+                    return (adapterType == GraphicsControllerType_VGAWithVirtioGpu) or
+                           (adapterType == GraphicsControllerType_VirtioGpu);
+                };
+
+                if (virtioGpuEnabled()) {
+                    AutoReadLock alock2(this COMMA_LOCKVAL_SRC_POS);
+                    Console::SafeVMPtr ptrVM(mParent);
+                    if (!ptrVM.isOk()) {
+                        LogRelFunc(("VMPtr is not okay.\n"));
+                        return ptrVM.hrc();
+                    }
+                    alock2.release();
+
+                    PPDMIBASE pBase;
+                    int rc = ptrVM.vtable()->pfnPDMR3QueryDevice(ptrVM.rawUVM(), "virtio-gpu", 0, &pBase);
+                    AssertReleaseMsg(RT_SUCCESS(rc), ("query device failed"));
+
+                    PPDMIVIRTIOGPUPORT pPort {PDMIBASE_QUERY_INTERFACE(pBase, PDMIVIRTIOGPUPORT)};
+                    AssertMsg(pPort, ("Query interface failed.\n"));
+                    AssertMsg(pPort->pfnDisplayChanged, ("No resize handler available.\n"));
+                    PPDMDEVINS pDevIns = PDMIBASE_2_PDMDEV(pBase);
+                    if (pPort->pfnDisplayChanged) {
+                        pPort->pfnDisplayChanged(pDevIns, cDisplays, paDisplayDefs);
+                    }
+                }
+
                 bool const fForce =    aScreenLayoutMode == ScreenLayoutMode_Reset
                                     || aScreenLayoutMode == ScreenLayoutMode_Apply;
                 bool const fNotify = aScreenLayoutMode != ScreenLayoutMode_Silent;
diff --git a/src/VBox/Main/src-server/GraphicsAdapterImpl.cpp b/src/VBox/Main/src-server/GraphicsAdapterImpl.cpp
index 759f432..481d18a 100644
--- a/src/VBox/Main/src-server/GraphicsAdapterImpl.cpp
+++ b/src/VBox/Main/src-server/GraphicsAdapterImpl.cpp
@@ -198,6 +198,8 @@ HRESULT GraphicsAdapter::setGraphicsControllerType(GraphicsControllerType_T aGra
         case GraphicsControllerType_VMSVGA:
         case GraphicsControllerType_VBoxSVGA:
 #endif
+        case GraphicsControllerType_VGAWithVirtioGpu:
+        case GraphicsControllerType_VirtioGpu:
             break;
         default:
             return setError(E_INVALIDARG, tr("The graphics controller type (%d) is invalid"), aGraphicsControllerType);
diff --git a/src/VBox/Main/src-server/MachineImpl.cpp b/src/VBox/Main/src-server/MachineImpl.cpp
index c3c63d5..e3d3287 100644
--- a/src/VBox/Main/src-server/MachineImpl.cpp
+++ b/src/VBox/Main/src-server/MachineImpl.cpp
@@ -7064,6 +7064,80 @@ HRESULT Machine::getPCIDeviceAssignments(std::vector<ComPtr<IPCIDeviceAttachment
     return S_OK;
 }
 
+HRESULT Machine::attachVFIODevice(const com::Utf8Str &aDevicePath)
+{
+    AutoWriteLock alock(this COMMA_LOCKVAL_SRC_POS);
+
+    HRESULT hrc = i_checkStateDependency(MutableStateDep);
+
+    if (not SUCCEEDED(hrc))
+    {
+        return hrc;
+    }
+
+    auto search_fn = [&aDevicePath] (const com::Utf8Str& path)
+    {
+        return aDevicePath == path;
+    };
+
+    auto it {std::find_if(mHWData->mVFIODeviceAssignments.begin(), mHWData->mVFIODeviceAssignments.end(), search_fn)};
+
+    if (it != mHWData->mVFIODeviceAssignments.end())
+    {
+        return setError(E_INVALIDARG, tr("The VFIO device %s is already attached"), aDevicePath);
+    }
+
+    hrc = mHWData.backupEx();
+    if (not SUCCEEDED(hrc)) {
+        return hrc;
+    }
+
+    mHWData->mVFIODeviceAssignments.emplace_back(aDevicePath);
+    return S_OK;
+}
+
+HRESULT Machine::detachVFIODevice(const com::Utf8Str &aDevicePath)
+{
+    AutoWriteLock alock(this COMMA_LOCKVAL_SRC_POS);
+
+    HRESULT hrc = i_checkStateDependency(MutableStateDep);
+
+    if (not SUCCEEDED(hrc))
+    {
+        return hrc;
+    }
+
+    auto search_fn = [&aDevicePath] (const com::Utf8Str& path)
+    {
+        return aDevicePath == path;
+    };
+
+    hrc = mHWData.backupEx();
+
+    if (not SUCCEEDED(hrc)) {
+        return hrc;
+    }
+
+    auto it {std::find_if(mHWData->mVFIODeviceAssignments.begin(), mHWData->mVFIODeviceAssignments.end(), search_fn)};
+
+    if (it == mHWData->mVFIODeviceAssignments.end())
+    {
+        return setError(VBOX_E_OBJECT_NOT_FOUND, tr("No VFIO device %s attached"), aDevicePath);
+    }
+
+    mHWData->mVFIODeviceAssignments.erase(it);
+
+    return S_OK;
+}
+
+HRESULT Machine::getVFIODeviceAssignments(std::vector<com::Utf8Str>& aVFIODeviceAssignments)
+{
+    AutoReadLock alock(this COMMA_LOCKVAL_SRC_POS);
+
+    std::copy(mHWData->mVFIODeviceAssignments.begin(), mHWData->mVFIODeviceAssignments.end(), std::back_inserter(aVFIODeviceAssignments));
+    return S_OK;
+}
+
 HRESULT Machine::getBandwidthControl(ComPtr<IBandwidthControl> &aBandwidthControl)
 {
     mBandwidthControl.queryInterfaceTo(aBandwidthControl.asOutParam());
@@ -9474,6 +9548,12 @@ HRESULT Machine::i_loadHardware(const Guid *puuidRegistry,
             mHWData->mPCIDeviceAssignments.push_back(pda);
         }
 
+        // VFIO Devices
+        for (auto deviceAssignment : data.vfioAttachments)
+        {
+            mHWData->mVFIODeviceAssignments.push_back(deviceAssignment.strDevicePath);
+        }
+
         /*
          * (The following isn't really real hardware, but it lives in HWData
          * for reasons of convenience.)
@@ -10887,6 +10967,17 @@ HRESULT Machine::i_saveHardware(settings::Hardware &data, settings::Debugging *p
             data.pciAttachments.push_back(hpda);
         }
 
+        /* VFIO Devices */
+        data.vfioAttachments.clear();
+        for (auto devStr : mHWData->mVFIODeviceAssignments)
+        {
+            settings::VFIODeviceAttachment vfioda;
+
+            vfioda.strDevicePath = devStr;
+
+            data.vfioAttachments.push_back(vfioda);
+        }
+
         // guest properties
         data.llGuestProperties.clear();
 #ifdef VBOX_WITH_GUEST_PROPS
diff --git a/src/VBox/Main/src-server/SystemPropertiesImpl.cpp b/src/VBox/Main/src-server/SystemPropertiesImpl.cpp
index c238ae3..cfee49e 100644
--- a/src/VBox/Main/src-server/SystemPropertiesImpl.cpp
+++ b/src/VBox/Main/src-server/SystemPropertiesImpl.cpp
@@ -1687,6 +1687,8 @@ HRESULT SystemProperties::getSupportedGraphicsControllerTypes(std::vector<Graphi
         GraphicsControllerType_VBoxVGA,
         GraphicsControllerType_VMSVGA,
         GraphicsControllerType_VBoxSVGA,
+        GraphicsControllerType_VGAWithVirtioGpu,
+        GraphicsControllerType_VirtioGpu,
         GraphicsControllerType_Null,
     };
     aSupportedGraphicsControllerTypes.assign(aGraphicsControllerTypes,
diff --git a/src/VBox/Main/xml/Settings.cpp b/src/VBox/Main/xml/Settings.cpp
index fa1c1d8..bf4c7ae 100644
--- a/src/VBox/Main/xml/Settings.cpp
+++ b/src/VBox/Main/xml/Settings.cpp
@@ -3902,6 +3902,21 @@ bool HostPCIDeviceAttachment::operator==(const HostPCIDeviceAttachment &a) const
             && strDeviceName  == a.strDeviceName);
 }
 
+/**
+ * VFIODeviceAttachment Constructor.
+ */
+VFIODeviceAttachment::VFIODeviceAttachment() {}
+
+/**
+ * Comparison operator. This gets called from MachineConfigFile::operator==,
+ * which in turn gets called from Machine::saveSettings to figure out whether
+ * machine settings have really changed and thus need to be written out to disk.
+ */
+bool VFIODeviceAttachment::operator==(const VFIODeviceAttachment &a) const
+{
+    return (this == &a)
+        || (strDevicePath == a.strDevicePath);
+}
 
 /**
  * Constructor. Needs to set sane defaults which stand the test of time.
@@ -4089,6 +4104,7 @@ bool Hardware::operator==(const Hardware& h) const
             && llGuestProperties              == h.llGuestProperties
             && ioSettings                     == h.ioSettings
             && pciAttachments                 == h.pciAttachments
+            && vfioAttachments                == h.vfioAttachments
             && strDefaultFrontend             == h.strDefaultFrontend);
 }
 
@@ -5417,6 +5433,10 @@ void MachineConfigFile::readHardware(const xml::ElementNode &elmHardware,
                     type = GraphicsControllerType_VMSVGA;
                 else if (strGraphicsControllerType == "VBOXSVGA")
                     type = GraphicsControllerType_VBoxSVGA;
+                else if (strGraphicsControllerType == "VGAWITHVIRTIOGPU")
+                    type = GraphicsControllerType_VGAWithVirtioGpu;
+                else if (strGraphicsControllerType == "VIRTIOGPU")
+                    type = GraphicsControllerType_VirtioGpu;
                 else if (strGraphicsControllerType == "NONE")
                     type = GraphicsControllerType_Null;
                 else
@@ -5842,6 +5862,26 @@ void MachineConfigFile::readHardware(const xml::ElementNode &elmHardware,
                 }
             }
         }
+        else if (pelmHwChild->nameEquals("Vfio"))
+        {
+            const xml::ElementNode *pelmDevices;
+            if ((pelmDevices = pelmHwChild->findChildElement("Devices")))
+            {
+                xml::NodesLoop nl2(*pelmDevices, "Device");
+                const xml::ElementNode *pelmDevice;
+                while ((pelmDevice = nl2.forAllNodes()))
+                {
+                    VFIODeviceAttachment vfioda;
+
+                    if (!pelmDevice->getAttributeValue("devicePath", vfioda.strDevicePath))
+                    {
+                        throw ConfigFileError(this, pelmDevice, N_("Missing Device/@devicePath attribute"));
+                    }
+
+                    hw.vfioAttachments.push_back(vfioda);
+                }
+            }
+        }
         else if (pelmHwChild->nameEquals("EmulatedUSB"))
         {
             const xml::ElementNode *pelmCardReader;
@@ -7138,6 +7178,8 @@ void MachineConfigFile::buildHardwareXML(xml::ElementNode &elmParent,
                 case GraphicsControllerType_VBoxVGA:            pcszGraphics = "VBoxVGA"; break;
                 case GraphicsControllerType_VMSVGA:             pcszGraphics = "VMSVGA"; break;
                 case GraphicsControllerType_VBoxSVGA:           pcszGraphics = "VBoxSVGA"; break;
+                case GraphicsControllerType_VGAWithVirtioGpu:   pcszGraphics = "VGAWithVirtioGPU"; break;
+                case GraphicsControllerType_VirtioGpu:   pcszGraphics = "VirtioGPU"; break;
                 default: /*case GraphicsControllerType_Null:*/  pcszGraphics = "None"; break;
             }
             pelmDisplay->setAttribute("controller", pcszGraphics);
@@ -7927,6 +7969,20 @@ void MachineConfigFile::buildHardwareXML(xml::ElementNode &elmParent,
         }
     }
 
+    if (   m->sv >= SettingsVersion_v1_17
+        && hw.vfioAttachments.size())
+    {
+        xml::ElementNode *pelmVFIO = pelmHardware->createChild("Vfio");
+        xml::ElementNode *pelmVFIODevices = pelmVFIO->createChild("Devices");
+
+        for (auto deviceAssignment : hw.vfioAttachments)
+        {
+            xml::ElementNode *pelmThis = pelmVFIODevices->createChild("Device");
+
+            pelmThis->setAttribute("devicePath",  deviceAssignment.strDevicePath);
+        }
+    }
+
     if (   m->sv >= SettingsVersion_v1_12
         && hw.fEmulatedUSBCardReader)
     {
@@ -9143,6 +9199,12 @@ void MachineConfigFile::bumpSettingsVersionIfNeeded()
                 return;
             }
         }
+
+        if (hardwareMachine.vfioAttachments.size() > 0)
+        {
+            m->sv = SettingsVersion_v1_17;
+            return;
+        }
     }
 
     if (m->sv < SettingsVersion_v1_16)
diff --git a/src/VBox/Main/xml/VirtualBox-settings.xsd b/src/VBox/Main/xml/VirtualBox-settings.xsd
index 60f7303..460c5e7 100644
--- a/src/VBox/Main/xml/VirtualBox-settings.xsd
+++ b/src/VBox/Main/xml/VirtualBox-settings.xsd
@@ -289,6 +289,8 @@
     <xsd:enumeration value="VBoxVGA"/>
     <xsd:enumeration value="VMSVGA"/>
     <xsd:enumeration value="VBoxSVGA"/>
+    <xsd:enumeration value="VGAWithVirtioGPU"/>
+    <xsd:enumeration value="VirtioGPU"/>
   </xsd:restriction>
 </xsd:simpleType>
 
diff --git a/src/VBox/Runtime/VBox/log-vbox.cpp b/src/VBox/Runtime/VBox/log-vbox.cpp
index 2e82f85..5b75d76 100644
--- a/src/VBox/Runtime/VBox/log-vbox.cpp
+++ b/src/VBox/Runtime/VBox/log-vbox.cpp
@@ -272,6 +272,8 @@ RTDECL(PRTLOGGER) RTLogDefaultInit(void)
     ASSERT_LOG_GROUP(DEV_SB16);
     ASSERT_LOG_GROUP(DEV_SERIAL);
     ASSERT_LOG_GROUP(DEV_SMC);
+    ASSERT_LOG_GROUP(DEV_VFIO);
+    ASSERT_LOG_GROUP(DEV_VIRTIO_GPU);
     ASSERT_LOG_GROUP(DEV_VGA);
     ASSERT_LOG_GROUP(DEV_VIRTIO);
     ASSERT_LOG_GROUP(DEV_VIRTIO_NET);
diff --git a/src/VBox/Runtime/r3/posix/thread-posix.cpp b/src/VBox/Runtime/r3/posix/thread-posix.cpp
index cd621ce..c89c600 100644
--- a/src/VBox/Runtime/r3/posix/thread-posix.cpp
+++ b/src/VBox/Runtime/r3/posix/thread-posix.cpp
@@ -727,6 +727,10 @@ RTDECL(int) RTThreadControlPokeSignal(RTTHREAD hThread, bool fEnable)
     return rc;
 }
 
+RTDECL(int) RTThreadPokeSignal(void)
+{
+    return g_iSigPokeThread;
+}
 
 #endif
 
diff --git a/src/VBox/Runtime/testcase/Makefile.kmk b/src/VBox/Runtime/testcase/Makefile.kmk
index c3a097b..4ecc3e5 100644
--- a/src/VBox/Runtime/testcase/Makefile.kmk
+++ b/src/VBox/Runtime/testcase/Makefile.kmk
@@ -559,6 +559,7 @@ ifdef VBOX_WITH_TESTCASES # The whole file
   tstLog_CLEAN        = $(tstLog_0_OUTDIR)/tstLogGroups.h
   $$(tstLog_0_OUTDIR)/tstLogGroups.h: $(PATH_ROOT)/include/VBox/log.h
 	$(call MSG_GENERATE,,$@,$<)
+	$(QUIET)$(MKDIR) -p $(tstLog_0_OUTDIR)
 	$(QUIET)$(RM) -f -- "$@"
 	$(QUIET)$(SED) -n -e 's/^ *LOG_GROUP_\([A-Z0-9_]*\),.*$(DOLLAR)/{ LOG_GROUP_\1, "\1" },/p' --output "$@" "$<"
  endif # !VBOX_ONLY_VALIDATIONKIT
diff --git a/src/VBox/VMM/Makefile.kmk b/src/VBox/VMM/Makefile.kmk
index 1d87ac3..43c8b53 100644
--- a/src/VBox/VMM/Makefile.kmk
+++ b/src/VBox/VMM/Makefile.kmk
@@ -137,7 +137,8 @@ VBoxVMM_SOURCES  = \
 	VMMR3/EMR3Nem.cpp \
 	VMMR3/GCM.cpp \
 	VMMR3/GIM.cpp \
-	VMMR3/GIMHv.cpp \
+	$(if-expr !defined(VBOX_WITH_KVM), VMMR3/GIMHv.cpp,) \
+	$(if-expr  defined(VBOX_WITH_KVM), VMMR3/GIMHvOnKvm.cpp,) \
 	VMMR3/GIMKvm.cpp \
 	VMMR3/GIMMinimal.cpp \
 	VMMR3/IEMR3.cpp \
@@ -215,7 +216,8 @@ VBoxVMM_SOURCES  = \
 	VMMAll/EMAll.cpp \
 	VMMAll/GCMAll.cpp \
 	VMMAll/GIMAll.cpp \
-	VMMAll/GIMAllHv.cpp \
+	$(if-expr !defined(VBOX_WITH_KVM), VMMAll/GIMAllHv.cpp,) \
+	$(if-expr  defined(VBOX_WITH_KVM), VMMAll/GIMAllHvOnKvm.cpp,) \
 	VMMAll/GIMAllKvm.cpp \
 	VMMAll/TMAll.cpp \
 	VMMAll/TMAllCpu.cpp \
diff --git a/src/VBox/VMM/VMMAll/APICAll.cpp b/src/VBox/VMM/VMMAll/APICAll.cpp
index 6041a84..e2df2ec 100644
--- a/src/VBox/VMM/VMMAll/APICAll.cpp
+++ b/src/VBox/VMM/VMMAll/APICAll.cpp
@@ -2726,6 +2726,16 @@ VMM_INT_DECL(VBOXSTRICTRC) APICLocalInterrupt(PVMCPUCC pVCpu, uint8_t u8Pin, uin
     AssertReturn(u8Level <= 1, VERR_INVALID_PARAMETER);
 
     VBOXSTRICTRC rcStrict = VINF_SUCCESS;
+#ifdef VBOX_WITH_KVM
+    /* TODO: Fix the local interrupt handling. See vbox-engineering#430. */
+    if (u8Level) {
+        apicSetInterruptFF(pVCpu, PDMAPICIRQ_EXTINT);
+    } else {
+        apicClearInterruptFF(pVCpu, PDMAPICIRQ_EXTINT);
+    }
+
+    return VINF_SUCCESS;
+#endif
 
     /* If the APIC is enabled, the interrupt is subject to LVT programming. */
     if (APICIsEnabled(pVCpu))
diff --git a/src/VBox/VMM/VMMAll/GIMAllHvOnKvm.cpp b/src/VBox/VMM/VMMAll/GIMAllHvOnKvm.cpp
new file mode 100644
index 0000000..9487027
--- /dev/null
+++ b/src/VBox/VMM/VMMAll/GIMAllHvOnKvm.cpp
@@ -0,0 +1,134 @@
+/*
+ * Copyright (C) Cyberus Technology GmbH.
+ *
+ * This program is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <https://www.gnu.org/licenses/>.
+ *
+ * SPDX-License-Identifier: GPL-3.0-or-later
+ */
+
+#define LOG_GROUP LOG_GROUP_GIM
+#include <VBox/vmm/dbgf.h>
+#include <VBox/vmm/gim.h>
+#include "GIMInternal.h"
+#include <VBox/vmm/vm.h>
+
+#include <iprt/assert.h>
+
+/**
+ * With GIMHvOnKvm, userspace does not need to do any HyperV emulation because
+ * it all happens inside the kernel module. These stubs are merely here to make
+ * GIM.cpp happy.
+ */
+
+VMM_INT_DECL(void) gimHvStartStimer(PVMCPUCC pVCpu, PCGIMHVSTIMER pHvStimer)
+{
+    NOREF(pVCpu); NOREF(pHvStimer);
+    AssertLogRelMsg(false, ("%s", __PRETTY_FUNCTION__));
+}
+
+VMM_INT_DECL(VBOXSTRICTRC) gimHvHypercall(PVMCPUCC pVCpu, PCPUMCTX pCtx)
+{
+    NOREF(pVCpu); NOREF(pCtx);
+    AssertLogRelMsgReturn(false, ("%s", __PRETTY_FUNCTION__), VERR_NOT_SUPPORTED);
+}
+
+VMM_INT_DECL(VBOXSTRICTRC) gimHvHypercallEx(PVMCPUCC pVCpu, PCPUMCTX pCtx, unsigned uDisOpcode, uint8_t cbInstr)
+{
+    NOREF(pVCpu); NOREF(pCtx); NOREF(uDisOpcode); NOREF(cbInstr);
+    AssertLogRelMsgReturn(false, ("%s", __PRETTY_FUNCTION__), VERR_NOT_SUPPORTED);
+}
+
+VMM_INT_DECL(PGIMMMIO2REGION) gimHvGetMmio2Regions(PVM pVM, uint32_t *pcRegions)
+{
+    NOREF(pVM); NOREF(pcRegions);
+    return nullptr;
+}
+
+VMM_INT_DECL(bool) gimHvAreHypercallsEnabled(PCVM pVM)
+{
+    NOREF(pVM);
+    return false;
+}
+
+VMM_INT_DECL(bool) gimHvIsParavirtTscEnabled(PVM pVM)
+{
+    NOREF(pVM);
+    return false;
+}
+
+VMM_INT_DECL(bool) gimHvShouldTrapXcptUD(PVMCPU pVCpu)
+{
+    NOREF(pVCpu);
+    return false;
+}
+
+VMM_INT_DECL(VBOXSTRICTRC) gimHvXcptUD(PVMCPUCC pVCpu, PCPUMCTX pCtx, PDISCPUSTATE pDis, uint8_t *pcbInstr)
+{
+    NOREF(pVCpu); NOREF(pCtx); NOREF(pDis); NOREF(pcbInstr);
+    AssertLogRelMsgReturn(false, ("%s", __PRETTY_FUNCTION__), VERR_NOT_SUPPORTED);
+}
+
+VMM_INT_DECL(VBOXSTRICTRC) gimHvReadMsr(PVMCPUCC pVCpu, uint32_t idMsr, PCCPUMMSRRANGE pRange, uint64_t *puValue)
+{
+    NOREF(pRange);
+
+    PVMCC   pVM = pVCpu->CTX_SUFF(pVM);
+    PCGIMHV pHv = &pVM->gim.s.u.Hv;
+
+    switch (idMsr)
+    {
+        case MSR_GIM_HV_CRASH_CTL:
+            *puValue = pHv->uCrashCtlMsr;
+            return VINF_SUCCESS;
+
+        case MSR_GIM_HV_CRASH_P0: *puValue = pHv->uCrashP0Msr;   return VINF_SUCCESS;
+        case MSR_GIM_HV_CRASH_P1: *puValue = pHv->uCrashP1Msr;   return VINF_SUCCESS;
+        case MSR_GIM_HV_CRASH_P2: *puValue = pHv->uCrashP2Msr;   return VINF_SUCCESS;
+        case MSR_GIM_HV_CRASH_P3: *puValue = pHv->uCrashP3Msr;   return VINF_SUCCESS;
+        case MSR_GIM_HV_CRASH_P4: *puValue = pHv->uCrashP4Msr;   return VINF_SUCCESS;
+        default: break;
+    }
+
+    AssertLogRelMsgReturn(false, ("%s", __PRETTY_FUNCTION__), VERR_NOT_SUPPORTED);
+}
+
+VMM_INT_DECL(VBOXSTRICTRC) gimHvWriteMsr(PVMCPUCC pVCpu, uint32_t idMsr, PCCPUMMSRRANGE pRange, uint64_t uRawValue)
+{
+    NOREF(pRange);
+
+    PVMCC  pVM = pVCpu->CTX_SUFF(pVM);
+    PGIMHV pHv = &pVM->gim.s.u.Hv;
+
+    switch (idMsr) {
+        case MSR_GIM_HV_CRASH_CTL:
+        {
+            if (uRawValue & MSR_GIM_HV_CRASH_CTL_NOTIFY)
+            {
+                LogRel(("GIM: HyperV: Guest indicates a fatal condition! P0=%#RX64 P1=%#RX64 P2=%#RX64 P3=%#RX64 P4=%#RX64\n",
+                        pHv->uCrashP0Msr, pHv->uCrashP1Msr, pHv->uCrashP2Msr, pHv->uCrashP3Msr, pHv->uCrashP4Msr));
+                DBGFR3ReportBugCheck(pVM, pVCpu, DBGFEVENT_BSOD_MSR, pHv->uCrashP0Msr, pHv->uCrashP1Msr,
+                                     pHv->uCrashP2Msr, pHv->uCrashP3Msr, pHv->uCrashP4Msr);
+            }
+            return VINF_SUCCESS;
+        }
+        case MSR_GIM_HV_CRASH_P0:  pHv->uCrashP0Msr = uRawValue;  return VINF_SUCCESS;
+        case MSR_GIM_HV_CRASH_P1:  pHv->uCrashP1Msr = uRawValue;  return VINF_SUCCESS;
+        case MSR_GIM_HV_CRASH_P2:  pHv->uCrashP2Msr = uRawValue;  return VINF_SUCCESS;
+        case MSR_GIM_HV_CRASH_P3:  pHv->uCrashP3Msr = uRawValue;  return VINF_SUCCESS;
+        case MSR_GIM_HV_CRASH_P4:  pHv->uCrashP4Msr = uRawValue;  return VINF_SUCCESS;
+        default: break;
+    }
+
+    AssertLogRelMsgReturn(false, ("%s", __PRETTY_FUNCTION__), VERR_NOT_SUPPORTED);
+}
diff --git a/src/VBox/VMM/VMMAll/PGMAllBth.h b/src/VBox/VMM/VMMAll/PGMAllBth.h
index 50b7a30..9d4bd8c 100644
--- a/src/VBox/VMM/VMMAll/PGMAllBth.h
+++ b/src/VBox/VMM/VMMAll/PGMAllBth.h
@@ -5046,7 +5046,10 @@ PGM_BTH_DECL(int, MapCR3)(PVMCPUCC pVCpu, RTGCPHYS GCPhysCR3)
  || PGM_GST_TYPE == PGM_TYPE_AMD64
 
     LogFlow(("MapCR3: %RGp\n", GCPhysCR3));
+
+#ifndef VBOX_WITH_KVM_IRQCHIP_FULL
     PGM_A20_ASSERT_MASKED(pVCpu, GCPhysCR3);
+#endif
 
 # if PGM_GST_TYPE == PGM_TYPE_PAE
     if (   !pVCpu->pgm.s.CTX_SUFF(fPaePdpesAndCr3Mapped)
diff --git a/src/VBox/VMM/VMMAll/TMAll.cpp b/src/VBox/VMM/VMMAll/TMAll.cpp
index 677decd..8edc178 100644
--- a/src/VBox/VMM/VMMAll/TMAll.cpp
+++ b/src/VBox/VMM/VMMAll/TMAll.cpp
@@ -208,7 +208,10 @@ VMMDECL(void) TMNotifyEndOfExecution(PVMCC pVM, PVMCPUCC pVCpu, uint64_t uTsc)
     uint64_t       cTicks = uTsc - pVCpu->tm.s.uTscStartExecuting - SUPGetTscDeltaByCpuSetIndex(pVCpu->iHostCpuSet);
     uint64_t const uCpuHz = SUPGetCpuHzFromGipBySetIndex(g_pSUPGlobalInfoPage, pVCpu->iHostCpuSet);
 # endif
-    AssertStmt(cTicks <= uCpuHz << 2, cTicks = uCpuHz << 2); /* max 4 sec */
+    /* Execute for at most 4s. */
+    AssertMsgStmt(cTicks <= uCpuHz << 2,
+                  ("TM/%u: execution took longer than 4s: cTicks=%llu uCpuHz=%llu\n", pVCpu->idCpu, cTicks, uCpuHz),
+                  cTicks = uCpuHz << 2);
 
     uint64_t cNsExecutingDelta;
     if (uCpuHz < _4G)
diff --git a/src/VBox/VMM/VMMAll/TMAllVirtual.cpp b/src/VBox/VMM/VMMAll/TMAllVirtual.cpp
index 9244bd8..2e34aea 100644
--- a/src/VBox/VMM/VMMAll/TMAllVirtual.cpp
+++ b/src/VBox/VMM/VMMAll/TMAllVirtual.cpp
@@ -952,7 +952,11 @@ VMM_INT_DECL(uint64_t) TMVirtualSyncGetWithDeadlineNoCheck(PVMCC pVM, uint64_t *
 VMMDECL(uint64_t) TMVirtualSyncGetNsToDeadline(PVMCC pVM, uint64_t *puDeadlineVersion, uint64_t *puTscNow)
 {
     uint64_t cNsToDeadline;
+#ifdef VBOX_WITH_KVM
+    tmVirtualSyncGetEx(pVM, true /*fCheckTimers*/, &cNsToDeadline, puDeadlineVersion, puTscNow);
+#else
     tmVirtualSyncGetEx(pVM, false /*fCheckTimers*/, &cNsToDeadline, puDeadlineVersion, puTscNow);
+#endif
     return cNsToDeadline;
 }
 
diff --git a/src/VBox/VMM/VMMR3/APIC.cpp b/src/VBox/VMM/VMMR3/APIC.cpp
index 6753ac6..b5ff86c 100644
--- a/src/VBox/VMM/VMMR3/APIC.cpp
+++ b/src/VBox/VMM/VMMR3/APIC.cpp
@@ -36,6 +36,7 @@
 #include <VBox/vmm/cpum.h>
 #include <VBox/vmm/hm.h>
 #include <VBox/vmm/mm.h>
+#include <VBox/vmm/nem.h>
 #include <VBox/vmm/pdmdev.h>
 #include <VBox/vmm/ssm.h>
 #include <VBox/vmm/vm.h>
@@ -347,6 +348,10 @@ static DECLCALLBACK(void) apicR3Info(PVM pVM, PCDBGFINFOHLP pHlp, const char *ps
     PCXAPICPAGE  pXApicPage  = VMCPU_TO_CXAPICPAGE(pVCpu);
     PCX2APICPAGE pX2ApicPage = VMCPU_TO_CX2APICPAGE(pVCpu);
 
+#ifdef VBOX_WITH_KVM
+    NEMR3KvmGetLapicState(pVCpu, VMCPU_TO_XAPICPAGE(pVCpu));
+#endif
+
     uint64_t const uBaseMsr  = pApicCpu->uApicBaseMsr;
     APICMODE const enmMode   = apicGetMode(uBaseMsr);
     bool const   fX2ApicMode = XAPIC_IN_X2APIC_MODE(pVCpu);
@@ -975,6 +980,10 @@ static DECLCALLBACK(int) apicR3SaveExec(PPDMDEVINS pDevIns, PSSMHANDLE pSSM)
         PVMCPU pVCpu = pVM->apCpusR3[idCpu];
         PCAPICCPU pApicCpu = VMCPU_TO_APICCPU(pVCpu);
 
+#ifdef VBOX_WITH_KVM
+        NEMR3KvmGetLapicState(pVCpu, pApicCpu->pvApicPageR3);
+#endif
+
         /* Update interrupts from the pending-interrupts bitmaps to the IRR. */
         APICUpdatePendingInterrupts(pVCpu);
 
@@ -1068,6 +1077,10 @@ static DECLCALLBACK(int) apicR3LoadExec(PPDMDEVINS pDevIns, PSSMHANDLE pSSM, uin
             else
                 pHlp->pfnSSMGetStruct(pSSM, pApicCpu->pvApicPageR3, &g_aXApicPageFields[0]);
 
+#ifdef VBOX_WITH_KVM
+            NEMR3KvmSetLapicState(pVCpu, pApicCpu->pvApicPageR3);
+#endif
+
             /* Load the timer. */
             rc = pHlp->pfnSSMGetU64(pSSM, &pApicCpu->u64TimerInitial);     AssertRCReturn(rc, rc);
             rc = PDMDevHlpTimerLoad(pDevIns, pApicCpu->hTimer, pSSM);      AssertRCReturn(rc, rc);
@@ -1196,6 +1209,11 @@ DECLCALLBACK(void) apicR3Reset(PPDMDEVINS pDevIns)
 
         /* Clear the interrupt pending force flag. */
         apicClearInterruptFF(pVCpuDest, PDMAPICIRQ_HARDWARE);
+
+#ifdef VBOX_WITH_KVM
+        PXAPICPAGE  pXApicPage  = VMCPU_TO_XAPICPAGE(pVCpuDest);
+        NEMR3KvmSetLapicState(pVCpuDest, pXApicPage);
+#endif
     }
 }
 
@@ -1547,6 +1565,9 @@ DECLCALLBACK(int) apicR3Construct(PPDMDEVINS pDevIns, int iInstance, PCFGMNODE p
     {
         PVMCPU   pVCpu     = pVM->apCpusR3[idCpu];
         PAPICCPU pApicCpu  = VMCPU_TO_APICCPU(pVCpu);
+#ifdef VBOX_WITH_KVM
+        NEMR3KvmSetLapicState(pVCpu, pApicCpu->pvApicPageR3);
+#endif
 
         APIC_REG_COUNTER(&pApicCpu->StatPostIntrCnt,   "%u",  "APIC/VCPU stats / number of apicPostInterrupt calls.");
         for (size_t i = 0; i < RT_ELEMENTS(pApicCpu->aStatVectors); i++)
diff --git a/src/VBox/VMM/VMMR3/CPUM.cpp b/src/VBox/VMM/VMMR3/CPUM.cpp
index 7e0fbd3..f906332 100644
--- a/src/VBox/VMM/VMMR3/CPUM.cpp
+++ b/src/VBox/VMM/VMMR3/CPUM.cpp
@@ -1790,9 +1790,13 @@ void cpumR3InitVmxGuestFeaturesAndMsrs(PVM pVM, PCFGMNODE pCpumCfg, PCVMXMSRS pH
     if (fVmxEpt)
     {
         const char *pszWhy = NULL;
+#ifndef VBOX_WITH_KVM_NESTING
         if (!VM_IS_HM_ENABLED(pVM) && !VM_IS_EXEC_ENGINE_IEM(pVM))
             pszWhy = "execution engine is neither HM nor IEM";
         else if (VM_IS_HM_ENABLED(pVM) && !HMIsNestedPagingActive(pVM))
+#else
+        if (VM_IS_HM_ENABLED(pVM) && !HMIsNestedPagingActive(pVM))
+#endif
             pszWhy = "nested paging is not enabled for the VM or it is not supported by the host";
         else if (VM_IS_HM_ENABLED(pVM) && !pVM->cpum.s.HostFeatures.fNoExecute)
             pszWhy = "NX is not available on the host";
@@ -2845,10 +2849,21 @@ static DECLCALLBACK(int) cpumR3LoadExec(PVM pVM, PSSMHANDLE pSSM, uint32_t uVers
                     rc = SSMR3GetStructEx(pSSM, &pGstCtx->XState.Hdr, sizeof(pGstCtx->XState.Hdr),
                                           0, g_aCpumXSaveHdrFields, NULL);
                     AssertRCReturn(rc, rc);
+#ifndef VBOX_WITH_KVM
+                    /*
+                     * This assertion triggers on resume when the guest was
+                     * suspended early during boot. The hypothesis is that this
+                     * happens when XSAVE is not enabled yet. Seems harmless for
+                     * now.
+                     *
+                     * See: virtualbox#69
+                     */
+
                     AssertLogRelMsgReturn(!(pGstCtx->XState.Hdr.bmXState & ~pGstCtx->fXStateMask),
                                           ("bmXState=%#RX64 fXStateMask=%#RX64\n",
                                            pGstCtx->XState.Hdr.bmXState, pGstCtx->fXStateMask),
                                           VERR_CPUM_INVALID_XSAVE_HDR);
+#endif
                 }
                 if (pGstCtx->fXStateMask & XSAVE_C_YMM)
                 {
diff --git a/src/VBox/VMM/VMMR3/CPUMR3CpuId.cpp b/src/VBox/VMM/VMMR3/CPUMR3CpuId.cpp
index 04d8ac3..6cc2948 100644
--- a/src/VBox/VMM/VMMR3/CPUMR3CpuId.cpp
+++ b/src/VBox/VMM/VMMR3/CPUMR3CpuId.cpp
@@ -1331,6 +1331,13 @@ static int cpumR3CpuIdSanitize(PVM pVM, PCPUM pCpum, PCPUMCPUIDCONFIG pConfig)
     ((enmConfig) && ((enmConfig) == CPUMISAEXTCFG_ENABLED_ALWAYS || (fHostFeature)) && (fAndExpr) ? (fConst) : 0)
 #define PASSTHRU_FEATURE_TODO(enmConfig, fConst) ((enmConfig) ? (fConst) : 0)
 
+#ifdef VBOX_WITH_KVM
+#define PASSTHRU_FEATURE_KVM_ONLY(fConst) (fConst)
+#else
+#define PASSTHRU_FEATURE_KVM_ONLY(fConst) (0)
+#endif
+
+
     /* Cpuid 1:
      * EAX: CPU model, family and stepping.
      *
@@ -1407,7 +1414,7 @@ static int cpumR3CpuIdSanitize(PVM pVM, PCPUM pCpum, PCPUMCPUIDCONFIG pConfig)
                            | PASSTHRU_FEATURE(pConfig->enmXSave, pHstFeat->fXSaveRstor, X86_CPUID_FEATURE_ECX_XSAVE)
                            //| X86_CPUID_FEATURE_ECX_OSXSAVE - mirrors CR4.OSXSAVE state, set dynamically.
                            | PASSTHRU_FEATURE(pConfig->enmAvx, pHstFeat->fAvx, X86_CPUID_FEATURE_ECX_AVX)
-                           //| X86_CPUID_FEATURE_ECX_F16C  - not implemented yet.
+                           | PASSTHRU_FEATURE_KVM_ONLY(X86_CPUID_FEATURE_ECX_F16C)
                            | PASSTHRU_FEATURE_TODO(pConfig->enmRdRand, X86_CPUID_FEATURE_ECX_RDRAND)
                            //| X86_CPUID_FEATURE_ECX_HVP   - Set explicitly later.
                            ;
@@ -1590,7 +1597,7 @@ static int cpumR3CpuIdSanitize(PVM pVM, PCPUM pCpum, PCPUMCPUIDCONFIG pConfig)
                                | X86_CPUID_AMD_FEATURE_EDX_MMX
                                | X86_CPUID_AMD_FEATURE_EDX_FXSR
                                | X86_CPUID_AMD_FEATURE_EDX_FFXSR
-                               //| X86_CPUID_EXT_FEATURE_EDX_PAGE1GB
+                               | PASSTHRU_FEATURE_KVM_ONLY(X86_CPUID_EXT_FEATURE_EDX_PAGE1GB)
                                | X86_CPUID_EXT_FEATURE_EDX_RDTSCP
                                //| RT_BIT_32(28)                    - reserved
                                //| X86_CPUID_EXT_FEATURE_EDX_LONG_MODE - turned on when necessary
@@ -1852,9 +1859,9 @@ static int cpumR3CpuIdSanitize(PVM pVM, PCPUM pCpum, PCPUMCPUIDCONFIG pConfig)
                                //| X86_CPUID_STEXT_FEATURE_EBX_HLE               RT_BIT(4)
                                | PASSTHRU_FEATURE(pConfig->enmAvx2, pHstFeat->fAvx2, X86_CPUID_STEXT_FEATURE_EBX_AVX2)
                                | X86_CPUID_STEXT_FEATURE_EBX_FDP_EXCPTN_ONLY
-                               //| X86_CPUID_STEXT_FEATURE_EBX_SMEP              RT_BIT(7)
+                               | PASSTHRU_FEATURE_KVM_ONLY(X86_CPUID_STEXT_FEATURE_EBX_SMEP)
                                | X86_CPUID_STEXT_FEATURE_EBX_BMI2
-                               //| X86_CPUID_STEXT_FEATURE_EBX_ERMS              RT_BIT(9)
+                               | PASSTHRU_FEATURE_KVM_ONLY(X86_CPUID_STEXT_FEATURE_EBX_ERMS)
                                | PASSTHRU_FEATURE(pConfig->enmInvpcid, pHstFeat->fInvpcid, X86_CPUID_STEXT_FEATURE_EBX_INVPCID)
                                //| X86_CPUID_STEXT_FEATURE_EBX_RTM               RT_BIT(11)
                                //| X86_CPUID_STEXT_FEATURE_EBX_PQM               RT_BIT(12)
@@ -1864,29 +1871,33 @@ static int cpumR3CpuIdSanitize(PVM pVM, PCPUM pCpum, PCPUMCPUIDCONFIG pConfig)
                                //| X86_CPUID_STEXT_FEATURE_EBX_AVX512F           RT_BIT(16)
                                //| RT_BIT(17) - reserved
                                | PASSTHRU_FEATURE_TODO(pConfig->enmRdSeed, X86_CPUID_STEXT_FEATURE_EBX_RDSEED)
-                               //| X86_CPUID_STEXT_FEATURE_EBX_ADX               RT_BIT(19)
-                               //| X86_CPUID_STEXT_FEATURE_EBX_SMAP              RT_BIT(20)
+                               | PASSTHRU_FEATURE_KVM_ONLY(X86_CPUID_STEXT_FEATURE_EBX_ADX)
+                               | PASSTHRU_FEATURE_KVM_ONLY(X86_CPUID_STEXT_FEATURE_EBX_SMAP)
                                //| RT_BIT(21) - reserved
                                //| RT_BIT(22) - reserved
                                | PASSTHRU_FEATURE(pConfig->enmCLFlushOpt, pHstFeat->fClFlushOpt, X86_CPUID_STEXT_FEATURE_EBX_CLFLUSHOPT)
-                               //| RT_BIT(24) - reserved
+                               | PASSTHRU_FEATURE_KVM_ONLY(X86_CPUID_STEXT_FEATURE_EBX_CLWB)
                                //| X86_CPUID_STEXT_FEATURE_EBX_INTEL_PT          RT_BIT(25)
                                //| X86_CPUID_STEXT_FEATURE_EBX_AVX512PF          RT_BIT(26)
                                //| X86_CPUID_STEXT_FEATURE_EBX_AVX512ER          RT_BIT(27)
                                //| X86_CPUID_STEXT_FEATURE_EBX_AVX512CD          RT_BIT(28)
-                               //| X86_CPUID_STEXT_FEATURE_EBX_SHA               RT_BIT(29)
+                               | PASSTHRU_FEATURE_KVM_ONLY(X86_CPUID_STEXT_FEATURE_EBX_SHA)
                                //| RT_BIT(30) - reserved
                                //| RT_BIT(31) - reserved
                                ;
                 pCurLeaf->uEcx &= 0
                                //| X86_CPUID_STEXT_FEATURE_ECX_PREFETCHWT1 - we do not do vector functions yet.
+                               | PASSTHRU_FEATURE_KVM_ONLY(X86_CPUID_STEXT_FEATURE_ECX_GFNI)
                                ;
                 pCurLeaf->uEdx &= 0
+                               | PASSTHRU_FEATURE_KVM_ONLY(X86_CPUID_STEXT_FEATURE_EDX_FSRM)
+                               | PASSTHRU_FEATURE_KVM_ONLY(X86_CPUID_STEXT_FEATURE_EDX_SERIALIZE)
                                | PASSTHRU_FEATURE(pConfig->enmMdsClear,   pHstFeat->fMdsClear, X86_CPUID_STEXT_FEATURE_EDX_MD_CLEAR)
-                               //| X86_CPUID_STEXT_FEATURE_EDX_IBRS_IBPB         RT_BIT(26)
-                               //| X86_CPUID_STEXT_FEATURE_EDX_STIBP             RT_BIT(27)
+                               | PASSTHRU_FEATURE_KVM_ONLY(X86_CPUID_STEXT_FEATURE_EDX_IBRS_IBPB)
+                               | PASSTHRU_FEATURE_KVM_ONLY(X86_CPUID_STEXT_FEATURE_EDX_STIBP)
                                | PASSTHRU_FEATURE(pConfig->enmFlushCmdMsr, pHstFeat->fFlushCmd, X86_CPUID_STEXT_FEATURE_EDX_FLUSH_CMD)
                                | PASSTHRU_FEATURE(pConfig->enmArchCapMsr,  pHstFeat->fArchCap,  X86_CPUID_STEXT_FEATURE_EDX_ARCHCAP)
+                               | PASSTHRU_FEATURE_KVM_ONLY(X86_CPUID_STEXT_FEATURE_EDX_SSBD)
                                ;
 
                 /* Mask out INVPCID unless FSGSBASE is exposed due to a bug in Windows 10 SMP guests, see @bugref{9089#c15}. */
@@ -2787,6 +2798,7 @@ static int cpumR3CpuIdReadConfig(PVM pVM, PCPUMCPUIDCONFIG pConfig, PCFGMNODE pC
         AssertLogRelRCReturn(rc, rc);
         if (pConfig->fNestedHWVirt)
         {
+#ifndef VBOX_WITH_KVM_NESTING
             /** @todo Think about enabling this later with NEM/KVM. */
             if (VM_IS_NEM_ENABLED(pVM))
             {
@@ -2796,6 +2808,7 @@ static int cpumR3CpuIdReadConfig(PVM pVM, PCPUMCPUIDCONFIG pConfig, PCFGMNODE pC
             else if (!fNestedPagingAndFullGuestExec)
                 return VMSetError(pVM, VERR_CPUM_INVALID_HWVIRT_CONFIG, RT_SRC_POS,
                                   "Cannot enable nested VT-x/AMD-V without nested-paging and unrestricted guest execution!\n");
+#endif
         }
     }
 
@@ -3384,6 +3397,7 @@ VMMR3_INT_DECL(void) CPUMR3SetGuestCpuIdFeature(PVM pVM, CPUMCPUIDFEATURE enmFea
          * Note! ASSUMES CPUMCPUIDFEATURE_APIC is called first.
          */
         case CPUMCPUIDFEATURE_X2APIC:
+#ifndef VBOX_WITH_KVM
             pLeaf = cpumCpuIdGetLeaf(pVM, UINT32_C(0x00000001));
             if (pLeaf)
                 pVM->cpum.s.aGuestCpuIdPatmStd[1].uEcx = pLeaf->uEcx |= X86_CPUID_FEATURE_ECX_X2APIC;
@@ -3398,6 +3412,7 @@ VMMR3_INT_DECL(void) CPUMR3SetGuestCpuIdFeature(PVM pVM, CPUMCPUIDFEATURE enmFea
             }
 
             LogRel(("CPUM: SetGuestCpuIdFeature: Enabled x2APIC\n"));
+#endif
             break;
 
         /*
diff --git a/src/VBox/VMM/VMMR3/EM.cpp b/src/VBox/VMM/VMMR3/EM.cpp
index bd15b88..5e52065 100644
--- a/src/VBox/VMM/VMMR3/EM.cpp
+++ b/src/VBox/VMM/VMMR3/EM.cpp
@@ -219,7 +219,11 @@ VMMR3_INT_DECL(int) EMR3Init(PVM pVM)
     {
         PVMCPU pVCpu = pVM->apCpusR3[idCpu];
 
+#ifdef VBOX_WITH_KVM
+        pVCpu->em.s.enmState            = EMSTATE_NONE;
+#else
         pVCpu->em.s.enmState            = idCpu == 0 ? EMSTATE_NONE : EMSTATE_WAIT_SIPI;
+#endif
         pVCpu->em.s.enmPrevState        = EMSTATE_NONE;
         pVCpu->em.s.u64TimeSliceStart   = 0; /* paranoia */
         pVCpu->em.s.idxContinueExitRec  = UINT16_MAX;
@@ -2353,7 +2357,14 @@ VMMR3_INT_DECL(int) EMR3ExecuteVM(PVM pVM, PVMCPU pVCpu)
                     else
                     {
                         /* All other VCPUs go into the wait for SIPI state. */
+#ifdef VBOX_WITH_KVM
+                        /* In case the KVM split irq chip is used, KVM manages
+                         * the wait for SIPI state for us and we need to stay in
+                         * the NEM state. */
+                        pVCpu->em.s.enmState = EMSTATE_NEM;
+#else
                         pVCpu->em.s.enmState = EMSTATE_WAIT_SIPI;
+#endif
                     }
                     break;
                 }
diff --git a/src/VBox/VMM/VMMR3/GIMHv.cpp b/src/VBox/VMM/VMMR3/GIMHv.cpp
index 0452fac..116045b 100644
--- a/src/VBox/VMM/VMMR3/GIMHv.cpp
+++ b/src/VBox/VMM/VMMR3/GIMHv.cpp
@@ -34,6 +34,9 @@
 #include <VBox/vmm/gim.h>
 #include <VBox/vmm/cpum.h>
 #include <VBox/vmm/mm.h>
+#if defined(VBOX_WITH_KVM)
+#include <VBox/vmm/nem.h>
+#endif
 #include <VBox/vmm/ssm.h>
 #include <VBox/vmm/hm.h>
 #include <VBox/vmm/pdmapi.h>
@@ -236,7 +239,8 @@ VMMR3_INT_DECL(int) gimR3HvInit(PVM pVM, PCFGMNODE pGimCfg)
         int rc2 = CFGMR3ValidateConfig(pCfgHv, "/HyperV/",
                                   "VendorID"
                                   "|VSInterface"
-                                  "|HypercallDebugInterface",
+                                  "|HypercallDebugInterface"
+                                  "|VirtioGPU",
                                   "" /* pszValidNodes */, "GIM/HyperV" /* pszWho */, 0 /* uInstance */);
         if (RT_FAILURE(rc2))
             return rc2;
@@ -270,6 +274,51 @@ VMMR3_INT_DECL(int) gimR3HvInit(PVM pVM, PCFGMNODE pGimCfg)
     rc = CFGMR3QueryBoolDef(pCfgHv, "HypercallDebugInterface", &pHv->fDbgHypercallInterface, false);
     AssertLogRelRCReturn(rc, rc);
 
+#ifdef VBOX_WITH_KVM
+    uint32_t uKvmBaseFeat = 0;
+    uint32_t uKvmPartFlags = 0;
+    uint32_t uKvmPowMgmtFeat = 0;
+    uint32_t uKvmMiscFeat = 0;
+    uint32_t uKvmHyperHints = 0;
+
+    {
+        PCPUMCPUIDLEAF pKvmCpuidLeaves = nullptr;
+        size_t cKvmCpuidLeaves = 0;
+
+        rc = NEMR3KvmGetHvCpuIdLeaves(pVM, &pKvmCpuidLeaves, &cKvmCpuidLeaves);
+        AssertLogRelRCReturn(rc, rc);
+
+        for (size_t uLeaf = 0; uLeaf < cKvmCpuidLeaves; uLeaf++) {
+            LogRel(("GIM: KVM CPUID[%08x] eax=%08x ebx=%08x ecx=%08x edx=%08x\n",
+                    pKvmCpuidLeaves[uLeaf].uLeaf,
+                    pKvmCpuidLeaves[uLeaf].uEax, pKvmCpuidLeaves[uLeaf].uEbx,
+                    pKvmCpuidLeaves[uLeaf].uEcx, pKvmCpuidLeaves[uLeaf].uEdx));
+
+            /*
+              See this documentation for an overview of Hyper-V CPUID flags:
+              https://learn.microsoft.com/en-us/virtualization/hyper-v-on-windows/tlfs/feature-discovery
+             */
+
+            switch (pKvmCpuidLeaves[uLeaf].uLeaf) {
+            case 0x40000003: /* Features */
+                uKvmBaseFeat = pKvmCpuidLeaves[uLeaf].uEax;
+                uKvmPartFlags = pKvmCpuidLeaves[uLeaf].uEbx;
+                uKvmPowMgmtFeat = pKvmCpuidLeaves[uLeaf].uEcx;
+                uKvmMiscFeat = pKvmCpuidLeaves[uLeaf].uEdx;
+                break;
+            case 0x40000004: /* Implementation Recommendations */
+                uKvmHyperHints = pKvmCpuidLeaves[uLeaf].uEax;
+                break;
+            default:
+                // Ignore
+                break;
+            }
+        }
+
+        RTMemFree(pKvmCpuidLeaves);
+    }
+#endif
+
     /*
      * Determine interface capabilities based on the version.
      */
@@ -277,7 +326,11 @@ VMMR3_INT_DECL(int) gimR3HvInit(PVM pVM, PCFGMNODE pGimCfg)
     {
         /* Basic features. */
         pHv->uBaseFeat = 0
+#ifdef VBOX_WITH_KVM
+                       | GIM_HV_BASE_FEAT_VP_RUNTIME_MSR
+#else
                      //| GIM_HV_BASE_FEAT_VP_RUNTIME_MSR
+#endif
                        | GIM_HV_BASE_FEAT_PART_TIME_REF_COUNT_MSR
                      //| GIM_HV_BASE_FEAT_BASIC_SYNIC_MSRS          // Both required for synethetic timers
                      //| GIM_HV_BASE_FEAT_STIMER_MSRS               // Both required for synethetic timers
@@ -300,15 +353,40 @@ VMMR3_INT_DECL(int) gimR3HvInit(PVM pVM, PCFGMNODE pGimCfg)
                          | GIM_HV_MISC_FEAT_GUEST_CRASH_MSRS
                        //| GIM_HV_MISC_FEAT_DEBUG_MSRS
                          ;
-
+#ifdef VBOX_WITH_KVM
+        /* Hypervisor recommendations to the guest. */
+        pHv->uHyperHints = GIM_HV_HINT_RELAX_TIME_CHECKS
+                         /* Causes assertion failures in interrupt injection. */
+                       //| GIM_HV_HINT_MSR_FOR_APIC_ACCESS
+                         /* Inform the guest whether the host has hyperthreading disabled. */
+                         | (GIM_HV_HINT_NO_NONARCH_CORESHARING & uKvmHyperHints)
+                         ;
+#else
         /* Hypervisor recommendations to the guest. */
         pHv->uHyperHints = GIM_HV_HINT_MSR_FOR_SYS_RESET
                          | GIM_HV_HINT_RELAX_TIME_CHECKS
                          | GIM_HV_HINT_X2APIC_MSRS
                          ;
+#endif
+
+        bool withVirtioGPU {false};
+        rc = CFGMR3QueryBoolDef(pCfgHv, "VirtioGPU", &withVirtioGPU, false);
+
+        if (RT_SUCCESS(rc) and withVirtioGPU and pVM->cCpus > 8) {
+            LogRel(("Disabling the GIM_HV_HINT_X2APIC_MSRS HyperV hint because there are %d virtual CPUs and " \
+                    "the VirtioGPU is used as a graphics controller. More than 8 vCPUs are known to result in "
+                    "Windows10 not booting if the DVServerKMD driver is installed in the guest if the specific "
+                    "HyperV hint is set.\n", pVM->cCpus));
+            pHv->uHyperHints &= ~GIM_HV_HINT_X2APIC_MSRS;
+        }
 
         /* Partition features. */
+#ifdef VBOX_WITH_KVM
+        /* Extended hypercalls require KVM_EXIT_HYPER_HCALL exits to be forwarded gimHvHypercall.
+           So we don't expose them for now. */
+#else
         pHv->uPartFlags |= GIM_HV_PART_FLAGS_EXTENDED_HYPERCALLS;
+#endif
 
         /* Expose more if we're posing as Microsoft. We can, if needed, force MSR-based Hv
            debugging by not exposing these bits while exposing the VS interface. The better
@@ -320,6 +398,15 @@ VMMR3_INT_DECL(int) gimR3HvInit(PVM pVM, PCFGMNODE pGimCfg)
 
             pHv->uPartFlags |= GIM_HV_PART_FLAGS_DEBUGGING;
         }
+
+#ifdef VBOX_WITH_KVM
+        // We should not enable features and hints that KVM doesn't know about.
+        Assert((pHv->uHyperHints & ~uKvmHyperHints) == 0);
+        Assert((pHv->uBaseFeat & ~uKvmBaseFeat) == 0);
+        Assert((pHv->uMiscFeat & ~uKvmMiscFeat) == 0);
+        Assert((pHv->uPartFlags & ~uKvmPartFlags) == 0);
+        Assert((pHv->uPowMgmtFeat & ~uKvmPowMgmtFeat) == 0);
+#endif
     }
 
     /*
diff --git a/src/VBox/VMM/VMMR3/GIMHvOnKvm.cpp b/src/VBox/VMM/VMMR3/GIMHvOnKvm.cpp
new file mode 100644
index 0000000..362cc69
--- /dev/null
+++ b/src/VBox/VMM/VMMR3/GIMHvOnKvm.cpp
@@ -0,0 +1,640 @@
+/* $Id: GIMHvOnKvm.cpp $ */
+/** @file
+ * GIM - Guest Interface Manager, Hyper-V implementation for the KVM-Backend.
+ */
+
+/*
+ * Copyright (C) 2014-2023 Oracle and/or its affiliates.
+ *
+ * This file is part of VirtualBox base platform packages, as
+ * available from https://www.virtualbox.org.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation, in version 3 of the
+ * License.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, see <https://www.gnu.org/licenses>.
+ *
+ * SPDX-License-Identifier: GPL-3.0-only
+ */
+
+
+/*********************************************************************************************************************************
+*   Header Files                                                                                                                 *
+*********************************************************************************************************************************/
+#define LOG_GROUP LOG_GROUP_GIM
+#include <VBox/vmm/gim.h>
+#include <VBox/vmm/nem.h>
+#include <VBox/vmm/ssm.h>
+#include <VBox/vmm/hm.h>
+#include "GIMInternal.h"
+#include <VBox/vmm/vm.h>
+
+#include <VBox/err.h>
+#include <VBox/version.h>
+
+#include <iprt/assert.h>
+#include <iprt/string.h>
+#include <iprt/mem.h>
+
+/*********************************************************************************************************************************
+*   Defined Constants And Macros                                                                                                 *
+*********************************************************************************************************************************/
+/**
+ * GIM Hyper-V saved-state version.
+ *
+ * We use a number that is far away from the original GIMHv saved state version
+ * to prevent future collisions.
+ */
+#define GIM_HV_SAVED_STATE_VERSION                      UINT32_C(0x1000)
+
+#ifdef VBOX_WITH_STATISTICS
+# define GIMHV_MSRRANGE(a_uFirst, a_uLast, a_szName) \
+    { (a_uFirst), (a_uLast), kCpumMsrRdFn_Gim, kCpumMsrWrFn_Gim, 0, 0, 0, 0, 0, a_szName, { 0 }, { 0 }, { 0 }, { 0 } }
+#else
+# define GIMHV_MSRRANGE(a_uFirst, a_uLast, a_szName) \
+    { (a_uFirst), (a_uLast), kCpumMsrRdFn_Gim, kCpumMsrWrFn_Gim, 0, 0, 0, 0, 0, a_szName }
+#endif
+
+
+/*********************************************************************************************************************************
+*   Global Variables                                                                                                             *
+*********************************************************************************************************************************/
+/**
+ * Array of MSR ranges supported by Hyper-V.
+ */
+static CPUMMSRRANGE const g_aMsrRanges_HyperV[] =
+{
+    GIMHV_MSRRANGE(MSR_GIM_HV_RANGE0_FIRST,  MSR_GIM_HV_RANGE0_LAST,  "Hyper-V range 0"),
+    GIMHV_MSRRANGE(MSR_GIM_HV_RANGE1_FIRST,  MSR_GIM_HV_RANGE1_LAST,  "Hyper-V range 1"),
+    GIMHV_MSRRANGE(MSR_GIM_HV_RANGE2_FIRST,  MSR_GIM_HV_RANGE2_LAST,  "Hyper-V range 2"),
+    GIMHV_MSRRANGE(MSR_GIM_HV_RANGE3_FIRST,  MSR_GIM_HV_RANGE3_LAST,  "Hyper-V range 3"),
+    GIMHV_MSRRANGE(MSR_GIM_HV_RANGE4_FIRST,  MSR_GIM_HV_RANGE4_LAST,  "Hyper-V range 4"),
+    GIMHV_MSRRANGE(MSR_GIM_HV_RANGE5_FIRST,  MSR_GIM_HV_RANGE5_LAST,  "Hyper-V range 5"),
+    GIMHV_MSRRANGE(MSR_GIM_HV_RANGE6_FIRST,  MSR_GIM_HV_RANGE6_LAST,  "Hyper-V range 6"),
+    GIMHV_MSRRANGE(MSR_GIM_HV_RANGE7_FIRST,  MSR_GIM_HV_RANGE7_LAST,  "Hyper-V range 7"),
+    GIMHV_MSRRANGE(MSR_GIM_HV_RANGE8_FIRST,  MSR_GIM_HV_RANGE8_LAST,  "Hyper-V range 8"),
+    GIMHV_MSRRANGE(MSR_GIM_HV_RANGE9_FIRST,  MSR_GIM_HV_RANGE9_LAST,  "Hyper-V range 9"),
+    GIMHV_MSRRANGE(MSR_GIM_HV_RANGE10_FIRST, MSR_GIM_HV_RANGE10_LAST, "Hyper-V range 10"),
+    GIMHV_MSRRANGE(MSR_GIM_HV_RANGE11_FIRST, MSR_GIM_HV_RANGE11_LAST, "Hyper-V range 11"),
+    GIMHV_MSRRANGE(MSR_GIM_HV_RANGE12_FIRST, MSR_GIM_HV_RANGE12_LAST, "Hyper-V range 12")
+};
+#undef GIMHV_MSRRANGE
+
+/*********************************************************************************************************************************
+*   Internal Functions                                                                                                           *
+*********************************************************************************************************************************/
+
+/**
+ * Initializes the Hyper-V GIM provider.
+ *
+ * @returns VBox status code.
+ * @param   pVM         The cross context VM structure.
+ * @param   pGimCfg     The GIM CFGM node.
+ */
+VMMR3_INT_DECL(int) gimR3HvInit(PVM pVM, PCFGMNODE pGimCfg)
+{
+    AssertReturn(pVM, VERR_INVALID_PARAMETER);
+    AssertReturn(pVM->gim.s.enmProviderId == GIMPROVIDERID_HYPERV, VERR_INTERNAL_ERROR_5);
+
+    PGIMHV pHv = &pVM->gim.s.u.Hv;
+
+    /*
+     * Read configuration.
+     */
+    PCFGMNODE pCfgHv = CFGMR3GetChild(pGimCfg, "HyperV");
+    if (pCfgHv)
+    {
+        /*
+         * Validate the Hyper-V settings.
+         */
+        int rc2 = CFGMR3ValidateConfig(pCfgHv, "/HyperV/",
+                                  "VendorID"
+                                  "|VSInterface"
+                                  "|HypercallDebugInterface"
+                                  "|VirtioGPU",
+                                  "" /* pszValidNodes */, "GIM/HyperV" /* pszWho */, 0 /* uInstance */);
+        if (RT_FAILURE(rc2))
+            return rc2;
+    }
+
+    /**
+     * If virtio-gpu is in use, revert back to VBoxVBoxVBox as HyperV Vendor because otherwise,
+     * the Intel GPU driver does not load.
+     */
+    bool withVirtioGPU {false};
+    int rc = CFGMR3QueryBoolDef(pCfgHv, "VirtioGPU", &withVirtioGPU, false);
+    AssertLogRelRCReturn(rc, rc);
+
+    /** @cfgm{/GIM/HyperV/VendorID, string, 'VBoxVBoxVBox'}
+     * The Hyper-V vendor signature, must be 12 characters. */
+    char szVendor[13];
+    rc = CFGMR3QueryStringDef(pCfgHv, "VendorID", szVendor, sizeof(szVendor), withVirtioGPU ? "VBoxVBoxVBox" : "Microsoft Hv");
+    AssertLogRelRCReturn(rc, rc);
+    AssertLogRelMsgReturn(strlen(szVendor) == 12,
+                          ("The VendorID config value must be exactly 12 chars, '%s' isn't!\n", szVendor),
+                          VERR_INVALID_PARAMETER);
+
+    AssertReleaseMsg(!RTStrNCmp(szVendor, GIM_HV_VENDOR_MICROSOFT, sizeof(GIM_HV_VENDOR_MICROSOFT) - 1) ||
+                     !RTStrNCmp(szVendor, GIM_HV_VENDOR_VBOX, sizeof(GIM_HV_VENDOR_VBOX) - 1), (("GIM Vendors other than Microsoft Hv and VBox are unsupported")));
+
+    LogRel(("GIM: HyperV: Reporting vendor as '%s'\n", szVendor));
+
+    pHv->fIsInterfaceVs = false;
+    pHv->fDbgHypercallInterface = false;
+
+    uint32_t uKvmBaseFeat = 0;
+    uint32_t uKvmPartFlags = 0;
+    uint32_t uKvmPowMgmtFeat = 0;
+    uint32_t uKvmMiscFeat = 0;
+    uint32_t uKvmHyperHints = 0;
+
+    {
+        PCPUMCPUIDLEAF pKvmCpuidLeaves = nullptr;
+        size_t cKvmCpuidLeaves = 0;
+
+        rc = NEMR3KvmGetHvCpuIdLeaves(pVM, &pKvmCpuidLeaves, &cKvmCpuidLeaves);
+        AssertLogRelRCReturn(rc, rc);
+
+        for (size_t uLeaf = 0; uLeaf < cKvmCpuidLeaves; uLeaf++) {
+            LogRel(("GIM: KVM CPUID[%08x] eax=%08x ebx=%08x ecx=%08x edx=%08x\n",
+                    pKvmCpuidLeaves[uLeaf].uLeaf,
+                    pKvmCpuidLeaves[uLeaf].uEax, pKvmCpuidLeaves[uLeaf].uEbx,
+                    pKvmCpuidLeaves[uLeaf].uEcx, pKvmCpuidLeaves[uLeaf].uEdx));
+
+            /*
+              See this documentation for an overview of Hyper-V CPUID flags:
+              https://learn.microsoft.com/en-us/virtualization/hyper-v-on-windows/tlfs/feature-discovery
+             */
+
+            switch (pKvmCpuidLeaves[uLeaf].uLeaf) {
+            case 0x40000003: /* Features */
+                uKvmBaseFeat = pKvmCpuidLeaves[uLeaf].uEax;
+                uKvmPartFlags = pKvmCpuidLeaves[uLeaf].uEbx;
+                uKvmPowMgmtFeat = pKvmCpuidLeaves[uLeaf].uEcx;
+                uKvmMiscFeat = pKvmCpuidLeaves[uLeaf].uEdx;
+                break;
+            case 0x40000004: /* Implementation Recommendations */
+                uKvmHyperHints = pKvmCpuidLeaves[uLeaf].uEax;
+                break;
+            default:
+                // Ignore
+                break;
+            }
+        }
+
+        RTMemFree(pKvmCpuidLeaves);
+    }
+
+    /*
+     * Determine interface capabilities based on the version.
+     */
+    if (!pVM->gim.s.u32Version)
+    {
+        /* Basic features. */
+        pHv->uBaseFeat = 0
+                       | GIM_HV_BASE_FEAT_VP_RUNTIME_MSR
+                       | GIM_HV_BASE_FEAT_PART_TIME_REF_COUNT_MSR
+                       | GIM_HV_BASE_FEAT_BASIC_SYNIC_MSRS
+                       | GIM_HV_BASE_FEAT_STIMER_MSRS
+                       | GIM_HV_BASE_FEAT_APIC_ACCESS_MSRS
+                       | GIM_HV_BASE_FEAT_HYPERCALL_MSRS
+                       | GIM_HV_BASE_FEAT_VP_ID_MSR
+                       | GIM_HV_BASE_FEAT_VIRT_SYS_RESET_MSR
+                     //| GIM_HV_BASE_FEAT_STAT_PAGES_MSR
+                       | GIM_HV_BASE_FEAT_PART_REF_TSC_MSR
+                     //| GIM_HV_BASE_FEAT_GUEST_IDLE_STATE_MSR
+                       | GIM_HV_BASE_FEAT_TIMER_FREQ_MSRS
+                     //| GIM_HV_BASE_FEAT_DEBUG_MSRS
+                       ;
+
+        /* Miscellaneous features. */
+        pHv->uMiscFeat = 0
+                       //| GIM_HV_MISC_FEAT_GUEST_DEBUGGING
+                       //| GIM_HV_MISC_FEAT_XMM_HYPERCALL_INPUT
+                         | GIM_HV_MISC_FEAT_TIMER_FREQ
+                         | GIM_HV_MISC_FEAT_GUEST_CRASH_MSRS
+                       //| GIM_HV_MISC_FEAT_DEBUG_MSRS
+                         | GIM_HV_MISC_FEAT_USE_DIRECT_SYNTH_MSRS
+                         ;
+
+        /* Hypervisor recommendations to the guest. */
+        pHv->uHyperHints = GIM_HV_HINT_RELAX_TIME_CHECKS
+                         /* Causes assertion failures in interrupt injection. */
+                       //| GIM_HV_HINT_MSR_FOR_APIC_ACCESS
+                       //|GIM_HV_HINT_MSR_FOR_SYS_RESET
+                         | GIM_HV_HINT_DEPRECATE_AUTO_EOI
+                         /* Inform the guest whether the host has hyperthreading disabled. */
+                         | (GIM_HV_HINT_NO_NONARCH_CORESHARING & uKvmHyperHints)
+                         ;
+
+
+        // We should not enable features and hints that KVM doesn't know about.
+        AssertRelease((pHv->uHyperHints & ~uKvmHyperHints) == 0);
+        AssertRelease((pHv->uBaseFeat & ~uKvmBaseFeat) == 0);
+        AssertRelease((pHv->uMiscFeat & ~uKvmMiscFeat) == 0);
+        AssertRelease((pHv->uPartFlags & ~uKvmPartFlags) == 0);
+        AssertRelease((pHv->uPowMgmtFeat & ~uKvmPowMgmtFeat) == 0);
+    }
+
+    /*
+     * Make sure the CPUID bits are in accordance with the Hyper-V
+     * requirement and other paranoia checks.
+     * See "Requirements for implementing the Microsoft hypervisor interface" spec.
+     */
+    AssertRelease(!(pHv->uPartFlags & (  GIM_HV_PART_FLAGS_CREATE_PART
+                                        | GIM_HV_PART_FLAGS_ACCESS_MEMORY_POOL
+                                        | GIM_HV_PART_FLAGS_ACCESS_PART_ID
+                                        | GIM_HV_PART_FLAGS_ADJUST_MSG_BUFFERS
+                                        | GIM_HV_PART_FLAGS_CREATE_PORT
+                                        | GIM_HV_PART_FLAGS_ACCESS_STATS
+                                        | GIM_HV_PART_FLAGS_CPU_MGMT
+                                        | GIM_HV_PART_FLAGS_CPU_PROFILER)));
+
+    AssertRelease((pHv->uBaseFeat & (GIM_HV_BASE_FEAT_HYPERCALL_MSRS | GIM_HV_BASE_FEAT_VP_ID_MSR))
+            == (GIM_HV_BASE_FEAT_HYPERCALL_MSRS | GIM_HV_BASE_FEAT_VP_ID_MSR));
+
+    /*
+     * Expose HVP (Hypervisor Present) bit to the guest.
+     */
+    CPUMR3SetGuestCpuIdFeature(pVM, CPUMCPUIDFEATURE_HVP);
+
+    /*
+     * Modify the standard hypervisor leaves for Hyper-V.
+     */
+    CPUMCPUIDLEAF HyperLeaf;
+    RT_ZERO(HyperLeaf);
+    HyperLeaf.uLeaf = UINT32_C(0x40000000);
+    HyperLeaf.uEax  = UINT32_C(0x40000006); /* Minimum value for Hyper-V default is 0x40000005. */
+    /*
+     * Don't report vendor as 'Microsoft Hv'[1] by default, see @bugref{7270#c152}.
+     * [1]: ebx=0x7263694d ('rciM') ecx=0x666f736f ('foso') edx=0x76482074 ('vH t')
+     */
+    {
+        uint32_t uVendorEbx;
+        uint32_t uVendorEcx;
+        uint32_t uVendorEdx;
+        uVendorEbx = ((uint32_t)szVendor[ 3]) << 24 | ((uint32_t)szVendor[ 2]) << 16 | ((uint32_t)szVendor[1]) << 8
+                    | (uint32_t)szVendor[ 0];
+        uVendorEcx = ((uint32_t)szVendor[ 7]) << 24 | ((uint32_t)szVendor[ 6]) << 16 | ((uint32_t)szVendor[5]) << 8
+                    | (uint32_t)szVendor[ 4];
+        uVendorEdx = ((uint32_t)szVendor[11]) << 24 | ((uint32_t)szVendor[10]) << 16 | ((uint32_t)szVendor[9]) << 8
+                    | (uint32_t)szVendor[ 8];
+        HyperLeaf.uEbx         = uVendorEbx;
+        HyperLeaf.uEcx         = uVendorEcx;
+        HyperLeaf.uEdx         = uVendorEdx;
+    }
+    rc = CPUMR3CpuIdInsert(pVM, &HyperLeaf);
+    AssertLogRelRCReturn(rc, rc);
+
+    HyperLeaf.uLeaf        = UINT32_C(0x40000001);
+    HyperLeaf.uEax         = 0x31237648;           /* 'Hv#1' */
+    HyperLeaf.uEbx         = 0;                    /* Reserved */
+    HyperLeaf.uEcx         = 0;                    /* Reserved */
+    HyperLeaf.uEdx         = 0;                    /* Reserved */
+    rc = CPUMR3CpuIdInsert(pVM, &HyperLeaf);
+    AssertLogRelRCReturn(rc, rc);
+
+    /*
+     * Add Hyper-V specific leaves.
+     */
+    HyperLeaf.uLeaf        = UINT32_C(0x40000002); /* MBZ until MSR_GIM_HV_GUEST_OS_ID is set by the guest. */
+    HyperLeaf.uEax         = 0;
+    HyperLeaf.uEbx         = 0;
+    HyperLeaf.uEcx         = 0;
+    HyperLeaf.uEdx         = 0;
+    rc = CPUMR3CpuIdInsert(pVM, &HyperLeaf);
+    AssertLogRelRCReturn(rc, rc);
+
+    HyperLeaf.uLeaf        = UINT32_C(0x40000003);
+    HyperLeaf.uEax         = pHv->uBaseFeat;
+    HyperLeaf.uEbx         = pHv->uPartFlags;
+    HyperLeaf.uEcx         = pHv->uPowMgmtFeat;
+    HyperLeaf.uEdx         = pHv->uMiscFeat;
+    rc = CPUMR3CpuIdInsert(pVM, &HyperLeaf);
+    AssertLogRelRCReturn(rc, rc);
+
+    HyperLeaf.uLeaf        = UINT32_C(0x40000004);
+    HyperLeaf.uEax         = pHv->uHyperHints;
+    /* Recommended number of spinlock retries before notifying the Hypervisor. 0xffffffff means that the Hypervisor is never notified */
+    HyperLeaf.uEbx         = 0xffffffff;
+    HyperLeaf.uEcx         = 0;
+    HyperLeaf.uEdx         = 0;
+    rc = CPUMR3CpuIdInsert(pVM, &HyperLeaf);
+    AssertLogRelRCReturn(rc, rc);
+
+    RT_ZERO(HyperLeaf);
+    HyperLeaf.uLeaf        = UINT32_C(0x40000005);
+    rc = CPUMR3CpuIdInsert(pVM, &HyperLeaf);
+    AssertLogRelRCReturn(rc, rc);
+
+    // Let the guest OS know that we're running HyperV PV on KVM.
+    static constexpr char kvmVendor[] = "KVMKVMKVM\0\0\0";
+    HyperLeaf.uLeaf = 0x40000100;
+    {
+        uint32_t uVendorEbx;
+        uint32_t uVendorEcx;
+        uint32_t uVendorEdx;
+        uVendorEbx = ((uint32_t)kvmVendor[ 3]) << 24 | ((uint32_t)kvmVendor[ 2]) << 16 | ((uint32_t)kvmVendor[1]) << 8
+            | (uint32_t)kvmVendor[ 0];
+        uVendorEcx = ((uint32_t)kvmVendor[ 7]) << 24 | ((uint32_t)kvmVendor[ 6]) << 16 | ((uint32_t)kvmVendor[5]) << 8
+            | (uint32_t)kvmVendor[ 4];
+        uVendorEdx = ((uint32_t)kvmVendor[11]) << 24 | ((uint32_t)kvmVendor[10]) << 16 | ((uint32_t)kvmVendor[9]) << 8
+            | (uint32_t)kvmVendor[ 8];
+        HyperLeaf.uEbx = uVendorEbx;
+        HyperLeaf.uEcx = uVendorEcx;
+        HyperLeaf.uEdx = uVendorEdx;
+    }
+
+    rc = CPUMR3CpuIdInsert(pVM, &HyperLeaf);
+    AssertLogRelRCReturn(rc, rc);
+
+
+    /*
+     * Insert all MSR ranges of Hyper-V.
+     */
+    for (unsigned i = 0; i < RT_ELEMENTS(g_aMsrRanges_HyperV); i++)
+    {
+        int rc2 = CPUMR3MsrRangesInsert(pVM, &g_aMsrRanges_HyperV[i]);
+        AssertLogRelRCReturn(rc2, rc2);
+    }
+
+    /*
+     * Setup non-zero MSRs.
+     */
+    if (pHv->uMiscFeat & GIM_HV_MISC_FEAT_GUEST_CRASH_MSRS)
+        pHv->uCrashCtlMsr = MSR_GIM_HV_CRASH_CTL_NOTIFY;
+
+    return VINF_SUCCESS;
+}
+
+
+/**
+ * Initializes remaining bits of the Hyper-V provider.
+ *
+ * This is called after initializing HM and almost all other VMM components.
+ *
+ * @returns VBox status code.
+ * @param   pVM     The cross context VM structure.
+ */
+VMMR3_INT_DECL(int) gimR3HvInitCompleted(PVM pVM)
+{
+    PGIMHV pHv = &pVM->gim.s.u.Hv;
+    pHv->cTscTicksPerSecond = TMCpuTicksPerSecond(pVM);
+
+    /*
+     * Determine interface capabilities based on the version.
+     */
+    if (!pVM->gim.s.u32Version)
+    {
+        /* Hypervisor capabilities; features used by the hypervisor. */
+        pHv->uHyperCaps  = HMIsNestedPagingActive(pVM) ? GIM_HV_HOST_FEAT_NESTED_PAGING : 0;
+        pHv->uHyperCaps |= HMIsMsrBitmapActive(pVM)    ? GIM_HV_HOST_FEAT_MSR_BITMAP    : 0;
+    }
+
+    CPUMCPUIDLEAF HyperLeaf;
+    RT_ZERO(HyperLeaf);
+    HyperLeaf.uLeaf        = UINT32_C(0x40000006);
+    HyperLeaf.uEax         = pHv->uHyperCaps;
+    HyperLeaf.uEbx         = 0;
+    HyperLeaf.uEcx         = 0;
+    HyperLeaf.uEdx         = 0;
+    int rc = CPUMR3CpuIdInsert(pVM, &HyperLeaf);
+    AssertLogRelRCReturn(rc, rc);
+
+    return rc;
+}
+
+
+/**
+ * Terminates the Hyper-V GIM provider.
+ *
+ * @returns VBox status code.
+ * @param   pVM         The cross context VM structure.
+ */
+VMMR3_INT_DECL(int) gimR3HvTerm(PVM pVM)
+{
+    gimR3HvReset(pVM);
+
+    return VINF_SUCCESS;
+}
+
+
+/**
+ * Applies relocations to data and code managed by this
+ * component. This function will be called at init and
+ * whenever the VMM need to relocate it self inside the GC.
+ *
+ * @param   pVM         The cross context VM structure.
+ * @param   offDelta    Relocation delta relative to old location.
+ */
+VMMR3_INT_DECL(void) gimR3HvRelocate(PVM pVM, RTGCINTPTR offDelta)
+{
+    RT_NOREF(pVM, offDelta);
+}
+
+
+static bool isSynICAllowed(PGIMHV pHv)
+{
+    return pHv->uBaseFeat & GIM_HV_BASE_FEAT_BASIC_SYNIC_MSRS;
+}
+
+/**
+ * This resets Hyper-V provider MSRs and unmaps whatever Hyper-V regions that
+ * the guest may have mapped.
+ *
+ * This is called when the VM is being reset.
+ *
+ * @param   pVM     The cross context VM structure.
+ *
+ * @thread  EMT(0)
+ */
+VMMR3_INT_DECL(void) gimR3HvReset(PVM pVM)
+{
+    VM_ASSERT_EMT0(pVM);
+
+    /*
+     * Unmap MMIO2 pages that the guest may have setup.
+     */
+    LogRel(("GIM: HyperV: Resetting MMIO2 regions and MSRs\n"));
+    PGIMHV pHv = &pVM->gim.s.u.Hv;
+
+    /*
+     * Reset MSRs.
+     */
+    pHv->u64GuestOsIdMsr      = 0;
+    pHv->u64HypercallMsr      = 0;
+    pHv->u64TscPageMsr        = 0;
+    pHv->uCrashP0Msr          = 0;
+    pHv->uCrashP1Msr          = 0;
+    pHv->uCrashP2Msr          = 0;
+    pHv->uCrashP3Msr          = 0;
+    pHv->uCrashP4Msr          = 0;
+    pHv->uDbgStatusMsr        = 0;
+    pHv->uDbgPendingBufferMsr = 0;
+    pHv->uDbgSendBufferMsr    = 0;
+    pHv->uDbgRecvBufferMsr    = 0;
+
+    PVMCPU pVCpuBsp = pVM->apCpusR3[0];
+    NEMR3KvmSetMsr(pVCpuBsp, MSR_GIM_HV_GUEST_OS_ID, pHv->u64GuestOsIdMsr);
+    NEMR3KvmSetMsr(pVCpuBsp, MSR_GIM_HV_HYPERCALL, pHv->u64HypercallMsr);
+    NEMR3KvmSetMsr(pVCpuBsp, MSR_GIM_HV_REF_TSC, pHv->u64TscPageMsr);
+    NEMR3KvmSetMsr(pVCpuBsp, MSR_GIM_HV_SYNTH_DEBUG_STATUS, pHv->uDbgStatusMsr);
+    NEMR3KvmSetMsr(pVCpuBsp, MSR_GIM_HV_SYNTH_DEBUG_PENDING_BUFFER, pHv->uDbgPendingBufferMsr);
+    NEMR3KvmSetMsr(pVCpuBsp, MSR_GIM_HV_SYNTH_DEBUG_SEND_BUFFER, pHv->uDbgSendBufferMsr);
+    NEMR3KvmSetMsr(pVCpuBsp, MSR_GIM_HV_SYNTH_DEBUG_RECEIVE_BUFFER, pHv->uDbgRecvBufferMsr);
+
+    for (VMCPUID idCpu = 0; idCpu < pVM->cCpus; idCpu++)
+    {
+        PGIMHVCPU pHvCpu = &pVM->apCpusR3[idCpu]->gim.s.u.HvCpu;
+        PVMCPU pVCpu = pVM->apCpusR3[idCpu];
+
+        pHvCpu->uSControlMsr = 0;
+        pHvCpu->uSimpMsr  = 0;
+        pHvCpu->uSiefpMsr = 0;
+        pHvCpu->uApicAssistPageMsr = 0;
+
+        NEMR3KvmSetMsr(pVCpu, MSR_GIM_HV_SCONTROL, pHvCpu->uSControlMsr);
+        NEMR3KvmSetMsr(pVCpu, MSR_GIM_HV_SIMP, pHvCpu->uSimpMsr);
+        NEMR3KvmSetMsr(pVCpu, MSR_GIM_HV_SIEFP, pHvCpu->uSiefpMsr);
+        NEMR3KvmSetMsr(pVCpu, MSR_GIM_HV_APIC_ASSIST_PAGE, pHvCpu->uApicAssistPageMsr);
+
+        for (uint8_t idxSint = 0; idxSint < RT_ELEMENTS(pHvCpu->auSintMsrs); idxSint++) {
+            pHvCpu->auSintMsrs[idxSint] = MSR_GIM_HV_SINT_MASKED;
+            if (isSynICAllowed(pHv)) {
+                NEMR3KvmSetMsr(pVCpu, MSR_GIM_HV_SINT0 + idxSint, pHvCpu->auSintMsrs[idxSint]);
+            }
+        }
+
+        for (uint8_t idxStimer = 0; idxStimer < RT_ELEMENTS(pHvCpu->aStimers); idxStimer++)
+        {
+            PGIMHVSTIMER pHvStimer = &pHvCpu->aStimers[idxStimer];
+            pHvStimer->uStimerConfigMsr = 0;
+            pHvStimer->uStimerCountMsr  = 0;
+            NEMR3KvmSetMsr(pVCpu, MSR_GIM_HV_STIMER0_CONFIG + idxStimer, pHvStimer->uStimerConfigMsr);
+            NEMR3KvmSetMsr(pVCpu, MSR_GIM_HV_STIMER0_COUNT + idxStimer, pHvStimer->uStimerCountMsr);
+        }
+    }
+}
+
+
+/**
+ * Hyper-V state-load operation, final pass.
+ *
+ * @returns VBox status code.
+ * @param   pVM             The cross context VM structure.
+ * @param   pSSM            The saved state handle.
+ */
+VMMR3_INT_DECL(int) gimR3HvLoad(PVM pVM, PSSMHANDLE pSSM)
+{
+    uint32_t uHvSavedStateVersion;
+    int rc = SSMR3GetU32(pSSM, &uHvSavedStateVersion);
+    AssertRCReturn(rc, rc);
+
+    if (uHvSavedStateVersion != GIM_HV_SAVED_STATE_VERSION) {
+        return SSMR3SetLoadError(pSSM, VERR_SSM_UNSUPPORTED_DATA_UNIT_VERSION, RT_SRC_POS,
+                                 N_("Unsupported Hyper-V saved-state version %u (current %u)!"),
+                                 uHvSavedStateVersion, GIM_HV_SAVED_STATE_VERSION);
+    }
+
+    for (unsigned i = 0; i < RT_ELEMENTS(g_aMsrRanges_HyperV); i++) {
+        for (unsigned msr {g_aMsrRanges_HyperV[i].uFirst}; msr <= g_aMsrRanges_HyperV[i].uLast; ++msr) {
+
+            // See gimR3HvSave to understand why we skip this MSR.
+            if (msr == MSR_GIM_HV_EOI) {
+                continue;
+            }
+
+            uint64_t val {0};
+            PVMCPU pVCpu = pVM->apCpusR3[0];
+
+            SSMR3GetU64(pSSM, &val);
+
+            rc = NEMR3KvmSetMsr(pVCpu, msr, val);
+            if (rc != VINF_SUCCESS) {
+                // Some MSRs can only be written when HYPERV_SYINC2 has been enabled.
+                // We don't actually care here because if we unable to write the MSR,
+                // the guest couldn't have read/written it either.
+                LogRel2(("Unable to read HV MSR: 0x%x\n", msr));
+            }
+        }
+    }
+
+    return VINF_SUCCESS;
+}
+
+
+/**
+ * Hyper-V load-done callback.
+ *
+ * @returns VBox status code.
+ * @param   pVM             The cross context VM structure.
+ * @param   pSSM            The saved state handle.
+ */
+VMMR3_INT_DECL(int) gimR3HvLoadDone(PVM pVM, PSSMHANDLE pSSM)
+{
+    NOREF(pVM); NOREF(pSSM);
+    return VINF_SUCCESS;
+}
+
+/**
+ * Hyper-V state-save operation.
+ *
+ * @returns VBox status code.
+ * @param   pVM     The cross context VM structure.
+ * @param   pSSM    The saved state handle.
+ */
+VMMR3_INT_DECL(int) gimR3HvSave(PVM pVM, PSSMHANDLE pSSM)
+{
+    /*
+     * Save the Hyper-V SSM version.
+     */
+    SSMR3PutU32(pSSM, GIM_HV_SAVED_STATE_VERSION);
+
+    for (unsigned i = 0; i < RT_ELEMENTS(g_aMsrRanges_HyperV); i++) {
+        for (unsigned msr {g_aMsrRanges_HyperV[i].uFirst}; msr <= g_aMsrRanges_HyperV[i].uLast; ++msr) {
+
+            // This register is wirte-only for the guest and the last value written isn't interesting at all.
+            // Thus, there is no need save it here.
+            if (msr == MSR_GIM_HV_EOI) {
+                continue;
+            }
+
+            uint64_t val {0};
+            PVMCPU pVCpu = pVM->apCpusR3[0];
+
+            int rc {NEMR3KvmGetMsr(pVCpu, msr, &val)};
+            if (rc != VINF_SUCCESS) {
+                // Some MSRs can only be read when HYPERV_SYINC2 has been enabled.
+                // We don't actually care here because if we unable to read the MSR,
+                // the guest couldn't have read/written it either. Simply save it as
+                // zero and call it good.
+                LogRel2(("Unable to read HV MSR: 0x%x\n", msr));
+            }
+
+            SSMR3PutU64(pSSM, val);
+        }
+    }
+
+    return VINF_SUCCESS;
+}
+
+/**
+ * Get Hyper-V debug setup parameters.
+ *
+ * @returns VBox status code.
+ * @param   pVM         The cross context VM structure.
+ * @param   pDbgSetup   Where to store the debug setup details.
+ */
+VMMR3_INT_DECL(int) gimR3HvGetDebugSetup(PVM pVM, PGIMDEBUGSETUP pDbgSetup)
+{
+    NOREF(pVM); NOREF(pDbgSetup);
+    return VERR_GIM_NO_DEBUG_CONNECTION;
+}
diff --git a/src/VBox/VMM/VMMR3/NEMR3Native-linux.cpp b/src/VBox/VMM/VMMR3/NEMR3Native-linux.cpp
index fa73141..cb43dd2 100644
--- a/src/VBox/VMM/VMMR3/NEMR3Native-linux.cpp
+++ b/src/VBox/VMM/VMMR3/NEMR3Native-linux.cpp
@@ -37,21 +37,31 @@
 #include <VBox/vmm/apic.h>
 #include <VBox/vmm/pdm.h>
 #include <VBox/vmm/trpm.h>
+#include "CPUMInternal.h"
 #include "NEMInternal.h"
+#include "HMInternal.h"
+#include "GIMInternal.h"
+#include "GIMHvInternal.h"
 #include <VBox/vmm/vmcc.h>
 
 #include <iprt/alloca.h>
+#include <iprt/mem.h>
 #include <iprt/string.h>
 #include <iprt/system.h>
 #include <iprt/x86.h>
 
 #include <errno.h>
 #include <unistd.h>
+#include <signal.h>
 #include <sys/ioctl.h>
 #include <sys/fcntl.h>
 #include <sys/mman.h>
+#include <sys/prctl.h>
 #include <linux/kvm.h>
 
+#include <algorithm>
+#include <vector>
+
 /*
  * Supply stuff missing from the kvm.h on the build box.
  */
@@ -59,7 +69,19 @@
 # define KVM_INTERNAL_ERROR_UNEXPECTED_EXIT_REASON 4
 #endif
 
+/**
+ * The MMIO address of the TPR register of the LAPIC.
+ */
+static constexpr uint64_t XAPIC_TPR_ADDR {0xfee00080};
+
+/**
+ * The class priority shift for the TPR register.
+ */
+static constexpr uint64_t LAPIC_TPR_SHIFT {4};
 
+#ifdef VBOX_WITH_KVM_IRQCHIP_FULL
+static int kvmSetGsiRoutingFullIrqChip(PVM pVM);
+#endif
 
 /**
  * Worker for nemR3NativeInit that gets the hypervisor capabilities.
@@ -439,6 +461,23 @@ static int nemR3LnxInitSetupVm(PVM pVM, PRTERRINFO pErrInfo)
     if (rcLnx == -1)
         return RTErrInfoSetF(pErrInfo, VERR_NEM_VM_CREATE_FAILED, "Failed to enable KVM_CAP_X86_USER_SPACE_MSR failed: %u", errno);
 
+#ifdef VBOX_WITH_KVM_IRQCHIP_FULL
+    rcLnx = ioctl(pVM->nem.s.fdVm, KVM_CREATE_IRQCHIP, 0);
+    if (rcLnx == -1)
+        return RTErrInfoSetF(pErrInfo, VERR_NEM_VM_CREATE_FAILED, "Failed to execute KVM_CREATE_VCPU: %u", errno);
+
+    kvmSetGsiRoutingFullIrqChip(pVM);
+#else
+    struct kvm_enable_cap CapSplitIrqChip =
+    {
+        KVM_CAP_SPLIT_IRQCHIP, 0,
+        { KVM_IRQCHIP_NUM_IOAPIC_INTR_PINS, 0, 0, 0}
+    };
+    rcLnx = ioctl(pVM->nem.s.fdVm, KVM_ENABLE_CAP, &CapSplitIrqChip);
+    if (rcLnx == -1)
+        return RTErrInfoSetF(pErrInfo, VERR_NEM_VM_CREATE_FAILED, "Failed to enable KVM_CAP_SPLIT_IRQCHIP: %u", errno);
+#endif
+
     /*
      * Create the VCpus.
      */
@@ -460,19 +499,118 @@ static int nemR3LnxInitSetupVm(PVM pVM, PRTERRINFO pErrInfo)
         /* We want all x86 registers and events on each exit. */
         pVCpu->nem.s.pRun->kvm_valid_regs = KVM_SYNC_X86_REGS | KVM_SYNC_X86_SREGS | KVM_SYNC_X86_EVENTS;
     }
+
+    pVM->nem.s.pARedirectionTable = std::make_unique<std::array<std::optional<MSIMSG>, KVM_IRQCHIP_NUM_IOAPIC_INTR_PINS>>();
+
+    return VINF_SUCCESS;
+}
+
+static VBOXSTRICTRC nemR3LnxSetVCpuSignalMask(PVMCPU pVCpu, sigset_t *pSigset)
+{
+    /*
+     * glibc and Linux/KVM do not agree on the size of sigset_t.
+     */
+    constexpr size_t kernel_sigset_size = 8;
+
+    alignas(kvm_signal_mask) char backing[sizeof(kvm_signal_mask) + kernel_sigset_size];
+    kvm_signal_mask *pKvmSignalMask = reinterpret_cast<kvm_signal_mask *>(backing);
+
+    static_assert(sizeof(sigset_t) >= kernel_sigset_size);
+
+    pKvmSignalMask->len = kernel_sigset_size;
+    memcpy(pKvmSignalMask->sigset, pSigset, kernel_sigset_size);
+
+    int rc = ioctl(pVCpu->nem.s.fdVCpu, KVM_SET_SIGNAL_MASK, pKvmSignalMask);
+    AssertLogRelMsgReturn(rc == 0, ("Failed to set vCPU signal mask: %d", errno),
+                          VERR_NEM_INIT_FAILED);
+
     return VINF_SUCCESS;
 }
 
+static void nemR3LnxConsumePokeSignal()
+{
+    int iPokeSignal = RTThreadPokeSignal();
+    AssertReturnVoid(iPokeSignal >= 0);
+
+    sigset_t sigset;
+    sigemptyset(&sigset);
+    sigaddset(&sigset, iPokeSignal);
+
+    struct timespec timeout;
+
+    /* Don't wait for a signal, just poll. */
+    timeout.tv_sec = 0;
+    timeout.tv_nsec = 0;
+
+    int rc = sigtimedwait(&sigset, nullptr, &timeout);
+    AssertLogRelMsg(rc >= 0 || errno == EAGAIN || errno == EINTR, ("Failed to consume signal: %d", errno));
+}
 
 /** @callback_method_impl{FNVMMEMTRENDEZVOUS}   */
 static DECLCALLBACK(VBOXSTRICTRC) nemR3LnxFixThreadPoke(PVM pVM, PVMCPU pVCpu, void *pvUser)
 {
     RT_NOREF(pVM, pvUser);
-    int rc = RTThreadControlPokeSignal(pVCpu->hThread, true /*fEnable*/);
+
+    int iPokeSignal = RTThreadPokeSignal();
+    AssertReturn(iPokeSignal >= 0, VERR_NEM_INIT_FAILED);
+
+    /* We disable the poke signal for the host. We never want that signal to be delivered. */
+    int rc = RTThreadControlPokeSignal(pVCpu->hThread, false /*fEnable*/);
     AssertLogRelRC(rc);
+
+    sigset_t sigset;
+
+    /* Fetch the current signal mask. */
+    int rcProcMask = pthread_sigmask(SIG_BLOCK /* ignored */, nullptr, &sigset);
+    AssertLogRelMsgReturn(rcProcMask == 0, ("Failed to retrieve thread signal mask"), VERR_NEM_INIT_FAILED);
+
+    sigdelset(&sigset, iPokeSignal);
+
+    /* We enable the poke signal for the vCPU. Any poke will kick the vCPU out of guest execution. */
+    VBOXSTRICTRC rcVcpuMask = nemR3LnxSetVCpuSignalMask(pVCpu, &sigset);
+    AssertRCSuccessReturn(rcVcpuMask, rcVcpuMask);
+
+    /* Create a timer that delivers the poke signal. */
+    struct sigevent sev {};
+
+    sev.sigev_notify = SIGEV_THREAD_ID;
+    sev.sigev_signo = iPokeSignal;
+    sev._sigev_un._tid = gettid();
+
+    int rcTimer = timer_create(CLOCK_MONOTONIC, &sev, &pVCpu->nem.s.pTimer);
+    AssertLogRelMsgReturn(rcTimer == 0, ("Failed to create timer: %d", errno), VERR_NEM_INIT_FAILED);
+
     return VINF_SUCCESS;
 }
 
+/**
+ * Check common environment problems and inform the user about misconfigurations.
+ */
+int nemR3CheckEnvironment(void)
+{
+    static const char szSplitLockMitigationFile[] = "/proc/sys/kernel/split_lock_mitigate";
+
+    char buf[64] {};
+    int fd = open(szSplitLockMitigationFile, O_RDONLY | O_CLOEXEC);
+
+    // Older kernels might not have this. A hard error feels unjustified here.
+    AssertLogRelMsgReturn(fd >= 0, ("Failed to check %s (%d). Assuming there is no problem.\n", szSplitLockMitigationFile, fd),
+                          VINF_SUCCESS);
+
+    /* Leave one character to ensure that the string is zero-terminated. */
+    ssize_t bytes = read(fd, buf, sizeof(buf) - 1);
+    AssertLogRelMsgReturn(bytes >= 0, ("Failed to read %s (%zd)\n", szSplitLockMitigationFile, bytes),
+                          VERR_NEM_INIT_FAILED);
+
+    int mitigationStatus = atoi(buf);
+
+    if (mitigationStatus != 0) {
+        LogRel(("NEM: WARNING: %s is %d. This can cause VM hangs, unless you set split_lock_detect=off on the host kernel command line! Please set it to 0.\n",
+                szSplitLockMitigationFile, mitigationStatus));
+    }
+
+    return VINF_SUCCESS;
+}
 
 /**
  * Try initialize the native API.
@@ -490,6 +628,10 @@ static DECLCALLBACK(VBOXSTRICTRC) nemR3LnxFixThreadPoke(PVM pVM, PVMCPU pVCpu, v
 int nemR3NativeInit(PVM pVM, bool fFallback, bool fForced)
 {
     RT_NOREF(pVM, fFallback, fForced);
+
+    int rcCheck = nemR3CheckEnvironment();
+    AssertLogRelMsgReturn(RT_SUCCESS(rcCheck), ("Failed to check environment\n"), VERR_NEM_INIT_FAILED);
+
     /*
      * Some state init.
      */
@@ -600,7 +742,7 @@ int nemR3NativeInit(PVM pVM, bool fFallback, bool fForced)
     else if (errno == EACCES)
         rc = RTErrInfoSet(pErrInfo, VERR_ACCESS_DENIED, "Do not have access to open /dev/kvm for reading & writing.");
     else if (errno == ENOENT)
-        rc = RTErrInfoSet(pErrInfo, VERR_NOT_SUPPORTED, "KVM is not availble (/dev/kvm does not exist)");
+        rc = RTErrInfoSet(pErrInfo, VERR_NOT_SUPPORTED, "KVM is not available (/dev/kvm does not exist)");
     else
         rc = RTErrInfoSetF(pErrInfo, RTErrConvertFromErrno(errno), "Failed to open '/dev/kvm': %u", errno);
 
@@ -636,6 +778,83 @@ int nemR3NativeInitAfterCPUM(PVM pVM)
     return VINF_SUCCESS;
 }
 
+static PCPUMCPUIDLEAF findKvmLeaf(PCPUMCPUIDLEAF paKvmSupportedLeaves,
+                                  uint32_t cKvmSupportedLeaves,
+                                  uint32_t leaf,
+                                  uint32_t subleaf)
+{
+    for (uint32_t i = 0; i < cKvmSupportedLeaves; i++) {
+        auto& kvmLeaf = paKvmSupportedLeaves[i];
+
+        if (kvmLeaf.uLeaf == leaf && kvmLeaf.uSubLeaf == subleaf) {
+            return &kvmLeaf;
+        }
+    }
+
+    return nullptr;
+}
+
+static void maybeMaskUnsupportedKVMCpuidLeafValues(PCPUMCPUIDLEAF paKvmSupportedLeaves,
+                                                   uint32_t cKvmSupportedLeaves,
+                                                   uint32_t leaf,
+                                                   uint32_t subleaf,
+                                                   uint32_t& eax,
+                                                   uint32_t& ebx,
+                                                   uint32_t& ecx,
+                                                   uint32_t& edx)
+{
+    static const uint32_t CPUID_FEATURE_INFORMATION_LEAF = 0x1;
+
+    /*
+     * A list of CPUID leaves that we want to mask with the KVM
+     * supported values. For example, we want to make sure that FSGSBASE
+     * support is supported by KVM before we offer it to the guest.
+     * VirtualBox detects the features it wants to offer via CPUID,
+     * which bypasses Linux/KVM.
+     */
+    const std::vector<uint32_t> leavesToMask = {
+        CPUID_FEATURE_INFORMATION_LEAF,
+        0x6,        // Thermal and power management
+        0x7,        // Structured Extended Feature Flags Enumeration
+        0x12,       // SGX capabilities
+        0x14,       // Processor Trace
+        0x19,       // AES Key Locker features
+        0x24,       // AVX10 Features
+        0x80000001, // Extended Processor Info and Feature Bits
+        0x80000007, // Processor Power Management Information and RAS Capabilities
+        0x80000008, // Virtual and Physical address Sizes
+        0x8000000A, // Secure Virtual Machine features
+        0x8000001F, // Encrypted Memory Capabilities
+        0x80000021, // Extended Feature Identification 2
+    };
+
+    if (std::find(leavesToMask.begin(), leavesToMask.end(), leaf) == leavesToMask.end()) {
+        return;
+    }
+
+    auto* paKvmSupportedLeaf = findKvmLeaf(paKvmSupportedLeaves, cKvmSupportedLeaves, leaf, subleaf);
+
+    if (paKvmSupportedLeaf == nullptr) {
+        return;
+    }
+
+    switch (leaf) {
+    case CPUID_FEATURE_INFORMATION_LEAF:
+        eax &= paKvmSupportedLeaf->uEax;
+        // ebx reports APIC IDs which we would mask if we use the
+        // KVM supported values.
+        ecx &= paKvmSupportedLeaf->uEcx;
+        ecx |= X86_CPUID_FEATURE_ECX_HVP; // The hypervisor bit is not enabled in the KVM values.
+        edx &= paKvmSupportedLeaf->uEdx;
+        break;
+    default:
+        eax &= paKvmSupportedLeaf->uEax;
+        ebx &= paKvmSupportedLeaf->uEbx;
+        ecx &= paKvmSupportedLeaf->uEcx;
+        edx &= paKvmSupportedLeaf->uEdx;
+        break;
+    }
+}
 
 /**
  * Update the CPUID leaves for a VCPU.
@@ -654,6 +873,12 @@ static int nemR3LnxUpdateCpuIdsLeaves(PVM pVM, PVMCPU pVCpu)
     pReq->nent    = cLeaves;
     pReq->padding = 0;
 
+    size_t cKvmSupportedLeaves = 0;
+    PCPUMCPUIDLEAF paKvmSupportedLeaves = nullptr;
+    int rc = NEMR3KvmGetCpuIdLeaves(pVM, &paKvmSupportedLeaves, &cKvmSupportedLeaves);
+    AssertLogRelMsgReturn(RT_SUCCESS(rc), ("Could not retrieve supported CPUID leaves"), rc);
+
+
     for (uint32_t i = 0; i < cLeaves; i++)
     {
         CPUMGetGuestCpuId(pVCpu, paLeaves[i].uLeaf, paLeaves[i].uSubLeaf, -1 /*f64BitMode*/,
@@ -661,6 +886,16 @@ static int nemR3LnxUpdateCpuIdsLeaves(PVM pVM, PVMCPU pVCpu)
                           &pReq->entries[i].ebx,
                           &pReq->entries[i].ecx,
                           &pReq->entries[i].edx);
+
+        maybeMaskUnsupportedKVMCpuidLeafValues(paKvmSupportedLeaves,
+                                               cKvmSupportedLeaves,
+                                               paLeaves[i].uLeaf,
+                                               paLeaves[i].uSubLeaf,
+                                               pReq->entries[i].eax,
+                                               pReq->entries[i].ebx,
+                                               pReq->entries[i].ecx,
+                                               pReq->entries[i].edx);
+
         pReq->entries[i].function   = paLeaves[i].uLeaf;
         pReq->entries[i].index      = paLeaves[i].uSubLeaf;
         pReq->entries[i].flags      = !paLeaves[i].fSubLeafMask ? 0 : KVM_CPUID_FLAG_SIGNIFCANT_INDEX;
@@ -675,6 +910,111 @@ static int nemR3LnxUpdateCpuIdsLeaves(PVM pVM, PVMCPU pVCpu)
     return VINF_SUCCESS;
 }
 
+static int nemR3LnxInitGuestInterface(PVM pVM)
+{
+    switch (pVM->gim.s.enmProviderId) {
+    case GIMPROVIDERID_HYPERV:
+        /*
+          SynIC is currently disabled pending investigation of interrupt issues. See #19.
+
+          Enabling this capability is not sufficient to enable SynNIC. The corresponding features in the Hyper-V CPUID
+          leaves also have to be enabled. Look for SYNIC and STIMER in GIMHv.cpp.
+
+          The CPUID implementation hints must also indicate deprecating AutoEOI to make APICv work.
+         */
+#if 1
+        LogRel(("NEM: Enabling SYNIC.\n"));
+
+        for (VMCPUID idCpu = 0; idCpu < pVM->cCpus; idCpu++)
+        {
+            PVMCPU pVCpu = pVM->apCpusR3[idCpu];
+
+            struct kvm_enable_cap CapSynIC =
+            {
+                KVM_CAP_HYPERV_SYNIC2, 0, { 0, 0, 0, 0 }
+            };
+
+            int rcLnx = ioctl(pVCpu->nem.s.fdVCpu, KVM_ENABLE_CAP, &CapSynIC);
+            AssertLogRelMsgReturn(rcLnx == 0, ("Failed to enable SYNIC: rcLnx=%d errno=%d\n", rcLnx, errno),
+                                  RTErrConvertFromErrno(errno));
+        }
+#endif
+
+        break;
+
+    default:
+        /* Other guest interfaces are not fully supported. */
+        break;
+    }
+
+    return VINF_SUCCESS;
+}
+
+namespace
+{
+
+enum class KvmCpuIdIoctl : uint32_t
+{
+    CPUID = KVM_GET_SUPPORTED_CPUID,
+    HV_CPUID = KVM_GET_SUPPORTED_HV_CPUID
+};
+
+int KvmGetCpuIdLeavesGeneric(PVM pVM, KvmCpuIdIoctl ioctlNum, PCPUMCPUIDLEAF *outpCpuId, size_t *outcLeaves)
+{
+    struct kvm_cpuid2 *pKvmCpuid;
+    uint32_t cLeaves = 0;
+    int rc;
+
+    /* In case we exit due to errors. */
+    *outpCpuId = nullptr;
+    *outcLeaves = 0;
+
+    /* There is no way to query how many leaves there are. We just try until we hit the right size. */
+    do
+    {
+        cLeaves += 1;
+        Log(("Querying for %u leaves\n", cLeaves));
+
+        pKvmCpuid = static_cast<struct kvm_cpuid2 *>(alloca(RT_UOFFSETOF_DYN(struct kvm_cpuid2, entries[cLeaves])));
+
+        pKvmCpuid->nent = cLeaves;
+        pKvmCpuid->padding = 0;
+
+        rc = ioctl(pVM->nem.s.fdKvm, static_cast<uint32_t>(ioctlNum), pKvmCpuid);
+    } while (rc != 0 && errno == E2BIG);
+    AssertLogRelMsgReturn(rc == 0, ("Failed to query supported CPUID leaves: errno=%d", errno), RTErrConvertFromErrno(errno));
+    AssertFatal(cLeaves == pKvmCpuid->nent);
+
+    PCPUMCPUIDLEAF pCpuId = static_cast<PCPUMCPUIDLEAF>(RTMemAllocZ(sizeof(*pCpuId) * cLeaves));
+
+    for (uint32_t uLeaf = 0; uLeaf < cLeaves; uLeaf++)
+    {
+        pCpuId[uLeaf].uLeaf = pKvmCpuid->entries[uLeaf].function;
+        pCpuId[uLeaf].uSubLeaf = pKvmCpuid->entries[uLeaf].index;
+
+        pCpuId[uLeaf].uEax = pKvmCpuid->entries[uLeaf].eax;
+        pCpuId[uLeaf].uEbx = pKvmCpuid->entries[uLeaf].ebx;
+        pCpuId[uLeaf].uEcx = pKvmCpuid->entries[uLeaf].ecx;
+        pCpuId[uLeaf].uEdx = pKvmCpuid->entries[uLeaf].edx;
+    }
+
+    *outpCpuId = pCpuId;
+    *outcLeaves = cLeaves;
+
+    return VINF_SUCCESS;
+}
+
+} // anonymous namespace
+
+int NEMR3KvmGetHvCpuIdLeaves(PVM pVM, PCPUMCPUIDLEAF *outpCpuId, size_t *outcLeaves)
+{
+    return KvmGetCpuIdLeavesGeneric(pVM, KvmCpuIdIoctl::HV_CPUID, outpCpuId, outcLeaves);
+}
+
+int NEMR3KvmGetCpuIdLeaves(PVM pVM, PCPUMCPUIDLEAF *outpCpuId, size_t *outcLeaves)
+{
+    return KvmGetCpuIdLeavesGeneric(pVM, KvmCpuIdIoctl::CPUID, outpCpuId, outcLeaves);
+}
 
 int nemR3NativeInitCompleted(PVM pVM, VMINITCOMPLETED enmWhat)
 {
@@ -692,11 +1032,32 @@ int nemR3NativeInitCompleted(PVM pVM, VMINITCOMPLETED enmWhat)
     {
         for (VMCPUID idCpu = 0; idCpu < pVM->cCpus; idCpu++)
         {
+            PCPUMCTXMSRS const  pCtxMsrs    = CPUMQueryGuestCtxMsrsPtr(pVM->apCpusR3[idCpu]);
+
             int rc = nemR3LnxUpdateCpuIdsLeaves(pVM, pVM->apCpusR3[idCpu]);
             AssertRCReturn(rc, rc);
+
+#ifdef VBOX_WITH_KVM_NESTING
+            if (pVM->cpum.s.GuestFeatures.fVmx) {
+                NEMR3KvmSetMsr(pVM->apCpusR3[idCpu], MSR_IA32_FEATURE_CONTROL, MSR_IA32_FEATURE_CONTROL_VMXON | MSR_IA32_FEATURE_CONTROL_LOCK);
+            }
+#endif
+
+            uint64_t val {0};
+            NEMR3KvmGetMsr(pVM->apCpusR3[idCpu], MSR_IA32_ARCH_CAPABILITIES, &val);
+            pCtxMsrs->msr.ArchCaps = val;
+
+            NEMR3KvmGetMsr(pVM->apCpusR3[idCpu], MSR_IA32_SPEC_CTRL, &val);
+            pCtxMsrs->msr.SpecCtrl = val;
         }
     }
 
+    if (enmWhat == VMINITCOMPLETED_RING3)
+    {
+        int rc = nemR3LnxInitGuestInterface(pVM);
+        AssertRCReturn(rc, rc);
+    }
+
     /*
      * Configure MSRs after ring-3 init is done.
      *
@@ -725,6 +1086,8 @@ int nemR3NativeInitCompleted(PVM pVM, VMINITCOMPLETED enmWhat)
             MsrFilters.ranges[iRange].bitmap = (uint8_t *)&RT_CONCAT(bm, a_uBase)[0]
 #define MSR_RANGE_ADD(a_Msr) \
         do { Assert((uint32_t)(a_Msr) - uBase < cMsrs); ASMBitSet(pbm, (uint32_t)(a_Msr) - uBase); } while (0)
+#define MSR_RANGE_ADD_CLOSED_IVL(first_Msr, last_Msr) \
+        for (uint32_t uMsr = (first_Msr); uMsr <= last_Msr; uMsr++) { MSR_RANGE_ADD(uMsr); }
 #define MSR_RANGE_END(a_cMinMsrs) \
             /* optimize the range size before closing: */ \
             uint32_t cBitmap = cMsrs / 64; \
@@ -736,11 +1099,45 @@ int nemR3NativeInitCompleted(PVM pVM, VMINITCOMPLETED enmWhat)
 
         /* 1st Intel range: 0000_0000 to 0000_3000. */
         MSR_RANGE_BEGIN(0x00000000, 0x00003000, KVM_MSR_FILTER_READ | KVM_MSR_FILTER_WRITE);
+        MSR_RANGE_ADD(MSR_IA32_BIOS_SIGN_ID);
         MSR_RANGE_ADD(MSR_IA32_TSC);
+        MSR_RANGE_ADD(MSR_IA32_APICBASE);
         MSR_RANGE_ADD(MSR_IA32_SYSENTER_CS);
         MSR_RANGE_ADD(MSR_IA32_SYSENTER_ESP);
         MSR_RANGE_ADD(MSR_IA32_SYSENTER_EIP);
         MSR_RANGE_ADD(MSR_IA32_CR_PAT);
+        MSR_RANGE_ADD(MSR_IA32_ARCH_CAPABILITIES);
+        MSR_RANGE_ADD(MSR_IA32_SPEC_CTRL);
+        MSR_RANGE_ADD(MSR_IA32_PRED_CMD);
+        MSR_RANGE_ADD(MSR_IA32_FLUSH_CMD);
+
+#ifdef VBOX_WITH_KVM_NESTING
+        if (pVM->cpum.s.GuestFeatures.fVmx) {
+            /* VMX MSRS */
+            MSR_RANGE_ADD(MSR_IA32_FEATURE_CONTROL);
+            MSR_RANGE_ADD(MSR_IA32_MISC_ENABLE);
+            MSR_RANGE_ADD(MSR_IA32_VMX_BASIC);
+            MSR_RANGE_ADD(MSR_IA32_VMX_PINBASED_CTLS);
+            MSR_RANGE_ADD(MSR_IA32_VMX_PROCBASED_CTLS);
+            MSR_RANGE_ADD(MSR_IA32_VMX_EXIT_CTLS);
+            MSR_RANGE_ADD(MSR_IA32_VMX_ENTRY_CTLS);
+            MSR_RANGE_ADD(MSR_IA32_VMX_MISC);
+            MSR_RANGE_ADD(MSR_IA32_VMX_CR0_FIXED0);
+            MSR_RANGE_ADD(MSR_IA32_VMX_CR0_FIXED1);
+            MSR_RANGE_ADD(MSR_IA32_VMX_CR4_FIXED0);
+            MSR_RANGE_ADD(MSR_IA32_VMX_CR4_FIXED1);
+            MSR_RANGE_ADD(MSR_IA32_VMX_VMCS_ENUM);
+            MSR_RANGE_ADD(MSR_IA32_VMX_PROCBASED_CTLS2);
+            MSR_RANGE_ADD(MSR_IA32_VMX_EPT_VPID_CAP);
+            MSR_RANGE_ADD(MSR_IA32_VMX_TRUE_PINBASED_CTLS);
+            MSR_RANGE_ADD(MSR_IA32_VMX_TRUE_PROCBASED_CTLS);
+            MSR_RANGE_ADD(MSR_IA32_VMX_TRUE_EXIT_CTLS);
+            MSR_RANGE_ADD(MSR_IA32_VMX_TRUE_ENTRY_CTLS);
+            MSR_RANGE_ADD(MSR_IA32_VMX_VMFUNC);
+            MSR_RANGE_ADD(MSR_IA32_VMX_PROCBASED_CTLS3);
+            MSR_RANGE_ADD(MSR_IA32_VMX_EXIT_CTLS2);
+        }
+#endif
         /** @todo more? */
         MSR_RANGE_END(64);
 
@@ -748,6 +1145,13 @@ int nemR3NativeInitCompleted(PVM pVM, VMINITCOMPLETED enmWhat)
         MSR_RANGE_BEGIN(0xc0000000, 0xc0003000, KVM_MSR_FILTER_READ | KVM_MSR_FILTER_WRITE);
         MSR_RANGE_ADD(MSR_K6_EFER);
         MSR_RANGE_ADD(MSR_K6_STAR);
+
+        /*
+         * If we don't allow direct access to FS_BASE, we clobber the FS base for the guest. This sounds like a bug in
+         * our state synchronization with KVM.
+         */
+        MSR_RANGE_ADD(MSR_K8_FS_BASE);
+
         MSR_RANGE_ADD(MSR_K8_GS_BASE);
         MSR_RANGE_ADD(MSR_K8_KERNEL_GS_BASE);
         MSR_RANGE_ADD(MSR_K8_LSTAR);
@@ -757,6 +1161,49 @@ int nemR3NativeInitCompleted(PVM pVM, VMINITCOMPLETED enmWhat)
         /** @todo add more? */
         MSR_RANGE_END(64);
 
+        if (pVM->gim.s.enmProviderId == GIMPROVIDERID_HYPERV)
+        {
+            MSR_RANGE_BEGIN(0x40000000, 0x40003000, KVM_MSR_FILTER_READ | KVM_MSR_FILTER_WRITE);
+
+            MSR_RANGE_ADD_CLOSED_IVL(MSR_GIM_HV_RANGE0_FIRST, MSR_GIM_HV_RANGE0_LAST);
+            MSR_RANGE_ADD_CLOSED_IVL(MSR_GIM_HV_RANGE1_FIRST, MSR_GIM_HV_RANGE1_LAST);
+            MSR_RANGE_ADD_CLOSED_IVL(MSR_GIM_HV_RANGE2_FIRST, MSR_GIM_HV_RANGE2_LAST);
+            MSR_RANGE_ADD_CLOSED_IVL(MSR_GIM_HV_RANGE3_FIRST, MSR_GIM_HV_RANGE3_LAST);
+
+            /* SynIC / STimer */
+            MSR_RANGE_ADD_CLOSED_IVL(MSR_GIM_HV_RANGE4_FIRST, MSR_GIM_HV_RANGE4_LAST);
+            MSR_RANGE_ADD_CLOSED_IVL(MSR_GIM_HV_RANGE5_FIRST, MSR_GIM_HV_RANGE5_LAST);
+            MSR_RANGE_ADD_CLOSED_IVL(MSR_GIM_HV_RANGE6_FIRST, MSR_GIM_HV_RANGE6_LAST);
+
+            MSR_RANGE_ADD_CLOSED_IVL(MSR_GIM_HV_RANGE7_FIRST, MSR_GIM_HV_RANGE7_LAST);
+            MSR_RANGE_ADD_CLOSED_IVL(MSR_GIM_HV_RANGE8_FIRST, MSR_GIM_HV_RANGE8_LAST);
+            MSR_RANGE_ADD_CLOSED_IVL(MSR_GIM_HV_RANGE9_FIRST, MSR_GIM_HV_RANGE9_LAST);
+            MSR_RANGE_ADD_CLOSED_IVL(MSR_GIM_HV_RANGE10_FIRST, MSR_GIM_HV_RANGE10_LAST);
+            MSR_RANGE_ADD_CLOSED_IVL(MSR_GIM_HV_RANGE11_FIRST, MSR_GIM_HV_RANGE11_LAST);
+
+            /*
+             * Crash MSRs
+             *
+             * We deliberately don't add them here, so we can handle them instead of KVM. This allows us to log the
+             * crash reason into VM log instead of it ending up in the kernel's log.
+             */
+            // MSR_RANGE_ADD_CLOSED_IVL(MSR_GIM_HV_RANGE12_FIRST, MSR_GIM_HV_RANGE12_LAST);
+
+            /*
+             * These should be available to the guest with feature bit 23 in the base features, which we don't
+             * expose. But Windows touches them anyway?
+             */
+            MSR_RANGE_ADD(0x40000114 /* HV_X64_MSR_STIME_UNHALTED_TIMER_CONFIG */);
+            MSR_RANGE_ADD(0x40000115 /* HV_X64_MSR_STIME_UNHALTED_TIMER_COUNT */);
+
+            /*
+             * These are available to the guest with feature bit 15 in the base features (undocumented).
+             */
+            MSR_RANGE_ADD(0x40000118 /* HV_X64_MSR_TSC_INVARIANT_CONTROL */);
+
+            MSR_RANGE_END(64);
+        }
+
         /** @todo Specify other ranges too? Like hyper-V and KVM to make sure we get
          *        the MSR requests instead of KVM. */
 
@@ -805,6 +1252,9 @@ int nemR3NativeTerm(PVM pVM)
         close(pVM->nem.s.fdKvm);
         pVM->nem.s.fdKvm = -1;
     }
+
+    pVM->nem.s.pARedirectionTable.reset();
+
     return VINF_SUCCESS;
 }
 
@@ -816,7 +1266,18 @@ int nemR3NativeTerm(PVM pVM)
  */
 void nemR3NativeReset(PVM pVM)
 {
-    RT_NOREF(pVM);
+    pVM->nem.s.pARedirectionTable->fill(std::nullopt);
+
+    for (VMCPUID idCpu = 0; idCpu < pVM->cCpus; idCpu++)
+    {
+        PVMCPU pVCpu = pVM->apCpusR3[idCpu];
+
+        struct kvm_mp_state mp;
+        mp.mp_state = pVCpu->idCpu == 0 ? KVM_MP_STATE_RUNNABLE : KVM_MP_STATE_UNINITIALIZED;
+
+        int rcLnx = ioctl(pVCpu->nem.s.fdVCpu, KVM_SET_MP_STATE, &mp);
+        AssertLogRelMsg(rcLnx == 0, ("nemR3NativeReset: Failed to set MP state. Error: %d, errno %d\n", rcLnx, errno));
+    }
 }
 
 
@@ -1121,6 +1582,325 @@ VMMR3_INT_DECL(int)  NEMR3NotifyPhysRomRegisterLate(PVM pVM, RTGCPHYS GCPhys, RT
 }
 
 
+VMMR3_INT_DECL(int) NEMR3LoadExec(PVM pVM)
+{
+    // TODO: this code leaves a small window between the guest sending an INIT IPI
+    // and a subsequent SIPI IPI. If that's the case, we need to set the MP state
+    // `KVM_MP_STATE_INIT_RECEIVED` which requires some serious interaction
+    // between the NEM and SSM. For now, we hope that noone suspends a VM during
+    // VCPU bringup. See vbox-engineering#426.
+    for (VMCPUID i = 0; i < pVM->cCpus; i++) {
+        PVMCPU pVCpu = pVM->apCpusR3[i];
+        auto state = VMCPU_GET_STATE(pVCpu);
+        if (state == VMCPUSTATE_STARTED || state == VMCPUSTATE_STARTED_EXEC_NEM || state == VMCPUSTATE_STARTED_EXEC_NEM_WAIT )
+        {
+            struct kvm_mp_state mp;
+            mp.mp_state = KVM_MP_STATE_RUNNABLE;
+            int rcLnx = ioctl(pVCpu->nem.s.fdVCpu, KVM_SET_MP_STATE, &mp);
+            AssertLogRelMsgReturn(rcLnx == 0, ("NEMR3Load: Failed to set MP state. Error: %d, errno %d\n", rcLnx, errno), VERR_NEM_IPE_5);
+        }
+    }
+    return VINF_SUCCESS;
+}
+
+VMMR3_INT_DECL(int) NEMR3KvmGetMsr(PVMCPU pVCpu, uint64_t msr, uint64_t* val)
+{
+    alignas(struct kvm_msrs) char backing[sizeof(struct kvm_msrs) + sizeof(struct kvm_msr_entry)];
+    struct kvm_msrs* msr_data {reinterpret_cast<struct kvm_msrs*>(&backing[0])};
+    RT_ZERO(backing);
+
+    msr_data->nmsrs = 1;
+    msr_data->entries[0].index = msr;
+
+    int rcLnx = ioctl(pVCpu->nem.s.fdVCpu, KVM_GET_MSRS, msr_data);
+    AssertLogRelMsgReturn(rcLnx == 1, ("NEMR3KvmGetMsr: \
+                Failed to get MSR data. Error: %d, errno %d\n", rcLnx, errno), VERR_NOT_SUPPORTED);
+
+    AssertLogRelMsgReturn(val != nullptr, ("NEMR3KvmGetMsr: \
+                Invalid buffer\n", rcLnx, errno), VERR_NEM_IPE_5);
+
+    *val = msr_data->entries[0].data;
+
+    return VINF_SUCCESS;
+}
+
+VMMR3_INT_DECL(int) NEMR3KvmSetMsr(PVMCPU pVCpu, uint64_t msr, uint64_t val)
+{
+    alignas(struct kvm_msrs) char backing[sizeof(struct kvm_msrs) + sizeof(struct kvm_msr_entry)];
+    struct kvm_msrs* msr_data {reinterpret_cast<struct kvm_msrs*>(&backing[0])};
+    RT_ZERO(backing);
+
+    msr_data->nmsrs = 1;
+    msr_data->entries[0].index = msr;
+    msr_data->entries[0].data = val;
+
+    int rcLnx = ioctl(pVCpu->nem.s.fdVCpu, KVM_SET_MSRS, msr_data);
+    AssertLogRelMsgReturn(rcLnx == 1, ("NEMR3KvmSetMsr: \
+                Failed to set MSR[%lx] data. Error: %d, errno %d\n", msr, rcLnx, errno), VERR_NOT_SUPPORTED);
+
+    return VINF_SUCCESS;
+}
+
+VMMR3_INT_DECL(int) NEMR3KvmGetLapicState(PVMCPU pVCpu, void* pXApicPage)
+{
+    struct kvm_lapic_state state;
+
+    int rcLnx = ioctl(pVCpu->nem.s.fdVCpu, KVM_GET_LAPIC, &state);
+    AssertLogRelMsgReturn(rcLnx == 0, ("NEMR3KvmGetLapicState: \
+                Failed to get APIC state. Error: %d, errno %d\n", rcLnx, errno), VERR_NEM_IPE_5);
+
+    memcpy(pXApicPage, &state.regs[0], KVM_APIC_REG_SIZE);
+    return VINF_SUCCESS;
+}
+
+VMMR3_INT_DECL(int) NEMR3KvmSetLapicState(PVMCPU pVCpu, void* pXApicPage)
+{
+    struct kvm_lapic_state state;
+
+    memcpy(&state.regs[0], pXApicPage, KVM_APIC_REG_SIZE);
+
+    int rcLnx = ioctl(pVCpu->nem.s.fdVCpu, KVM_SET_LAPIC, &state);
+    AssertLogRelMsgReturn(rcLnx == 0, ("NEMR3KvmSetApicState: \
+                Failed to set APIC state. Error %d, errno %d\n", rcLnx, errno), VERR_NEM_IPE_5);
+
+    return VINF_SUCCESS;
+}
+
+VMMR3_INT_DECL(int) NEMR3KvmSetIrqLine(PVM pVM, uint16_t u16Gsi, int iLevel)
+{
+    struct kvm_irq_level irq;
+    RT_ZERO(irq);
+
+    irq.irq = u16Gsi;
+    irq.level = iLevel;
+
+    int rcLnx = ioctl(pVM->nem.s.fdVm, KVM_IRQ_LINE, &irq);
+    AssertLogRelMsgReturn(rcLnx == 0, ("NEMR3KvmSetIrqLine: Failed to set irq line %d! error: %d, errno %d\n", u16Gsi, rcLnx, errno), VERR_NEM_IPE_5);
+
+    return VINF_SUCCESS;
+}
+
+VMMR3_INT_DECL(int) NEMR3KvmSplitIrqchipDeliverMsi(PVM pVM, PCMSIMSG pMsi)
+{
+    AssertLogRelReturn(pVM != nullptr, VERR_INVALID_POINTER);
+    AssertLogRelReturn(pMsi != nullptr, VERR_INVALID_POINTER);
+
+    struct kvm_msi msi;
+    RT_ZERO(msi);
+    msi.address_lo = pMsi->Addr.au32[0];
+    msi.address_hi = pMsi->Addr.au32[1];
+    msi.data = pMsi->Data.u32;
+
+    int rcLnx = ioctl(pVM->nem.s.fdVm, KVM_SIGNAL_MSI, &msi);
+    AssertLogRelMsgReturn(rcLnx >= 0, ("NEMR3KvmSplitIrqchipDeliverMsi: Failed to deliver MSI! error: %d, errno %d\n", rcLnx, errno), VERR_NEM_IPE_5);
+
+    return rcLnx == 0 ? VERR_APIC_INTR_DISCARDED : VINF_SUCCESS;
+}
+
+#ifdef VBOX_WITH_KVM_IRQCHIP_FULL
+static int kvmSetGsiRoutingFullIrqChip(PVM pVM)
+{
+    alignas(kvm_irq_routing) char backing[ sizeof(struct kvm_irq_routing) +
+        (KVM_IRQCHIP_NUM_IOAPIC_INTR_PINS + KVM_IRQCHIP_NUM_PIC_INTR_PINS) * sizeof(struct kvm_irq_routing_entry) ] {};
+    kvm_irq_routing* routing = reinterpret_cast<kvm_irq_routing*>(backing);
+
+    for (unsigned i = 0; i < KVM_IRQCHIP_NUM_PIC_INTR_PINS; ++i) {
+        routing->entries[i].gsi = i;
+        routing->entries[i].type = KVM_IRQ_ROUTING_IRQCHIP;
+        routing->entries[i].u.irqchip.irqchip = (i < 8) ? KVM_IRQCHIP_PIC_MASTER : KVM_IRQCHIP_PIC_SLAVE;
+        routing->entries[i].u.irqchip.pin = (i < 8) ? i : (i - 8);
+    }
+
+    for (unsigned i = 0; i < KVM_IRQCHIP_NUM_IOAPIC_INTR_PINS; ++i) {
+        uint64_t arr_idx = i + KVM_IRQCHIP_NUM_PIC_INTR_PINS;
+        routing->entries[arr_idx].gsi = i;
+        routing->entries[arr_idx].type = KVM_IRQ_ROUTING_IRQCHIP;
+        routing->entries[arr_idx].u.irqchip.irqchip = KVM_IRQCHIP_IOAPIC;
+        if (i == 0) {
+            routing->entries[arr_idx].u.irqchip.pin = 2;
+        } else {
+            routing->entries[arr_idx].u.irqchip.pin = i;
+        }
+    }
+    routing->nr = KVM_IRQCHIP_NUM_PIC_INTR_PINS + KVM_IRQCHIP_NUM_IOAPIC_INTR_PINS;
+
+    int rc = ioctl(pVM->nem.s.fdVm, KVM_SET_GSI_ROUTING, routing);
+
+    AssertLogRelMsgReturn(rc >= 0, ("NEM/KVM: Unable to set GSI routing! rc: %d errno %d \n", rc, errno), VERR_INTERNAL_ERROR);
+
+    return VINF_SUCCESS;
+}
+
+VMMR3_INT_DECL(int) NEMR3KvmGetPicState(PVM pVM, KVMIRQCHIP irqchip, KVMPICSTATE* state)
+{
+    struct kvm_irqchip irqchip_state;
+    irqchip_state.chip_id = irqchip == KVMIRQCHIP::PIC_MASTER ? KVM_IRQCHIP_PIC_MASTER : KVM_IRQCHIP_PIC_SLAVE;
+
+    if (state == nullptr) {
+        return VERR_INVALID_POINTER;
+    }
+
+    int rcLnx = ioctl(pVM->nem.s.fdVm, KVM_GET_IRQCHIP, &irqchip_state);
+    AssertLogRelMsgReturn(rcLnx == 0, ("NEMR3KvmGetPicState: \
+                Failed to get PIC state. Error: %d, errno %d\n", rcLnx, errno), VERR_NEM_IPE_5);
+
+    state->last_irr = irqchip_state.chip.pic.last_irr;
+    state->irr = irqchip_state.chip.pic.irr;
+    state->imr = irqchip_state.chip.pic.imr;
+    state->isr = irqchip_state.chip.pic.isr;
+    state->priority_add = irqchip_state.chip.pic.priority_add;
+    state->irq_base = irqchip_state.chip.pic.irq_base;
+    state->read_reg_select = irqchip_state.chip.pic.read_reg_select;
+    state->poll = irqchip_state.chip.pic.poll;
+    state->special_mask = irqchip_state.chip.pic.special_mask;
+    state->init_state = irqchip_state.chip.pic.init_state;
+    state->auto_eoi = irqchip_state.chip.pic.auto_eoi;
+    state->rotate_on_auto_eoi = irqchip_state.chip.pic.rotate_on_auto_eoi;
+    state->special_fully_nested_mode = irqchip_state.chip.pic.special_fully_nested_mode;
+    state->init4 = irqchip_state.chip.pic.init4;
+    state->elcr = irqchip_state.chip.pic.elcr;
+    state->elcr_mask = irqchip_state.chip.pic.elcr_mask;
+
+    return VINF_SUCCESS;
+}
+
+VMMR3_INT_DECL(int) NEMR3KvmSetPicState(PVM pVM, KVMIRQCHIP irqchip, KVMPICSTATE* state)
+{
+    struct kvm_irqchip irqchip_state;
+    irqchip_state.chip_id = irqchip == KVMIRQCHIP::PIC_MASTER ? KVM_IRQCHIP_PIC_MASTER : KVM_IRQCHIP_PIC_SLAVE;
+
+    if (state == nullptr) {
+        return VERR_INVALID_POINTER;
+    }
+
+    irqchip_state.chip.pic.last_irr = state->last_irr;
+    irqchip_state.chip.pic.irr = state->irr;
+    irqchip_state.chip.pic.imr = state->imr;
+    irqchip_state.chip.pic.isr = state->isr;
+    irqchip_state.chip.pic.priority_add = state->priority_add;
+    irqchip_state.chip.pic.irq_base = state->irq_base;
+    irqchip_state.chip.pic.read_reg_select = state->read_reg_select;
+    irqchip_state.chip.pic.poll = state->poll;
+    irqchip_state.chip.pic.special_mask = state->special_mask;
+    irqchip_state.chip.pic.init_state = state->init_state;
+    irqchip_state.chip.pic.auto_eoi = state->auto_eoi;
+    irqchip_state.chip.pic.rotate_on_auto_eoi = state->rotate_on_auto_eoi;
+    irqchip_state.chip.pic.special_fully_nested_mode = state->special_fully_nested_mode;
+    irqchip_state.chip.pic.init4 = state->init4;
+    irqchip_state.chip.pic.elcr = state->elcr;
+    irqchip_state.chip.pic.elcr_mask = state->elcr_mask;
+
+    int rcLnx = ioctl(pVM->nem.s.fdVm, KVM_GET_IRQCHIP, &irqchip_state);
+    AssertLogRelMsgReturn(rcLnx == 0, ("NEMR3KvmSetPicState: \
+                Failed to get PIC state. Error: %d, errno %d\n", rcLnx, errno), VERR_NEM_IPE_5);
+
+    return VINF_SUCCESS;
+}
+
+VMMR3_INT_DECL(int) NEMR3KvmGetIoApicState(PVM pVM, KVMIOAPICSTATE* state)
+{
+    struct kvm_irqchip irqchip_state;
+    irqchip_state.chip_id = KVM_IRQCHIP_IOAPIC;
+
+    if (state == nullptr) {
+        return VERR_INVALID_POINTER;
+    }
+
+    int rcLnx = ioctl(pVM->nem.s.fdVm, KVM_GET_IRQCHIP, &irqchip_state);
+    AssertLogRelMsgReturn(rcLnx == 0, ("NEMR3KvmGetIoApicState: \
+                Failed to get IOAPIC state. Error: %d, errno %d\n", rcLnx, errno), VERR_NEM_IPE_5);
+
+    state->base_address = irqchip_state.chip.ioapic.base_address;
+    state->ioregsel = irqchip_state.chip.ioapic.ioregsel;
+    state->id = irqchip_state.chip.ioapic.id;
+    state->irr = irqchip_state.chip.ioapic.irr;
+
+    for (unsigned i = 0; i < KVM_IRQCHIP_NUM_IOAPIC_INTR_PINS; ++i) {
+        state->redirtbl[i] = irqchip_state.chip.ioapic.redirtbl[i].bits;
+    }
+
+    return VINF_SUCCESS;
+}
+
+VMMR3_INT_DECL(int) NEMR3KvmSetIoApicState(PVM pVM, KVMIOAPICSTATE* state)
+{
+    struct kvm_irqchip irqchip_state;
+    irqchip_state.chip_id = KVM_IRQCHIP_IOAPIC;
+
+    if (state == nullptr) {
+        return VERR_INVALID_POINTER;
+    }
+
+    irqchip_state.chip.ioapic.base_address = state->base_address;
+    irqchip_state.chip.ioapic.ioregsel = state->ioregsel;
+    irqchip_state.chip.ioapic.id = state->id;
+    irqchip_state.chip.ioapic.irr = state->irr;
+
+    for (unsigned i = 0; i < KVM_IRQCHIP_NUM_IOAPIC_INTR_PINS; ++i) {
+        irqchip_state.chip.ioapic.redirtbl[i].bits = state->redirtbl[i];
+    }
+
+    int rcLnx = ioctl(pVM->nem.s.fdVm, KVM_SET_IRQCHIP, &irqchip_state);
+    AssertLogRelMsgReturn(rcLnx == 0, ("NEMR3KvmSetIoApicState: \
+                Failed to set IOPIC state. Error: %d, errno %d\n", rcLnx, errno), VERR_NEM_IPE_5);
+
+    return VINF_SUCCESS;
+}
+#endif
+
+static int kvmSetGsiRouting(PVM pVM)
+{
+    alignas(kvm_irq_routing) char backing[ sizeof(struct kvm_irq_routing) + KVM_IRQCHIP_NUM_IOAPIC_INTR_PINS * sizeof(struct kvm_irq_routing_entry) ] {};
+    kvm_irq_routing* routing = reinterpret_cast<kvm_irq_routing*>(backing);
+
+    unsigned routingCount {0};
+
+    for(unsigned i {0}; i < KVM_IRQCHIP_NUM_IOAPIC_INTR_PINS; ++i)
+    {
+        if (pVM->nem.s.pARedirectionTable->at(i).has_value())
+        {
+            PMSIMSG msi = &(pVM->nem.s.pARedirectionTable->at(i).value());
+            routing->entries[routingCount].gsi = i;
+            routing->entries[routingCount].type = KVM_IRQ_ROUTING_MSI;
+            routing->entries[routingCount].u.msi.address_lo = msi->Addr.au32[0];
+            routing->entries[routingCount].u.msi.address_hi = msi->Addr.au32[1];
+            routing->entries[routingCount].u.msi.data = msi->Data.u32;
+            routingCount++;
+        }
+    }
+
+    routing->nr = routingCount;
+
+    int rc = ioctl(pVM->nem.s.fdVm, KVM_SET_GSI_ROUTING, routing);
+
+    AssertLogRelMsgReturn(rc >= 0, ("NEM/KVM: Unable to set GSI routing! rc: %d errno %d \n", rc, errno), VERR_INTERNAL_ERROR);
+
+    return VINF_SUCCESS;
+}
+
+
+VMMR3_INT_DECL(int) NEMR3KvmSplitIrqchipAddUpdateRTE(PVM pVM, uint16_t u16Gsi, PCMSIMSG pMsi)
+{
+    AssertRelease(pVM->nem.s.pARedirectionTable != nullptr);
+    AssertRelease(u16Gsi < KVM_IRQCHIP_NUM_IOAPIC_INTR_PINS);
+
+    pVM->nem.s.pARedirectionTable->at(u16Gsi) = *pMsi;
+
+    return kvmSetGsiRouting(pVM);
+}
+
+
+VMMR3_INT_DECL(int) NEMR3KvmSplitIrqchipRemoveRTE(PVM pVM, uint16_t u16Gsi)
+{
+    AssertRelease(pVM->nem.s.pARedirectionTable != nullptr);
+    AssertRelease(u16Gsi < KVM_IRQCHIP_NUM_IOAPIC_INTR_PINS);
+
+    pVM->nem.s.pARedirectionTable->at(u16Gsi) = std::nullopt;
+
+    return kvmSetGsiRouting(pVM);
+}
+
+
 VMMR3_INT_DECL(void) NEMR3NotifySetA20(PVMCPU pVCpu, bool fEnabled)
 {
     Log(("nemR3NativeNotifySetA20: fEnabled=%RTbool\n", fEnabled));
@@ -1329,8 +2109,7 @@ static int nemHCLnxImportState(PVMCPUCC pVCpu, uint64_t fWhat, PCPUMCTX pCtx, st
                 }
             }
         }
-        if (fWhat & CPUMCTX_EXTRN_APIC_TPR)
-            APICSetTpr(pVCpu, (uint8_t)pRun->s.regs.sregs.cr8 << 4);
+
         if (fWhat & CPUMCTX_EXTRN_EFER)
         {
             if (pCtx->msrEFER != pRun->s.regs.sregs.efer)
@@ -1397,6 +2176,7 @@ static int nemHCLnxImportState(PVMCPUCC pVCpu, uint64_t fWhat, PCPUMCTX pCtx, st
 
             pCtx->aXcr[0] = Xcrs.xcrs[0].value;
             pCtx->aXcr[1] = Xcrs.xcrs[1].value;
+            pCtx->fXStateMask = Xcrs.xcrs[0].value;
         }
     }
 
@@ -1444,6 +2224,8 @@ static int nemHCLnxImportState(PVMCPUCC pVCpu, uint64_t fWhat, PCPUMCTX pCtx, st
         if (fWhat & CPUMCTX_EXTRN_OTHER_MSRS)
         {
             ADD_MSR(MSR_IA32_CR_PAT, pCtx->msrPAT);
+            ADD_MSR(MSR_IA32_ARCH_CAPABILITIES, pCtxMsrs->msr.ArchCaps);
+            ADD_MSR(MSR_IA32_SPEC_CTRL, pCtxMsrs->msr.SpecCtrl);
             /** @todo What do we _have_ to add here?
              * We also have: Mttr*, MiscEnable, FeatureControl. */
         }
@@ -1481,12 +2263,6 @@ static int nemHCLnxImportState(PVMCPUCC pVCpu, uint64_t fWhat, PCPUMCTX pCtx, st
                                          pVCpu->cpum.GstCtx.rip);
         CPUMUpdateInterruptInhibitingByNmi(&pVCpu->cpum.GstCtx, KvmEvents.nmi.masked != 0);
 
-        if (KvmEvents.interrupt.injected)
-        {
-            STAM_REL_COUNTER_INC(&pVCpu->nem.s.StatImportPendingInterrupt);
-            TRPMAssertTrap(pVCpu, KvmEvents.interrupt.nr, !KvmEvents.interrupt.soft ? TRPM_HARDWARE_INT : TRPM_SOFTWARE_INT);
-        }
-
         Assert(KvmEvents.nmi.injected == 0);
         Assert(KvmEvents.nmi.pending  == 0);
     }
@@ -1651,15 +2427,7 @@ static int nemHCLnxExportState(PVM pVM, PVMCPU pVCpu, PCPUMCTX pCtx, struct kvm_
                       | CPUMCTX_EXTRN_EFER      | CPUMCTX_EXTRN_APIC_TPR))
         || uApicBase != pVCpu->nem.s.uKvmApicBase)
     {
-        if ((pVCpu->nem.s.uKvmApicBase ^ uApicBase) & MSR_IA32_APICBASE_EN)
-            Log(("NEM/%u: APICBASE_EN changed %#010RX64 -> %#010RX64\n", pVCpu->idCpu, pVCpu->nem.s.uKvmApicBase, uApicBase));
-        pRun->s.regs.sregs.apic_base = uApicBase;
-        pVCpu->nem.s.uKvmApicBase    = uApicBase;
-
-        if (fExtrn & CPUMCTX_EXTRN_APIC_TPR)
-            pRun->s.regs.sregs.cr8   = CPUMGetGuestCR8(pVCpu);
-
-#define NEM_LNX_EXPORT_SEG(a_KvmSeg, a_CtxSeg) do { \
+#define NEM_LNX_EXPORT_SEG(a_KvmSeg, a_CtxSeg, dirty_flag) do { \
             (a_KvmSeg).base     = (a_CtxSeg).u64Base; \
             (a_KvmSeg).limit    = (a_CtxSeg).u32Limit; \
             (a_KvmSeg).selector = (a_CtxSeg).Sel; \
@@ -1673,64 +2441,129 @@ static int nemHCLnxExportState(PVM pVM, PVMCPU pVCpu, PCPUMCTX pCtx, struct kvm_
             (a_KvmSeg).g        = (a_CtxSeg).Attr.n.u1Granularity; \
             (a_KvmSeg).unusable = (a_CtxSeg).Attr.n.u1Unusable; \
             (a_KvmSeg).padding  = 0; \
+            dirty_flag = true; \
         } while (0)
+#define NEM_LNX_SREG_IDENTICAL(a_KvmSeg, a_CtxSeg) ( \
+            (a_KvmSeg).base     == (a_CtxSeg).u64Base && \
+            (a_KvmSeg).limit    == (a_CtxSeg).u32Limit && \
+            (a_KvmSeg).selector == (a_CtxSeg).Sel && \
+            (a_KvmSeg).type     == (a_CtxSeg).Attr.n.u4Type && \
+            (a_KvmSeg).s        == (a_CtxSeg).Attr.n.u1DescType && \
+            (a_KvmSeg).dpl      == (a_CtxSeg).Attr.n.u2Dpl && \
+            (a_KvmSeg).present  == (a_CtxSeg).Attr.n.u1Present && \
+            (a_KvmSeg).avl      == (a_CtxSeg).Attr.n.u1Available && \
+            (a_KvmSeg).l        == (a_CtxSeg).Attr.n.u1Long && \
+            (a_KvmSeg).db       == (a_CtxSeg).Attr.n.u1DefBig && \
+            (a_KvmSeg).g        == (a_CtxSeg).Attr.n.u1Granularity && \
+            (a_KvmSeg).unusable == (a_CtxSeg).Attr.n.u1Unusable \
+        )
+#define NEM_UPDATE_IF_CHANGED(dst, src, dirty_flag) \
+        if (src != dst) { \
+            dst = src; \
+            dirty_flag = true; \
+        }
+
+        bool dirty_sregs = false;
+
+        if ((pVCpu->nem.s.uKvmApicBase ^ uApicBase) & MSR_IA32_APICBASE_EN)
+            Log(("NEM/%u: APICBASE_EN changed %#010RX64 -> %#010RX64\n", pVCpu->idCpu, pVCpu->nem.s.uKvmApicBase, uApicBase));
+
+        NEM_UPDATE_IF_CHANGED(pRun->s.regs.sregs.apic_base, uApicBase, dirty_sregs);
+        NEM_UPDATE_IF_CHANGED(pVCpu->nem.s.uKvmApicBase, uApicBase, dirty_sregs);
 
         if (fExtrn & CPUMCTX_EXTRN_SREG_MASK)
         {
-            if (fExtrn & CPUMCTX_EXTRN_ES)
-                NEM_LNX_EXPORT_SEG(pRun->s.regs.sregs.es, pCtx->es);
-            if (fExtrn & CPUMCTX_EXTRN_CS)
-                NEM_LNX_EXPORT_SEG(pRun->s.regs.sregs.cs, pCtx->cs);
-            if (fExtrn & CPUMCTX_EXTRN_SS)
-                NEM_LNX_EXPORT_SEG(pRun->s.regs.sregs.ss, pCtx->ss);
-            if (fExtrn & CPUMCTX_EXTRN_DS)
-                NEM_LNX_EXPORT_SEG(pRun->s.regs.sregs.ds, pCtx->ds);
-            if (fExtrn & CPUMCTX_EXTRN_FS)
-                NEM_LNX_EXPORT_SEG(pRun->s.regs.sregs.fs, pCtx->fs);
-            if (fExtrn & CPUMCTX_EXTRN_GS)
-                NEM_LNX_EXPORT_SEG(pRun->s.regs.sregs.gs, pCtx->gs);
+            if (fExtrn & CPUMCTX_EXTRN_ES and not NEM_LNX_SREG_IDENTICAL(pRun->s.regs.sregs.es, pCtx->es)) {
+                NEM_LNX_EXPORT_SEG(pRun->s.regs.sregs.es, pCtx->es, dirty_sregs);
+            }
+            if (fExtrn & CPUMCTX_EXTRN_CS and not NEM_LNX_SREG_IDENTICAL(pRun->s.regs.sregs.cs, pCtx->cs)) {
+                NEM_LNX_EXPORT_SEG(pRun->s.regs.sregs.cs, pCtx->cs, dirty_sregs);
+            }
+            if (fExtrn & CPUMCTX_EXTRN_SS and not NEM_LNX_SREG_IDENTICAL(pRun->s.regs.sregs.ss, pCtx->ss)) {
+                NEM_LNX_EXPORT_SEG(pRun->s.regs.sregs.ss, pCtx->ss, dirty_sregs);
+            }
+            if (fExtrn & CPUMCTX_EXTRN_DS and not NEM_LNX_SREG_IDENTICAL(pRun->s.regs.sregs.ds, pCtx->ds)) {
+                NEM_LNX_EXPORT_SEG(pRun->s.regs.sregs.ds, pCtx->ds, dirty_sregs);
+            }
+            if (fExtrn & CPUMCTX_EXTRN_FS and not NEM_LNX_SREG_IDENTICAL(pRun->s.regs.sregs.fs, pCtx->fs)) {
+                NEM_LNX_EXPORT_SEG(pRun->s.regs.sregs.fs, pCtx->fs, dirty_sregs);
+            }
+            if (fExtrn & CPUMCTX_EXTRN_GS and not NEM_LNX_SREG_IDENTICAL(pRun->s.regs.sregs.gs, pCtx->gs)) {
+                NEM_LNX_EXPORT_SEG(pRun->s.regs.sregs.gs, pCtx->gs, dirty_sregs);
+            }
+
         }
         if (fExtrn & CPUMCTX_EXTRN_TABLE_MASK)
         {
             if (fExtrn & CPUMCTX_EXTRN_GDTR)
             {
-                pRun->s.regs.sregs.gdt.base  = pCtx->gdtr.pGdt;
-                pRun->s.regs.sregs.gdt.limit = pCtx->gdtr.cbGdt;
+                NEM_UPDATE_IF_CHANGED(pRun->s.regs.sregs.gdt.base, pCtx->gdtr.pGdt, dirty_sregs);
+                NEM_UPDATE_IF_CHANGED(pRun->s.regs.sregs.gdt.limit, pCtx->gdtr.cbGdt, dirty_sregs);
                 pRun->s.regs.sregs.gdt.padding[0] = 0;
                 pRun->s.regs.sregs.gdt.padding[1] = 0;
                 pRun->s.regs.sregs.gdt.padding[2] = 0;
             }
             if (fExtrn & CPUMCTX_EXTRN_IDTR)
             {
-                pRun->s.regs.sregs.idt.base  = pCtx->idtr.pIdt;
-                pRun->s.regs.sregs.idt.limit = pCtx->idtr.cbIdt;
+                NEM_UPDATE_IF_CHANGED(pRun->s.regs.sregs.idt.base, pCtx->idtr.pIdt, dirty_sregs);
+                NEM_UPDATE_IF_CHANGED(pRun->s.regs.sregs.idt.limit, pCtx->idtr.cbIdt, dirty_sregs);
                 pRun->s.regs.sregs.idt.padding[0] = 0;
                 pRun->s.regs.sregs.idt.padding[1] = 0;
                 pRun->s.regs.sregs.idt.padding[2] = 0;
             }
-            if (fExtrn & CPUMCTX_EXTRN_LDTR)
-                NEM_LNX_EXPORT_SEG(pRun->s.regs.sregs.ldt, pCtx->ldtr);
-            if (fExtrn & CPUMCTX_EXTRN_TR)
-                NEM_LNX_EXPORT_SEG(pRun->s.regs.sregs.tr, pCtx->tr);
+            if (fExtrn & CPUMCTX_EXTRN_LDTR and not NEM_LNX_SREG_IDENTICAL(pRun->s.regs.sregs.ldt, pCtx->ldtr)) {
+                NEM_LNX_EXPORT_SEG(pRun->s.regs.sregs.ldt, pCtx->ldtr, dirty_sregs);
+            }
+            if (fExtrn & CPUMCTX_EXTRN_TR and not NEM_LNX_SREG_IDENTICAL(pRun->s.regs.sregs.tr, pCtx->tr)) {
+                NEM_LNX_EXPORT_SEG(pRun->s.regs.sregs.tr, pCtx->tr, dirty_sregs);
+            }
+
         }
         if (fExtrn & CPUMCTX_EXTRN_CR_MASK)
         {
-            if (fExtrn & CPUMCTX_EXTRN_CR0)
-                pRun->s.regs.sregs.cr0   = pCtx->cr0;
-            if (fExtrn & CPUMCTX_EXTRN_CR2)
-                pRun->s.regs.sregs.cr2   = pCtx->cr2;
-            if (fExtrn & CPUMCTX_EXTRN_CR3)
-                pRun->s.regs.sregs.cr3   = pCtx->cr3;
-            if (fExtrn & CPUMCTX_EXTRN_CR4)
-                pRun->s.regs.sregs.cr4   = pCtx->cr4;
+            if (fExtrn & CPUMCTX_EXTRN_CR0) {
+                NEM_UPDATE_IF_CHANGED(pRun->s.regs.sregs.cr0, pCtx->cr0, dirty_sregs);
+            }
+            if (fExtrn & CPUMCTX_EXTRN_CR2) {
+                NEM_UPDATE_IF_CHANGED(pRun->s.regs.sregs.cr2, pCtx->cr2, dirty_sregs);
+            }
+            if (fExtrn & CPUMCTX_EXTRN_CR3) {
+                NEM_UPDATE_IF_CHANGED(pRun->s.regs.sregs.cr3, pCtx->cr3, dirty_sregs);
+            }
+            if (fExtrn & CPUMCTX_EXTRN_CR4) {
+                NEM_UPDATE_IF_CHANGED(pRun->s.regs.sregs.cr4, pCtx->cr4, dirty_sregs);
+            }
+        }
+        if (fExtrn & CPUMCTX_EXTRN_EFER) {
+            NEM_UPDATE_IF_CHANGED(pRun->s.regs.sregs.efer, pCtx->msrEFER, dirty_sregs);
         }
-        if (fExtrn & CPUMCTX_EXTRN_EFER)
-            pRun->s.regs.sregs.efer   = pCtx->msrEFER;
 
-        RT_ZERO(pRun->s.regs.sregs.interrupt_bitmap); /* this is an alternative interrupt injection interface */
 
-        pRun->kvm_dirty_regs |= KVM_SYNC_X86_SREGS;
+        if (dirty_sregs) {
+            pRun->kvm_dirty_regs |= KVM_SYNC_X86_SREGS;
+        } else {
+            // This is a very weird and poorly documented part of the kvm_run structure.
+            // https://www.kernel.org/doc/html/latest/virt/kvm/api.html explains this the following way:
+            //
+            //   interrupt_bitmap is a bitmap of pending external interrupts. At most one bit may be set.
+            //   This interrupt has been acknowledged by the APIC but not yet injected into the cpu core.
+            //
+            // Looking at the kernel part of SET/GET_SREGS, we can see that this is kinda true, but not quite.
+            // The kernel sets only 1 bit, but never clears any of the fields. Thus, in order to have only
+            // a single bit set, userspace must clear the bitmap iff we haven't modified any SREGS. If we have
+            // modified SREGS, we have to transfer the unmodified bitmap back to KVM, because otherwise, we
+            // would tell KVM that the injection is no longer pending.
+            //
+            //
+            // This is a nasty interface and we should probably do what Qemu does, that is, using SET/GET_SREGS2
+            // where this field is no longer present.
+            RT_ZERO(pRun->s.regs.sregs.interrupt_bitmap);
+        }
+
     }
+#undef NEM_LNX_EXPORT_SEG
+#undef NEM_LNX_SREG_IDENTICAL
+#undef NEM_UPDATE_IF_CHANGED
 
     /*
      * Debug registers.
@@ -1836,6 +2669,8 @@ static int nemHCLnxExportState(PVM pVM, PVMCPU pVCpu, PCPUMCTX pCtx, struct kvm_
         if (fExtrn & CPUMCTX_EXTRN_OTHER_MSRS)
         {
             ADD_MSR(MSR_IA32_CR_PAT, pCtx->msrPAT);
+            ADD_MSR(MSR_IA32_ARCH_CAPABILITIES, pCtxMsrs->msr.ArchCaps);
+            ADD_MSR(MSR_IA32_SPEC_CTRL, pCtxMsrs->msr.SpecCtrl);
             /** @todo What do we _have_ to add here?
              * We also have: Mttr*, MiscEnable, FeatureControl. */
         }
@@ -1862,37 +2697,20 @@ static int nemHCLnxExportState(PVM pVM, PVMCPU pVCpu, PCPUMCTX pCtx, struct kvm_
                ==           (CPUMCTX_EXTRN_INHIBIT_INT | CPUMCTX_EXTRN_INHIBIT_NMI));
 
         struct kvm_vcpu_events KvmEvents = {0};
+        int rcLnx = ioctl(pVCpu->nem.s.fdVCpu, KVM_GET_VCPU_EVENTS, &KvmEvents);
+        AssertLogRelMsgReturn(rcLnx == 0, ("rcLnx=%d errno=%d\n", rcLnx, errno), VERR_NEM_IPE_5);
 
         KvmEvents.flags = KVM_VCPUEVENT_VALID_SHADOW;
         if (!CPUMIsInInterruptShadowWithUpdate(&pVCpu->cpum.GstCtx))
         { /* probably likely */ }
         else
-            KvmEvents.interrupt.shadow = (CPUMIsInInterruptShadowAfterSs()  ? KVM_X86_SHADOW_INT_MOV_SS : 0)
-                                       | (CPUMIsInInterruptShadowAfterSti() ? KVM_X86_SHADOW_INT_STI    : 0);
+            KvmEvents.interrupt.shadow = (CPUMIsInInterruptShadowAfterSs(&pVCpu->cpum.GstCtx)  ? KVM_X86_SHADOW_INT_MOV_SS : 0)
+                                       | (CPUMIsInInterruptShadowAfterSti(&pVCpu->cpum.GstCtx) ? KVM_X86_SHADOW_INT_STI    : 0);
 
         /* No flag - this is updated unconditionally. */
         KvmEvents.nmi.masked = CPUMAreInterruptsInhibitedByNmi(&pVCpu->cpum.GstCtx);
 
-        if (TRPMHasTrap(pVCpu))
-        {
-            TRPMEVENT enmType = TRPM_32BIT_HACK;
-            uint8_t   bTrapNo = 0;
-            TRPMQueryTrap(pVCpu, &bTrapNo, &enmType);
-            Log(("nemHCLnxExportState: Pending trap: bTrapNo=%#x enmType=%d\n", bTrapNo, enmType));
-            if (   enmType == TRPM_HARDWARE_INT
-                || enmType == TRPM_SOFTWARE_INT)
-            {
-                KvmEvents.interrupt.soft     = enmType == TRPM_SOFTWARE_INT;
-                KvmEvents.interrupt.nr       = bTrapNo;
-                KvmEvents.interrupt.injected = 1;
-                STAM_REL_COUNTER_INC(&pVCpu->nem.s.StatExportPendingInterrupt);
-                TRPMResetTrap(pVCpu);
-            }
-            else
-                AssertFailed();
-        }
-
-        int rcLnx = ioctl(pVCpu->nem.s.fdVCpu, KVM_SET_VCPU_EVENTS, &KvmEvents);
+        rcLnx = ioctl(pVCpu->nem.s.fdVCpu, KVM_SET_VCPU_EVENTS, &KvmEvents);
         AssertLogRelMsgReturn(rcLnx == 0, ("rcLnx=%d errno=%d\n", rcLnx, errno), VERR_NEM_IPE_3);
     }
 
@@ -1917,8 +2735,31 @@ static int nemHCLnxExportState(PVM pVM, PVMCPU pVCpu, PCPUMCTX pCtx, struct kvm_
 VMM_INT_DECL(int) NEMHCQueryCpuTick(PVMCPUCC pVCpu, uint64_t *pcTicks, uint32_t *puAux)
 {
     STAM_REL_COUNTER_INC(&pVCpu->nem.s.StatQueryCpuTick);
-    // KVM_GET_CLOCK?
-    RT_NOREF(pVCpu, pcTicks, puAux);
+
+    // This function is called when the VM is paused or
+    // suspended. It's called for all vCPUs.
+
+    const size_t NMSRS = 2;
+
+    size_t szReq = RT_UOFFSETOF_DYN(struct kvm_msrs, entries[NMSRS]);
+    struct kvm_msrs *pReq = static_cast<kvm_msrs *>(alloca(szReq));
+    memset(pReq, 0, szReq);
+
+    pReq->nmsrs = NMSRS;
+    pReq->entries[0].index = MSR_IA32_TSC;
+    pReq->entries[1].index = MSR_K8_TSC_AUX;
+
+    int rcLnx = ioctl(pVCpu->nem.s.fdVCpu, KVM_GET_MSRS, pReq);
+    AssertLogRelMsgReturn(rcLnx == NMSRS, ("rcLnx=%d errno=%d\n", rcLnx, errno), VERR_NEM_IPE_5);
+
+    if (pcTicks) {
+      *pcTicks = pReq->entries[0].data;
+    }
+
+    if (puAux) {
+      *puAux = static_cast<uint32_t>(pReq->entries[1].data);
+    }
+
     return VINF_SUCCESS;
 }
 
@@ -1935,8 +2776,39 @@ VMM_INT_DECL(int) NEMHCQueryCpuTick(PVMCPUCC pVCpu, uint64_t *pcTicks, uint32_t
  */
 VMM_INT_DECL(int) NEMHCResumeCpuTickOnAll(PVMCC pVM, PVMCPUCC pVCpu, uint64_t uPausedTscValue)
 {
-    // KVM_SET_CLOCK?
-    RT_NOREF(pVM, pVCpu, uPausedTscValue);
+    RT_NOREF(pVCpu);
+
+    // This function is called once during unpause or resume. Despite
+    // the pVCpu parameter it is _not_ called for all vCPUs.
+
+    const size_t NMSRS = 1;
+
+    size_t szReq = RT_UOFFSETOF_DYN(struct kvm_msrs, entries[NMSRS]);
+    struct kvm_msrs *pReq = static_cast<kvm_msrs *>(alloca(szReq));
+    memset(pReq, 0, szReq);
+
+    pReq->nmsrs = NMSRS;
+    pReq->entries[0].index = MSR_IA32_TSC;
+    pReq->entries[0].data = uPausedTscValue;
+
+    // Setting the individual TSC values of all CPUs is fundamentally
+    // flawed, because the TSCs keep ticking while we set them. That
+    // means that we never really end up with synchronized TSC values
+    // unless KVM's built-in TSC synchronization magic fixes things up
+    // for us. But the interface doesn't leave us a lot of choice here
+    // for now.
+    //
+    // A better approach would be to use KVM_GET_CLOCK/KVM_SET_CLOCK
+    // and restore TSC_ADJUST values. We should validate whether this
+    // does the right thing though first.
+    for (VMCPUID idCpu = 0; idCpu < pVM->cCpus; idCpu++)
+    {
+        PVMCPU pVCpuCur = pVM->apCpusR3[idCpu];
+
+        int rcLnx = ioctl(pVCpuCur->nem.s.fdVCpu, KVM_SET_MSRS, pReq);
+        AssertLogRelMsgReturn(rcLnx == NMSRS, ("rcLnx=%d errno=%d\n", rcLnx, errno), VERR_NEM_IPE_5);
+    }
+
     return VINF_SUCCESS;
 }
 
@@ -1958,6 +2830,7 @@ VMM_INT_DECL(uint32_t) NEMHCGetFeatures(PVMCC pVM)
 
 VMMR3_INT_DECL(bool) NEMR3CanExecuteGuest(PVM pVM, PVMCPU pVCpu)
 {
+#ifndef VBOX_WITH_KVM_IRQCHIP_FULL
     /*
      * Only execute when the A20 gate is enabled as I cannot immediately
      * spot any A20 support in KVM.
@@ -1965,6 +2838,15 @@ VMMR3_INT_DECL(bool) NEMR3CanExecuteGuest(PVM pVM, PVMCPU pVCpu)
     RT_NOREF(pVM);
     Assert(VM_IS_NEM_ENABLED(pVM));
     return PGMPhysIsA20Enabled(pVCpu);
+#else
+    /*
+     * In full-irqchip mode, we always need to execute via KVM because we
+     * have no other way to inject interrupt into the guest (because the PIC is
+     * in the kernel!). Otherwise, we will break non-UEFI boot. This will
+     * break DOS support.
+     */
+    return true;
+#endif
 }
 
 
@@ -1977,6 +2859,14 @@ bool nemR3NativeSetSingleInstruction(PVM pVM, PVMCPU pVCpu, bool fEnable)
 
 void nemR3NativeNotifyFF(PVM pVM, PVMCPU pVCpu, uint32_t fFlags)
 {
+    if (pVCpu->hThread == RTThreadSelf()) {
+        // RTThreadPoke doesn't like poking the current thread. We can
+        // safely return here because the vCPU thread is currently handling
+        // an exit and will will check all conditions again when we re-enter
+        // the run-loop.
+        return;
+    }
+
     int rc = RTThreadPoke(pVCpu->hThread);
     LogFlow(("nemR3NativeNotifyFF: #%u -> %Rrc\n", pVCpu->idCpu, rc));
     AssertRC(rc);
@@ -2010,12 +2900,10 @@ static VBOXSTRICTRC nemHCLnxHandleInterruptFF(PVM pVM, PVMCPU pVCpu, struct kvm_
      * only inject one event per KVM_RUN call.  This can only happend if we
      * can directly from the loop in EM, so the inhibit bits must be internal.
      */
-    if (!TRPMHasTrap(pVCpu))
-    { /* semi likely */ }
-    else
+    if (TRPMHasTrap(pVCpu))
     {
-        Assert(!(pVCpu->cpum.GstCtx.fExtrn & (CPUMCTX_EXTRN_INHIBIT_INT | CPUMCTX_EXTRN_INHIBIT_NMI)));
         Log8(("nemHCLnxHandleInterruptFF: TRPM has an pending event already\n"));
+
         return VINF_SUCCESS;
     }
 
@@ -2024,12 +2912,12 @@ static VBOXSTRICTRC nemHCLnxHandleInterruptFF(PVM pVM, PVMCPU pVCpu, struct kvm_
      */
     if (VMCPU_FF_TEST_AND_CLEAR(pVCpu, VMCPU_FF_UPDATE_APIC))
     {
-        APICUpdatePendingInterrupts(pVCpu);
-        if (!VMCPU_FF_IS_ANY_SET(pVCpu, VMCPU_FF_INTERRUPT_APIC | VMCPU_FF_INTERRUPT_PIC
-                                      | VMCPU_FF_INTERRUPT_NMI  | VMCPU_FF_INTERRUPT_SMI))
-            return VINF_SUCCESS;
+        AssertLogRelMsgReturn(false, ("VMCPU_FF_UPDATE_APIC is set"), VERR_NEM_IPE_5);
     }
 
+    if (!VMCPU_FF_IS_ANY_SET(pVCpu, VMCPU_FF_INTERRUPT_PIC | VMCPU_FF_INTERRUPT_NMI  | VMCPU_FF_INTERRUPT_SMI))
+        return VINF_SUCCESS;
+
     /*
      * We don't currently implement SMIs.
      */
@@ -2052,12 +2940,12 @@ static VBOXSTRICTRC nemHCLnxHandleInterruptFF(PVM pVM, PVMCPU pVCpu, struct kvm_
     KvmEvents.flags |= KVM_VCPUEVENT_VALID_SHADOW;
     if (!(pVCpu->cpum.GstCtx.fExtrn & CPUMCTX_EXTRN_INHIBIT_INT))
         KvmEvents.interrupt.shadow = !CPUMIsInInterruptShadowWithUpdate(&pVCpu->cpum.GstCtx) ? 0
-                                   :   (CPUMIsInInterruptShadowAfterSs()  ? KVM_X86_SHADOW_INT_MOV_SS : 0)
-                                     | (CPUMIsInInterruptShadowAfterSti() ? KVM_X86_SHADOW_INT_STI    : 0);
+                                   :   (CPUMIsInInterruptShadowAfterSs(&pVCpu->cpum.GstCtx)  ? KVM_X86_SHADOW_INT_MOV_SS : 0)
+                                     | (CPUMIsInInterruptShadowAfterSti(&pVCpu->cpum.GstCtx) ? KVM_X86_SHADOW_INT_STI    : 0);
     else
         CPUMUpdateInterruptShadowSsStiEx(&pVCpu->cpum.GstCtx,
                                          RT_BOOL(KvmEvents.interrupt.shadow & KVM_X86_SHADOW_INT_MOV_SS),
-                                         RT_BOOL(KvmEvents.interrupt.shadow & KVM_X86_SHADOW_INT_MOV_STI),
+                                         RT_BOOL(KvmEvents.interrupt.shadow & KVM_X86_SHADOW_INT_STI),
                                          pRun->s.regs.regs.rip);
 
     if (!(pVCpu->cpum.GstCtx.fExtrn & CPUMCTX_EXTRN_INHIBIT_NMI))
@@ -2085,35 +2973,24 @@ static VBOXSTRICTRC nemHCLnxHandleInterruptFF(PVM pVM, PVMCPU pVCpu, struct kvm_
         Log8(("Queuing NMI on %u\n", pVCpu->idCpu));
     }
 
+#ifdef VBOX_WITH_KVM_IRQCHIP_FULL
+    AssertLogRelMsg(!VMCPU_FF_IS_ANY_SET(pVCpu, VMCPU_FF_INTERRUPT_PIC), ("PDM has pic interrupt but full irqchip is enabled"));
+#else
     /*
-     * APIC or PIC interrupt?
+     * PIC interrupt?
      */
-    if (VMCPU_FF_IS_ANY_SET(pVCpu, VMCPU_FF_INTERRUPT_APIC | VMCPU_FF_INTERRUPT_PIC))
+    if (VMCPU_FF_IS_ANY_SET(pVCpu, VMCPU_FF_INTERRUPT_PIC))
     {
         if (pRun->s.regs.regs.rflags & X86_EFL_IF)
         {
-            if (KvmEvents.interrupt.shadow == 0)
+            if (pRun->ready_for_interrupt_injection)
             {
-                /*
-                 * If CR8 is in KVM, update the VBox copy so PDMGetInterrupt will
-                 * work correctly.
-                 */
-                if (pVCpu->cpum.GstCtx.fExtrn & CPUMCTX_EXTRN_APIC_TPR)
-                    APICSetTpr(pVCpu, (uint8_t)pRun->cr8 << 4);
-
                 uint8_t bInterrupt;
                 int rc = PDMGetInterrupt(pVCpu, &bInterrupt);
                 if (RT_SUCCESS(rc))
                 {
-                    Assert(KvmEvents.interrupt.injected == false);
-#if 0
-                    int rcLnx = ioctl(pVCpu->nem.s.fdVm, KVM_INTERRUPT, (unsigned long)bInterrupt);
-                    AssertLogRelMsgReturn(rcLnx == 0, ("rcLnx=%d errno=%d\n", rcLnx, errno), VERR_NEM_IPE_5);
-#else
-                    KvmEvents.interrupt.nr       = bInterrupt;
-                    KvmEvents.interrupt.soft     = false;
-                    KvmEvents.interrupt.injected = true;
-#endif
+                    TRPMAssertTrap(pVCpu, bInterrupt, TRPM_HARDWARE_INT);
+
                     Log8(("Queuing interrupt %#x on %u: %04x:%08RX64 efl=%#x\n", bInterrupt, pVCpu->idCpu,
                           pVCpu->cpum.GstCtx.cs.Sel, pVCpu->cpum.GstCtx.rip, pVCpu->cpum.GstCtx.eflags.u));
                 }
@@ -2134,7 +3011,7 @@ static VBOXSTRICTRC nemHCLnxHandleInterruptFF(PVM pVM, PVMCPU pVCpu, struct kvm_
             Log8(("Interrupt window pending on %u (#1)\n", pVCpu->idCpu));
         }
     }
-
+#endif
     /*
      * Now, update the state.
      */
@@ -2321,6 +3198,16 @@ static VBOXSTRICTRC nemHCLnxHandleExitMmio(PVMCC pVM, PVMCPUCC pVCpu, struct kvm
     VBOXSTRICTRC rcStrict;
     if (pRun->mmio.is_write)
     {
+        /*
+         * Sync LAPIC TPR register with cr8 from KVM. This is required as long
+         * as we don't use KVM's IRQCHIP feature.
+         *
+         * This doesn't cover the X2APIC mode. But the whole cr8-code will be
+         * gone very soon anyway as we will use KVM's split-irqchip.
+         */
+        if (pRun->mmio.phys_addr == XAPIC_TPR_ADDR) {
+            pRun->cr8 = *pRun->mmio.data >> LAPIC_TPR_SHIFT;
+        }
         rcStrict = PGMPhysWrite(pVM, pRun->mmio.phys_addr, pRun->mmio.data, pRun->mmio.len, PGMACCESSORIGIN_HM);
         Log4(("MmioExit/%u: %04x:%08RX64: WRITE %#x LB %u, %.*Rhxs -> rcStrict=%Rrc\n",
               pVCpu->idCpu, pRun->s.regs.sregs.cs.selector, pRun->s.regs.regs.rip,
@@ -2420,8 +3307,6 @@ static VBOXSTRICTRC nemHCLnxHandleExitWrMsr(PVMCPUCC pVCpu, struct kvm_run *pRun
     return rcStrict;
 }
 
-
-
 static VBOXSTRICTRC nemHCLnxHandleExit(PVMCC pVM, PVMCPUCC pVCpu, struct kvm_run *pRun, bool *pfStatefulExit)
 {
     STAM_REL_COUNTER_INC(&pVCpu->nem.s.StatExitTotal);
@@ -2450,12 +3335,10 @@ static VBOXSTRICTRC nemHCLnxHandleExit(PVMCC pVM, PVMCPUCC pVCpu, struct kvm_run
             return VINF_SUCCESS;
 
         case KVM_EXIT_SET_TPR:
-            STAM_REL_COUNTER_INC(&pVCpu->nem.s.StatExitSetTpr);
             AssertFailed();
             break;
 
         case KVM_EXIT_TPR_ACCESS:
-            STAM_REL_COUNTER_INC(&pVCpu->nem.s.StatExitTprAccess);
             AssertFailed();
             break;
 
@@ -2481,6 +3364,10 @@ static VBOXSTRICTRC nemHCLnxHandleExit(PVMCC pVM, PVMCPUCC pVCpu, struct kvm_run
                              pRun->s.regs.regs.rip + pRun->s.regs.sregs.cs.base, ASMReadTSC());
             STAM_REL_COUNTER_INC(&pVCpu->nem.s.StatExitIntr);
             Log5(("Intr/%u\n", pVCpu->idCpu));
+
+            /* If we don't consume the poke signal, subsequent KVM_RUN invocations will immediately return EINTR again. */
+            nemR3LnxConsumePokeSignal();
+
             return VINF_SUCCESS;
 
         case KVM_EXIT_HYPERCALL:
@@ -2497,11 +3384,53 @@ static VBOXSTRICTRC nemHCLnxHandleExit(PVMCC pVM, PVMCPUCC pVCpu, struct kvm_run
             AssertFailed();
             break;
         case KVM_EXIT_IOAPIC_EOI:
-            AssertFailed();
-            break;
+            PDMIoApicBroadcastEoi(pVM, pRun->eoi.vector);
+            return VINF_SUCCESS;
         case KVM_EXIT_HYPERV:
-            AssertFailed();
-            break;
+            Assert(pVM->gim.s.enmProviderId == GIMPROVIDERID_HYPERV);
+
+            switch (pRun->hyperv.type)
+            {
+            case KVM_EXIT_HYPERV_SYNDBG:
+                /* The synthetic debugger is not enabled and we should not get these exits. */
+                AssertFailed();
+                break;
+            case KVM_EXIT_HYPERV_HCALL:
+                LogRel2(("Hyper-V hcall input:%lx p0:%lx p1:%lx\n", pRun->hyperv.u.hcall.input, pRun->hyperv.u.hcall.params[0], pRun->hyperv.u.hcall.params[1]));
+
+                /* TODO KVM handles the performance-critical hypercalls on its own. We get mostly extended hypercalls
+                   here. We would need to forward them to gimHvHypercall. None of these features are enabled right now,
+                   so we can just deny the hypercall right away. */
+
+                pRun->hyperv.u.hcall.result = GIM_HV_STATUS_ACCESS_DENIED;
+                break;
+            case KVM_EXIT_HYPERV_SYNIC:
+                LogRel2(("HyperV synic msr:%lx control:%lx evt_page:%lx msg_page:%lx\n",
+                         pRun->hyperv.u.synic.msr,
+                         pRun->hyperv.u.synic.control,
+                         pRun->hyperv.u.synic.evt_page,
+                         pRun->hyperv.u.synic.msg_page));
+
+                switch (pRun->hyperv.u.synic.msr)
+                {
+                case MSR_GIM_HV_SCONTROL:
+                    gimHvWriteMsr(pVCpu, MSR_GIM_HV_SCONTROL, 0, pRun->hyperv.u.synic.control);
+                    break;
+                case MSR_GIM_HV_SIMP:
+                    gimHvWriteMsr(pVCpu, MSR_GIM_HV_SIMP, 0, pRun->hyperv.u.synic.msg_page);
+                    break;
+                case MSR_GIM_HV_SIEFP:
+                    gimHvWriteMsr(pVCpu, MSR_GIM_HV_SIEFP, 0, pRun->hyperv.u.synic.evt_page);
+                    break;
+                default:
+                    AssertReleaseFailed();
+                }
+                break;
+            default:
+                AssertReleaseFailed();
+            }
+
+            return VINF_SUCCESS;
 
         case KVM_EXIT_DIRTY_RING_FULL:
             AssertFailed();
@@ -2569,6 +3498,83 @@ static VBOXSTRICTRC nemHCLnxHandleExit(PVMCC pVM, PVMCPUCC pVCpu, struct kvm_run
     return VERR_NOT_IMPLEMENTED;
 }
 
+static VBOXSTRICTRC nemHCLnxHandleTimers(PVMCC pVM, PVMCPUCC pVCpu)
+{
+    uint64_t nsAbsNextTimerEvt;
+    uint64_t uTscNow;
+    uint64_t nsDelta = TMVirtualSyncGetNsToDeadline(pVM, &nsAbsNextTimerEvt, &uTscNow);
+
+    [[maybe_unused]] uint64_t const nsAbsOldTimerEvt = pVCpu->nem.s.nsAbsNextTimerEvt;
+
+    pVCpu->nem.s.nsAbsNextTimerEvt = nsAbsNextTimerEvt;
+
+    /*
+     * With this optimization we only program timers once when something changes. We can enable this when we are
+     * confident that everything works correctly.
+     */
+#ifdef VBOX_KVM_DONT_REPROGRAM_TIMERS
+    if (nsAbsOldTimerEvt == nsAbsNextTimerEvt) {
+        return VINF_SUCCESS;
+    }
+#endif
+
+    if (nsDelta == 0) {
+        /* If there is no timeout, program a catch-all timer instead. */
+        nsDelta = RT_NS_1MS_64;
+    } else if (nsDelta >= RT_NS_1SEC_64) {
+        /* We need to exit at least once every 4 seconds. */
+        nsDelta = RT_NS_1SEC_64;
+    }
+
+    struct itimerspec timeout {};
+
+    /*
+     * It would be nice to program absolute timeouts here instead for better accuracy, but VBox times do not correlate
+     * to any Linux timer.
+     */
+    timeout.it_value.tv_sec = nsDelta / RT_NS_1SEC_64;
+    timeout.it_value.tv_nsec = nsDelta % RT_NS_1SEC_64;
+
+    int rcTimer = timer_settime(pVCpu->nem.s.pTimer, 0 /* relative timeout */,
+                                    &timeout, nullptr);
+    AssertLogRel(rcTimer == 0);
+
+    return VINF_SUCCESS;
+}
+
+static VBOXSTRICTRC nemHCLnxCheckAndInjectInterrupts(PVMCPUCC pVCpu)
+{
+#ifdef VBOX_WITH_KVM_IRQCHIP_FULL
+    NOREF(pVCpu);
+    AssertLogRelMsg(!TRPMHasTrap(pVCpu), ("TRPM has trap but full irqchip is enabled"));
+    return VINF_SUCCESS;
+#else
+    if (TRPMHasTrap(pVCpu))
+    {
+        TRPMEVENT enmType = TRPM_32BIT_HACK;
+        uint8_t   bTrapNo = 0;
+        TRPMQueryTrap(pVCpu, &bTrapNo, &enmType);
+        Log(("nemHCLnxCheckAndInjectInterrupts: Pending trap: bTrapNo=%#x enmType=%d\n", bTrapNo, enmType));
+        if (enmType == TRPM_HARDWARE_INT)
+        {
+            struct kvm_interrupt kvm_int;
+            RT_ZERO(kvm_int);
+            kvm_int.irq = bTrapNo;
+            int rcLnx = ioctl(pVCpu->nem.s.fdVCpu, KVM_INTERRUPT, &kvm_int);
+            AssertLogRelMsgReturn(rcLnx == 0, ("rcLnx=%d errno=%d\n", rcLnx, errno), VERR_NEM_IPE_5);
+
+            TRPMResetTrap(pVCpu);
+        }
+        else
+        {
+            return VERR_NOT_SUPPORTED;
+        }
+
+    }
+    return VINF_SUCCESS;
+#endif
+}
+
 
 VBOXSTRICTRC nemR3NativeRunGC(PVM pVM, PVMCPU pVCpu)
 {
@@ -2584,6 +3590,28 @@ VBOXSTRICTRC nemR3NativeRunGC(PVM pVM, PVMCPU pVCpu)
         return VINF_SUCCESS;
     }
 
+    /*
+     * The first time we come here, we have to apply Spectre mitigations. The prctl interface only allows us to set
+     * these only for the current thread.
+     */
+    if (!pVCpu->nem.s.fMitigationsApplied) {
+        Log(("NEM/%u: applying mitigations\n", pVCpu->idCpu));
+        if (pVM->hm.s.fIbpbOnVmEntry || pVM->hm.s.fIbpbOnVmExit) {
+            int rcLnx = prctl(PR_SET_SPECULATION_CTRL, PR_SPEC_INDIRECT_BRANCH, PR_SPEC_FORCE_DISABLE, 0, 0);
+
+            if (rcLnx != 0 && errno == EPERM) {
+                LogRel(("WARNING: requested IBPB, but kernel API is not activated! Boot Linux with spectre_v2_user=prctl.\n", pVCpu->idCpu));
+            } else {
+                AssertLogRelMsgReturn(rcLnx == 0,
+                                      ("rcLnx=%d errno=%d\n", rcLnx, errno),
+                                      VERR_NEM_MISSING_KERNEL_API_1);
+                Log(("NEM/%u: enabled IBPB\n", pVCpu->idCpu));
+            }
+        }
+
+        pVCpu->nem.s.fMitigationsApplied = true;
+    }
+
     /*
      * The run loop.
      */
@@ -2612,6 +3640,8 @@ VBOXSTRICTRC nemR3NativeRunGC(PVM pVM, PVMCPU pVCpu)
             }
         }
 
+    // See NEMR3CanExecuteGuest for details why we ignore A20 at this point.
+#ifndef VBOX_WITH_KVM_IRQCHIP_FULL
         /*
          * Do not execute in KVM if the A20 isn't enabled.
          */
@@ -2623,6 +3653,7 @@ VBOXSTRICTRC nemR3NativeRunGC(PVM pVM, PVMCPU pVCpu)
             LogFlow(("NEM/%u: breaking: A20 disabled\n", pVCpu->idCpu));
             break;
         }
+#endif
 
         /*
          * Ensure KVM has the whole state.
@@ -2633,17 +3664,9 @@ VBOXSTRICTRC nemR3NativeRunGC(PVM pVM, PVMCPU pVCpu)
             AssertRCReturn(rc2, rc2);
         }
 
-        /*
-         * Poll timers and run for a bit.
-         *
-         * With the VID approach (ring-0 or ring-3) we can specify a timeout here,
-         * so we take the time of the next timer event and uses that as a deadline.
-         * The rounding heuristics are "tuned" so that rhel5 (1K timer) will boot fine.
-         */
-        /** @todo See if we cannot optimize this TMTimerPollGIP by only redoing
-         *        the whole polling job when timers have changed... */
-        uint64_t       offDeltaIgnored;
-        uint64_t const nsNextTimerEvt = TMTimerPollGIP(pVM, pVCpu, &offDeltaIgnored); NOREF(nsNextTimerEvt);
+        /* Poll timers and run for a bit. */
+        nemHCLnxHandleTimers(pVM, pVCpu);
+
         if (   !VM_FF_IS_ANY_SET(pVM, VM_FF_EMT_RENDEZVOUS | VM_FF_TM_VIRTUAL_SYNC)
             && !VMCPU_FF_IS_ANY_SET(pVCpu, VMCPU_FF_HM_TO_R3_MASK))
         {
@@ -2653,13 +3676,20 @@ VBOXSTRICTRC nemR3NativeRunGC(PVM pVM, PVMCPU pVCpu)
                          pVCpu->idCpu, pRun->s.regs.sregs.cs.selector, pRun->s.regs.regs.rip,
                          !!(pRun->s.regs.regs.rflags & X86_EFL_IF), pRun->s.regs.regs.rflags,
                          pRun->s.regs.sregs.ss.selector, pRun->s.regs.regs.rsp, pRun->s.regs.sregs.cr0));
+
+                VBOXSTRICTRC rc2 = nemHCLnxCheckAndInjectInterrupts(pVCpu);
+                AssertLogRelMsg(RT_SUCCESS(rc2), ("Failed to inject interrupt"));
+
                 TMNotifyStartOfExecution(pVM, pVCpu);
 
                 int rcLnx = ioctl(pVCpu->nem.s.fdVCpu, KVM_RUN, 0UL);
+                int errno_ = errno;
 
                 VMCPU_CMPXCHG_STATE(pVCpu, VMCPUSTATE_STARTED_EXEC_NEM, VMCPUSTATE_STARTED_EXEC_NEM_WAIT);
                 TMNotifyEndOfExecution(pVM, pVCpu, ASMReadTSC());
 
+                pVCpu->nem.s.pRun->immediate_exit = 0;
+
 #ifdef LOG_ENABLED
                 if (LogIsFlowEnabled())
                 {
@@ -2672,7 +3702,7 @@ VBOXSTRICTRC nemR3NativeRunGC(PVM pVM, PVMCPU pVCpu)
                 }
 #endif
                 fStatefulExit = false;
-                if (RT_LIKELY(rcLnx == 0 || errno == EINTR))
+                if (RT_LIKELY(rcLnx == 0 || errno_ == EINTR))
                 {
                     /*
                      * Deal with the exit.
@@ -2687,10 +3717,19 @@ VBOXSTRICTRC nemR3NativeRunGC(PVM pVM, PVMCPU pVCpu)
                         break;
                     }
                 }
+                else if (errno_ == EAGAIN) {
+                    /*
+                    * We might drop out of KVM_RUN if the vCPU is still in an
+                    * uninitialized state (e.g. WAIT_FOR_INIT) and some spurious
+                    * wakeup event is received. In this case, simply do nothing
+                    * and let the run loop enter KVM_RUN again.
+                    * See https://elixir.bootlin.com/linux/v6.6/source/arch/x86/kvm/x86.c#L11138
+                    */
+                }
                 else
                 {
-                    int rc2 = RTErrConvertFromErrno(errno);
-                    AssertLogRelMsgFailedReturn(("KVM_RUN failed: rcLnx=%d errno=%u rc=%Rrc\n", rcLnx, errno, rc2), rc2);
+                    rc2 = RTErrConvertFromErrno(errno_);
+                    AssertLogRelMsgFailedReturn(("KVM_RUN failed: rcLnx=%d errno=%u rc=%Rrc\n", rcLnx, errno_, rc2), rc2);
                 }
 
                 /*
@@ -2835,4 +3874,3 @@ VBOXSTRICTRC nemR3NativeRunGC(PVM pVM, PVMCPU pVCpu)
  * This is using KVM.
  *
  */
-
diff --git a/src/VBox/VMM/VMMR3/PDMDevMiscHlp.cpp b/src/VBox/VMM/VMMR3/PDMDevMiscHlp.cpp
index f11f0b2..d723f54 100644
--- a/src/VBox/VMM/VMMR3/PDMDevMiscHlp.cpp
+++ b/src/VBox/VMM/VMMR3/PDMDevMiscHlp.cpp
@@ -34,6 +34,7 @@
 #include <VBox/vmm/pdm.h>
 #include <VBox/vmm/pgm.h>
 #include <VBox/vmm/hm.h>
+#include <VBox/vmm/nem.h>
 #include <VBox/vmm/apic.h>
 #include <VBox/vmm/vm.h>
 #include <VBox/vmm/vmm.h>
@@ -98,6 +99,34 @@ static DECLCALLBACK(void) pdmR3PicHlp_Unlock(PPDMDEVINS pDevIns)
     pdmUnlock(pDevIns->Internal.s.pVMR3);
 }
 
+#if defined(IN_RING3) && defined(VBOX_WITH_KVM_IRQCHIP_FULL)
+/** @interface_method_impl{PDMPICHLP,pfnKvmSetIrqLine} */
+static DECLCALLBACK(int) pdmR3PicHlp_KvmSetIrqLine(PPDMDEVINS pDevIns, uint16_t u16Gsi, int iLevel)
+{
+    PDMDEV_ASSERT_DEVINS(pDevIns);
+    PVM pVM = pDevIns->Internal.s.pVMR3;
+
+    return NEMR3KvmSetIrqLine(pVM, u16Gsi, iLevel);
+}
+
+/** @interface_method_impl{PDMPICHLP,pfnKvmGetPicState} */
+static DECLCALLBACK(int) pdmR3PicHlp_KvmGetPicState(PPDMDEVINS pDevIns, KVMIRQCHIP irqchip, KVMPICSTATE* state)
+{
+    PDMDEV_ASSERT_DEVINS(pDevIns);
+    PVM pVM = pDevIns->Internal.s.pVMR3;
+
+    return NEMR3KvmGetPicState(pVM, irqchip, state);
+}
+
+/** @interface_method_impl{PDMPICHLP,pfnKvmSetPicState} */
+static DECLCALLBACK(int) pdmR3PicHlp_KvmSetPicState(PPDMDEVINS pDevIns, KVMIRQCHIP irqchip, KVMPICSTATE* state)
+{
+    PDMDEV_ASSERT_DEVINS(pDevIns);
+    PVM pVM = pDevIns->Internal.s.pVMR3;
+
+    return NEMR3KvmSetPicState(pVM, irqchip, state);
+}
+#endif
 
 /**
  * PIC Device Helpers.
@@ -109,6 +138,11 @@ const PDMPICHLP g_pdmR3DevPicHlp =
     pdmR3PicHlp_ClearInterruptFF,
     pdmR3PicHlp_Lock,
     pdmR3PicHlp_Unlock,
+#if defined(IN_RING3) && defined(VBOX_WITH_KVM_IRQCHIP_FULL)
+    pdmR3PicHlp_KvmSetIrqLine,
+    pdmR3PicHlp_KvmGetPicState,
+    pdmR3PicHlp_KvmSetPicState,
+#endif
     PDM_PICHLP_VERSION /* the end */
 };
 
@@ -175,7 +209,64 @@ static DECLCALLBACK(int) pdmR3IoApicHlp_IommuMsiRemap(PPDMDEVINS pDevIns, uint16
     return VERR_IOMMU_NOT_PRESENT;
 }
 
+#if defined(IN_RING3) && defined(VBOX_WITH_KVM)
+/** @interface_method_impl{PDMIOAPICHLP,pfnKvmSetIrqLine} */
+static DECLCALLBACK(int) pdmR3IoApicHlp_KvmSetIrqLine(PPDMDEVINS pDevIns, uint16_t u16Gsi, int iLevel) {
+    PDMDEV_ASSERT_DEVINS(pDevIns);
+    PVM pVM = pDevIns->Internal.s.pVMR3;
+
+    return NEMR3KvmSetIrqLine(pVM, u16Gsi, iLevel);
+}
+
+/** @interface_method_impl{PDMIOAPICHLP,pfnKvmSplitIrqchipDeliverMsi} */
+static DECLCALLBACK(int) pdmR3IoApicHlp_KvmSplitIrqchipDeliverMsi(PPDMDEVINS pDevIns, PCMSIMSG pMsi)
+{
+    PDMDEV_ASSERT_DEVINS(pDevIns);
+    PVM pVM = pDevIns->Internal.s.pVMR3;
+
+    return NEMR3KvmSplitIrqchipDeliverMsi(pVM, pMsi);
+}
+
 
+/** @interface_method_impl{PDMIOAPICHLP,pfnKvmSplitIrqchipAddUpdateRTE} */
+static DECLCALLBACK(int) pdmR3IoApicHlp_KvmSplitIrqchipAddUpdateRTE(PPDMDEVINS pDevIns, uint16_t gsi, PCMSIMSG pMsi)
+{
+    PDMDEV_ASSERT_DEVINS(pDevIns);
+    PVM pVM = pDevIns->Internal.s.pVMR3;
+
+    return NEMR3KvmSplitIrqchipAddUpdateRTE(pVM, gsi, pMsi);
+}
+
+
+/** @interface_method_impl{PDMIOAPICHLP,pfnKvmSplitIrqchipRemoveRTE} */
+static DECLCALLBACK(int) pdmR3IoApicHlp_KvmSplitIrqchipRemoveRTE(PPDMDEVINS pDevIns, uint16_t gsi)
+{
+    PDMDEV_ASSERT_DEVINS(pDevIns);
+    PVM pVM = pDevIns->Internal.s.pVMR3;
+
+    return NEMR3KvmSplitIrqchipRemoveRTE(pVM, gsi);
+}
+#endif
+
+#if defined(IN_RING3) && defined(VBOX_WITH_KVM_IRQCHIP_FULL)
+/** @interface_method_impl{PDMIOAPICHLP,pfnKvmGetIoApicState} */
+static DECLCALLBACK(int) pdmR3IoApicHlp_pfnKvmGetIoApicState(PPDMDEVINS pDevIns, KVMIOAPICSTATE* state)
+{
+    PDMDEV_ASSERT_DEVINS(pDevIns);
+    PVM pVM = pDevIns->Internal.s.pVMR3;
+
+    return NEMR3KvmGetIoApicState(pVM, state);
+}
+
+/** @interface_method_impl{PDMIOAPICHLP,pfnKvmSetIoApicState} */
+static DECLCALLBACK(int) pdmR3IoApicHlp_pfnKvmSetIoApicState(PPDMDEVINS pDevIns, KVMIOAPICSTATE* state)
+{
+    PDMDEV_ASSERT_DEVINS(pDevIns);
+    PVM pVM = pDevIns->Internal.s.pVMR3;
+
+    return NEMR3KvmSetIoApicState(pVM, state);
+}
+#endif
 /**
  * I/O APIC Device Helpers.
  */
@@ -187,6 +278,17 @@ const PDMIOAPICHLP g_pdmR3DevIoApicHlp =
     pdmR3IoApicHlp_Unlock,
     pdmR3IoApicHlp_LockIsOwner,
     pdmR3IoApicHlp_IommuMsiRemap,
+#if defined(IN_RING3) && defined(VBOX_WITH_KVM)
+    pdmR3IoApicHlp_KvmSetIrqLine,
+    pdmR3IoApicHlp_KvmSplitIrqchipDeliverMsi,
+    pdmR3IoApicHlp_KvmSplitIrqchipAddUpdateRTE,
+    pdmR3IoApicHlp_KvmSplitIrqchipRemoveRTE,
+#endif
+
+#if defined(IN_RING3) && defined(VBOX_WITH_KVM_IRQCHIP_FULL)
+    pdmR3IoApicHlp_pfnKvmGetIoApicState,
+    pdmR3IoApicHlp_pfnKvmSetIoApicState,
+#endif
     PDM_IOAPICHLP_VERSION /* the end */
 };
 
diff --git a/src/VBox/VMM/VMMR3/PGMPhys.cpp b/src/VBox/VMM/VMMR3/PGMPhys.cpp
index fb9fd66..b54be52 100644
--- a/src/VBox/VMM/VMMR3/PGMPhys.cpp
+++ b/src/VBox/VMM/VMMR3/PGMPhys.cpp
@@ -1862,7 +1862,12 @@ int pgmR3PhysRamPreAllocate(PVM pVM)
     Assert(pVM->pgm.s.fRamPreAlloc);
     Log(("pgmR3PhysRamPreAllocate: enter\n"));
 #ifdef VBOX_WITH_PGM_NEM_MODE
+#ifdef VBOX_WITH_PREALLOC_RAM_BY_DEFAULT
+    Log(("pgmR3PhysRamPreAllocate: Handled by default in NEM mode, skip\n"));
+    return VINF_SUCCESS;
+#else
     AssertLogRelReturn(!pVM->pgm.s.fNemMode, VERR_PGM_NOT_SUPPORTED_FOR_NEM_MODE);
+#endif
 #endif
 
     /*
diff --git a/src/VBox/VMM/VMMR3/VMM.cpp b/src/VBox/VMM/VMMR3/VMM.cpp
index e235184..787df96 100644
--- a/src/VBox/VMM/VMMR3/VMM.cpp
+++ b/src/VBox/VMM/VMMR3/VMM.cpp
@@ -1092,6 +1092,11 @@ static DECLCALLBACK(int) vmmR3Load(PVM pVM, PSSMHANDLE pSSM, uint32_t uVersion,
         AssertMsgFailed(("u32=%#x\n", u32));
         return VERR_SSM_DATA_UNIT_FORMAT_CHANGED;
     }
+
+#ifdef VBOX_WITH_KVM
+    NEMR3LoadExec(pVM);
+#endif
+
     return VINF_SUCCESS;
 }
 
diff --git a/src/VBox/VMM/include/GIMHvInternal.h b/src/VBox/VMM/include/GIMHvInternal.h
index 960dc36..7308180 100644
--- a/src/VBox/VMM/include/GIMHvInternal.h
+++ b/src/VBox/VMM/include/GIMHvInternal.h
@@ -202,6 +202,8 @@
 #define GIM_HV_HINT_INT_FOR_MBEC_SYSCALLS                   RT_BIT(13)
 /** Recommend using enlightened VMCS interfacea and nested enlightenments. */
 #define GIM_HV_HINT_NESTED_ENLIGHTENED_VMCS_INTERFACE       RT_BIT(14)
+/** Indicates that core-sharing is not possible. */
+#define GIM_HV_HINT_NO_NONARCH_CORESHARING                  RT_BIT(18)
 /** @}  */
 
 
@@ -1100,6 +1102,7 @@ AssertCompileSize(GIMHVEXTGETBOOTZEROMEM, 16);
 
 /** Microsoft Hyper-V vendor signature. */
 #define GIM_HV_VENDOR_MICROSOFT                   "Microsoft Hv"
+#define GIM_HV_VENDOR_VBOX                        "VBoxVBoxVBox"
 
 /**
  * MMIO2 region indices.
diff --git a/src/VBox/VMM/include/NEMInternal.h b/src/VBox/VMM/include/NEMInternal.h
index e0817e2..35a7665 100644
--- a/src/VBox/VMM/include/NEMInternal.h
+++ b/src/VBox/VMM/include/NEMInternal.h
@@ -35,13 +35,24 @@
 #include <VBox/types.h>
 #include <VBox/vmm/nem.h>
 #include <VBox/vmm/cpum.h> /* For CPUMCPUVENDOR. */
+#ifdef VBOX_WITH_KVM
+#include <VBox/vmm/pdmdev.h> /* For KVM_IRQCHIP_NUM_IOAPIC_INTR_PINS */
+#endif
 #include <VBox/vmm/stam.h>
 #include <VBox/vmm/vmapi.h>
+#if defined(IN_RING3) && defined(VBOX_WITH_KVM)
+#include <array>
+#include <memory>
+#include <optional>
+#include <VBox/msi.h>
+#endif
 #ifdef RT_OS_WINDOWS
 #include <iprt/nt/hyperv.h>
 #include <iprt/critsect.h>
 #elif defined(RT_OS_DARWIN)
 # include "VMXInternal.h"
+#elif defined(RT_OS_LINUX)
+# include <time.h>
 #endif
 
 RT_C_DECLS_BEGIN
@@ -207,6 +218,9 @@ typedef struct NEM
     uint16_t                    idPrevSlot;
     /** Memory slot ID allocation bitmap. */
     uint64_t                    bmSlotIds[_32K / 8 / sizeof(uint64_t)];
+#if defined(IN_RING3) && defined(VBOX_WITH_KVM)
+    std::unique_ptr<std::array<std::optional<MSIMSG>, KVM_IRQCHIP_NUM_IOAPIC_INTR_PINS>> pARedirectionTable;
+#endif
 
 #elif defined(RT_OS_WINDOWS)
     /** Set if we've created the EMTs. */
@@ -354,11 +368,22 @@ typedef struct NEMCPU
     bool                        fGCMTrapXcptDE : 1;
 
 #if defined(RT_OS_LINUX)
-    uint8_t                     abPadding[3];
+    uint8_t                     abPadding[2];
+    /** Whether processor bug mitigations have already been applied. */
+    bool                        fMitigationsApplied;
     /** The KVM VCpu file descriptor. */
     int32_t                     fdVCpu;
     /** Pointer to the KVM_RUN data exchange region. */
     R3PTRTYPE(struct kvm_run *) pRun;
+
+#if defined(IN_RING3) && defined(VBOX_WITH_KVM)
+    /** The vCPU timer. */
+    timer_t                     pTimer;
+
+    /** The the next timeout (absolute). */
+    uint64_t                    nsAbsNextTimerEvt;
+#endif
+
     /** The MSR_IA32_APICBASE value known to KVM. */
     uint64_t                    uKvmApicBase;
 
@@ -666,4 +691,3 @@ int     nemHCNativeNotifyPhysPageAllocated(PVMCC pVM, RTGCPHYS GCPhys, RTHCPHYS
 RT_C_DECLS_END
 
 #endif /* !VMM_INCLUDED_SRC_include_NEMInternal_h */
-
